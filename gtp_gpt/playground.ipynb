{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./venv/lib/python3.10/site-packages (1.13.1)\r\n",
      "Requirement already satisfied: transformers in ./venv/lib/python3.10/site-packages (4.26.1)\r\n",
      "Collecting wandb\r\n",
      "  Using cached wandb-0.13.10-py3-none-any.whl (2.0 MB)\r\n",
      "Requirement already satisfied: PyGuitarPro in ./venv/lib/python3.10/site-packages (0.9.3)\r\n",
      "Requirement already satisfied: typing-extensions in ./venv/lib/python3.10/site-packages (from torch) (4.5.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.10/site-packages (from transformers) (6.0)\r\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in ./venv/lib/python3.10/site-packages (from transformers) (0.13.2)\r\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.10/site-packages (from transformers) (1.24.2)\r\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.10/site-packages (from transformers) (2.28.2)\r\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from transformers) (3.9.0)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in ./venv/lib/python3.10/site-packages (from transformers) (4.65.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.10/site-packages (from transformers) (23.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in ./venv/lib/python3.10/site-packages (from transformers) (0.12.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.10/site-packages (from transformers) (2022.10.31)\r\n",
      "Requirement already satisfied: psutil>=5.0.0 in ./venv/lib/python3.10/site-packages (from wandb) (5.9.4)\r\n",
      "Collecting docker-pycreds>=0.4.0\r\n",
      "  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\r\n",
      "Collecting GitPython>=1.0.0\r\n",
      "  Using cached GitPython-3.1.31-py3-none-any.whl (184 kB)\r\n",
      "Collecting appdirs>=1.4.3\r\n",
      "  Using cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\r\n",
      "Collecting setproctitle\r\n",
      "  Using cached setproctitle-1.3.2-cp310-cp310-macosx_10_9_x86_64.whl (11 kB)\r\n",
      "Collecting protobuf!=4.21.0,<5,>=3.19.0\r\n",
      "  Using cached protobuf-4.22.0-cp37-abi3-macosx_10_9_universal2.whl (397 kB)\r\n",
      "Collecting sentry-sdk>=1.0.0\r\n",
      "  Using cached sentry_sdk-1.16.0-py2.py3-none-any.whl (184 kB)\r\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.10/site-packages (from wandb) (67.1.0)\r\n",
      "Collecting Click!=8.0.0,>=7.0\r\n",
      "  Using cached click-8.1.3-py3-none-any.whl (96 kB)\r\n",
      "Collecting pathtools\r\n",
      "  Using cached pathtools-0.1.2.tar.gz (11 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hRequirement already satisfied: attrs>=19.2 in ./venv/lib/python3.10/site-packages (from PyGuitarPro) (22.2.0)\r\n",
      "Requirement already satisfied: six>=1.4.0 in ./venv/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\r\n",
      "Collecting gitdb<5,>=4.0.1\r\n",
      "  Using cached gitdb-4.0.10-py3-none-any.whl (62 kB)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests->transformers) (3.0.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests->transformers) (3.4)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./venv/lib/python3.10/site-packages (from requests->transformers) (1.26.14)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\r\n",
      "Collecting smmap<6,>=3.0.1\r\n",
      "  Using cached smmap-5.0.0-py3-none-any.whl (24 kB)\r\n",
      "Building wheels for collected packages: pathtools\r\n",
      "  Building wheel for pathtools (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=49a238c08d7de6857efc82f618c3b23529e60b7b745e7a7791ca862f2f123c0e\r\n",
      "  Stored in directory: /Users/vlad/Library/Caches/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\r\n",
      "Successfully built pathtools\r\n",
      "Installing collected packages: pathtools, appdirs, smmap, setproctitle, sentry-sdk, protobuf, docker-pycreds, Click, gitdb, GitPython, wandb\r\n",
      "Successfully installed Click-8.1.3 GitPython-3.1.31 appdirs-1.4.4 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 protobuf-4.22.0 sentry-sdk-1.16.0 setproctitle-1.3.2 smmap-5.0.0 wandb-0.13.10\r\n",
      "env: TOKENIZERS_PARALLELISM=false\n"
     ]
    }
   ],
   "source": [
    "!pip install torch transformers wandb PyGuitarPro\n",
    "%env TOKENIZERS_PARALLELISM false"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "drive_path = Path('/Users/vlad/googledrive')\n",
    "if not drive_path.exists():\n",
    "    drive_path = Path(\"/content/drive/MyDrive\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 49125 files\n"
     ]
    }
   ],
   "source": [
    "tabs_path = drive_path / 'PlayMusic/tabs'\n",
    "paths = list(tabs_path.glob('**/*.gp[3-5]'))\n",
    "print(f'Found {len(paths)} files')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "N_TOY = 100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Parsing tabs\n",
    "We would start with only bass tracks as they are simpler. Doing best to select bass tracks based on heuristics: 4 strings, 24 frets, instruments from 32 to 40 (unfortunately PyGuitarPro doesn't provide labels for the instruments, only numbers - so I checked the names in GuitarPro itself (rather, I use an open source version tuxguitar) and selected all instrument that have \"bass\" in the name."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 228/49125 [01:44<6:14:43,  2.17it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 99/49125 files with bass tracks, total 100 tracks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import guitarpro\n",
    "from tqdm import tqdm\n",
    "\n",
    "N_FRETS = 24\n",
    "N_STRINGS = 4  # base; 6 for standard guitar\n",
    "INSTRUMENTS = range(32, 40)  # base; range(24, 31) for standard guitar\n",
    "\n",
    "tracks_by_path = dict()\n",
    "\n",
    "for path_num, path in enumerate(tqdm(paths)):\n",
    "    try:\n",
    "        curl = guitarpro.parse(path)\n",
    "    except guitarpro.GPException:\n",
    "        print(f'   failed to parse {path}')\n",
    "        continue\n",
    "\n",
    "    tracks = []\n",
    "    for track in curl.tracks:\n",
    "        if all([\n",
    "            track.settings.tablature, \n",
    "            len(track.strings) == N_STRINGS,\n",
    "            track.fretCount == N_FRETS,\n",
    "            track.channel.instrument in INSTRUMENTS,\n",
    "        ]):\n",
    "            tracks.append(track)\n",
    "    \n",
    "    if tracks:\n",
    "        tracks_by_path[path] = tracks\n",
    "\n",
    "    if sum(map(len, tracks_by_path.values())) >= N_TOY:\n",
    "        break\n",
    "\n",
    "if len(tracks_by_path) == 0:\n",
    "    raise Exception('No bass tracks found')\n",
    "\n",
    "print(\n",
    "    f'Found {len(tracks_by_path)}/{len(paths)} files with bass tracks, '\n",
    "    f'total {sum(map(len, tracks_by_path.values()))} tracks'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Verifying tabs by printing one in a human-readable format"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/vlad/googledrive/PlayMusic/tabs/White Lion/White Lion - Lady Of The Valley.gp4\n",
      "Bass\n",
      "  1:-   |4+:7   4+:7   4:7   |8:~   4+:7   4:7   4:7   |4+:7   4+:7   4:7   |8:~\n",
      "4 1:-   |4+:-   4+:-   4:-   |8:-   4+:-   4:-   4:-   |4+:-   4+:-   4:-   |8:-\n",
      "4 1:-   |4+:-   4+:-   4:-   |8:-   4+:-   4:-   4:-   |4+:-   4+:-   4:-   |8:-\n",
      "  1:-   |4+:-   4+:-   4:-   |8:-   4+:-   4:-   4:-   |4+:-   4+:-   4:-   |8:-\n",
      "\n",
      "   4+:7   4:7   4:7   |4+:7   4+:7   4:7   |8:~   4+:7   4:7   4:7   |4+:7   4+:\n",
      "   4+:-   4:-   4:-   |4+:-   4+:-   4:-   |8:-   4+:-   4:-   4:-   |4+:-   4+:\n",
      "   4+:-   4:-   4:-   |4+:-   4+:-   4:-   |8:-   4+:-   4:-   4:-   |4+:-   4+:\n",
      "   4+:-   4:-   4:-   |4+:-   4+:-   4:-   |8:-   4+:-   4:-   4:-   |4+:-   4+:\n",
      "\n",
      "7   4:7   |8:~   4+:7   8:7   8+:-   8+:-   |4+:-   2:-   8:-   |4+:-   4:-   8+\n",
      "-   4:-   |8:-   4+:-   8:-   8+:-   8+:-   |4+:-   2:0   8:~   |4+:-   4:-   8+\n",
      "-   4:-   |8:-   4+:-   8:-   8+:-   8+:-   |4+:-   2:-   8:-   |4+:-   4:-   8+\n",
      "-   4:-   |8:-   4+:-   8:-   8+:1   8+:0   |4+:-   2:-   8:-   |4+:-   4:-   8+\n",
      "\n",
      ":-   8+:-   |4:-   8:-   2:5   8:~   |4+:6   4:-   8+:-   8+:-   |4+:-   2:-   8\n",
      ":-   8+:-   |4:-   8:-   2:-   8:-   |4+:-   4:7   8+:-   8+:-   |4+:-   2:0   8\n",
      ":-   8+:-   |4:3   8:3   2:-   8:-   |4+:-   4:-   8+:-   8+:-   |4+:-   2:-   8\n",
      ":1   8+:0   |4:-   8:-   2:-   8:-   |4+:-   4:-   8+:1   8+:0   |4+:-   2:-   8\n",
      "\n",
      ":-   |4+:-   4:-   8+:-   8+:-   |4:-   8:-   2:5   8:~   |4+:6   4:-   8+:-   8\n",
      ":~   |4+:-   4:-   8+:-   8+:-   |4:-   8:-   2:-   8:-   |4+:-   4:7   8+:-   8\n",
      ":-   |4+:-   4:-   8+:-   8+:-   |4:3   8:3   2:-   8:-   |4+:-   4:-   8+:-   8\n",
      ":-   |4+:-   4:-   8+:1   8+:0   |4:-   8:-   2:-   8:-   |4+:-   4:-   8+:1   8\n",
      "\n",
      "+:-   |4+:-   2:-   8:-   |4+:-   4:-   8+:-   8+:-   |4:-   8:-   4+:5   4:5   \n",
      "+:-   |4+:-   2:0   8:~   |4+:-   4:-   8+:-   8+:-   |4:-   8:-   4+:-   4:-   \n",
      "+:-   |4+:-   2:-   8:-   |4+:-   4:-   8+:-   8+:-   |4:3   8:3   4+:-   4:-   \n",
      "+:0   |4+:-   2:-   8:-   |4+:-   4:-   8+:1   8+:0   |4:-   8:-   4+:-   4:-   \n",
      "\n",
      "|4+:6   4:-   8+:-   8+:-   |4+:-   2:-   8:-   |4:-   8:-   4:-   8+:-   8+:-  \n",
      "|4+:-   4:7   8+:-   8+:-   |4+:-   2:0   8:~   |4:-   8:-   4:-   8+:-   8+:-  \n",
      "|4+:-   4:-   8+:-   8+:-   |4+:-   2:-   8:-   |4:-   8:-   4:-   8+:-   8+:-  \n",
      "|4+:-   4:-   8+:1   8+:0   |4+:-   2:-   8:-   |4:-   8:-   4:-   8+:1   8+:0  \n",
      "\n",
      " |4:-   8:-   4+:5   4:5   |4+:6   4+:-   4:-   |4+:-   4:-   8:-   4:-   |8:-  \n",
      " |4:-   8:-   4+:-   4:-   |4+:-   4+:7   4:7   |4+:-   4:-   8:-   4:-   |8:-  \n",
      " |4:3   8:3   4+:-   4:-   |4+:-   4+:-   4:-   |4+:8   4:7   8:-   4:8   |8:~  \n",
      " |4:-   8:-   4+:-   4:-   |4+:-   4+:-   4:-   |4+:-   4:-   8:-   4:-   |8:-  \n",
      "\n",
      " 4:-   8:-   4:-   8:0   8:0   |1:~   |1:~   |1:-   |2+:-   8:-   8:-   |1:-   |\n",
      " 4:-   8:-   4:-   8:-   8:-   |1:-   |1:-   |1:-   |2+:-   8:-   8:-   |1:0   |\n",
      " 4:7   8:-   4:8   8:-   8:-   |1:-   |1:-   |1:-   |2+:-   8:-   8:0   |1:-   |\n",
      " 4:-   8:-   4:-   8:-   8:-   |1:-   |1:-   |1:-   |2+:-   8:-   8:-   |1:-   |\n",
      "\n",
      "2+:-   4:-   |1:-   |1:-   |1:-   |1:-   |1:-   |1:-   |1:-   |1:-   |2+:-   8:-\n",
      "2+:~   4:-   |1:-   |1:-   |1:-   |1:-   |1:-   |1:-   |1:-   |1:-   |2+:-   8:-\n",
      "2+:-   4:-   |1:-   |1:-   |1:-   |1:-   |1:-   |1:-   |1:-   |1:-   |2+:-   8:-\n",
      "2+:-   4:-   |1:-   |1:-   |1:-   |1:-   |1:-   |1:-   |1:-   |1:-   |2+:-   8:-\n",
      "\n",
      "   8:-   |4+:-   8:-   4:-   4:-   |2+:-   8:-   8:-   |4+:-   8:-   8:-   8:-  \n",
      "   8:-   |4+:0   8:-   4:0   4:0   |2+:-   8:-   8:-   |4+:-   8:-   8:0   8:-  \n",
      "   8:0   |4+:-   8:0   4:-   4:-   |2+:3   8:~   8:3   |4+:3   8:3   8:-   8:3  \n",
      "   8:-   |4+:-   8:-   4:-   4:-   |2+:-   8:-   8:-   |4+:-   8:-   8:-   8:-  \n",
      "\n",
      " 8:-   8:-   |2+:-   8:-   8:-   |4+:-   8:-   8:-   8:-   8:-   8:-   |2+:-   8\n",
      " 8:-   8:-   |2+:-   8:-   8:-   |4+:-   8:-   8:-   8:-   8:-   8:0   |2+:-   8\n",
      " 8:-   8:-   |2+:-   8:-   8:-   |4+:-   8:-   8:-   8:-   8:0   8:-   |2+:3   8\n",
      " 8:-   8:3   |2+:1   8:~   8:-   |4+:1   8:-   8:1   8:3   8:-   8:-   |2+:-   8\n",
      "\n",
      ":-   8:-   |8:2   8:0   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8\n",
      ":-   8:-   |8:-   8:-   8:3   8:2   8:0   8:-   8:-   8:-   |8:-   8:-   8:-   8\n",
      ":~   8:-   |8:-   8:-   8:-   8:-   8:-   8:3   8:0   8:-   |8:0   8:0   8:0   8\n",
      ":-   8:3   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:3   |8:-   8:-   8:-   8\n",
      "\n",
      ":-   8:-   8:-   8:-   8:-   |4:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8\n",
      ":-   8:-   8:-   8:-   8:-   |4:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8\n",
      ":0   8:0   8:0   8:-   8:0   |4:~   8:0   8:0   8:0   8:0   8:0   8:0   |8:1   8\n",
      ":-   8:-   8:-   8:3   8:-   |4:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8\n",
      "\n",
      ":-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:\n",
      ":-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:\n",
      ":1   8:1   8:1   8:1   8:1   8:1   8:3   |8:~   8:3   8:3   8:3   8:3   8:1   8:\n",
      ":-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:\n",
      "\n",
      "-   8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:\n",
      "-   8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:\n",
      "0   8:-   |8:0   8:0   8:0   8:0   8:0   8:0   8:-   8:0   |8:~   8:0   8:0   8:\n",
      "-   8:3   |8:-   8:-   8:-   8:-   8:-   8:-   8:3   8:-   |8:-   8:-   8:-   8:\n",
      "\n",
      "-   8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   |4:\n",
      "-   8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   |4:\n",
      "0   8:0   8:0   8:0   8:0   |8:1   8:1   8:1   8:1   8:1   8:1   8:1   8:3   |4:\n",
      "-   8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   |4:\n",
      "\n",
      "-   2+:-   |1:-   |1:-   |2+:-   8:-   8:-   |4+:-   8:-   4:-   8:-   8:-   |2+\n",
      "-   2+:-   |1:-   |1:-   |2+:-   8:-   8:-   |4+:-   8:-   4:-   8:-   8:-   |2+\n",
      "~   2+:-   |1:-   |1:-   |2+:3   8:~   8:-   |4+:3   8:-   4:3   8:3   8:-   |2+\n",
      "-   2+:-   |1:-   |1:-   |2+:-   8:-   8:3   |4+:-   8:3   4:-   8:-   8:-   |2+\n",
      "\n",
      ":-   8:-   8:-   |4+:-   8:-   4:-   8:-   8:-   |2+:-   8:-   8:-   |4+:-   8:-\n",
      ":-   8:-   8:-   |4+:-   8:-   4:-   8:-   8:0   |2+:-   8:-   8:-   |4+:-   8:-\n",
      ":-   8:-   8:-   |4+:-   8:-   4:-   8:0   8:-   |2+:3   8:~   8:-   |4+:3   8:-\n",
      ":1   8:~   8:-   |4+:1   8:-   4:1   8:-   8:-   |2+:-   8:-   8:3   |4+:-   8:3\n",
      "\n",
      "   4:-   8:-   8:-   |1:-   |4+:-   4+:-   4:-   |2+:-   8:-   8:-   |4+:-   8:-\n",
      "   4:0   8:-   8:-   |1:-   |4+:-   4+:-   4:-   |2+:-   8:-   8:-   |4+:-   8:-\n",
      "   4:-   8:3   8:-   |1:-   |4+:-   4+:-   4:-   |2+:3   8:~   8:-   |4+:3   8:-\n",
      "   4:-   8:-   8:3   |1:-   |4+:-   4+:-   4:-   |2+:-   8:-   8:3   |4+:-   8:3\n",
      "\n",
      "   8:-   8:-   8:-   8:-   |2+:-   8:-   8:-   |4+:-   8:-   8:-   8:-   8:-   8\n",
      "   8:0   8:-   8:-   8:-   |2+:-   8:-   8:-   |4+:-   8:-   8:-   8:-   8:-   8\n",
      "   8:-   8:3   8:0   8:-   |2+:-   8:-   8:-   |4+:-   8:-   8:-   8:-   8:0   8\n",
      "   8:-   8:-   8:-   8:-   |2+:1   8:~   8:-   |4+:1   8:-   8:1   8:3   8:-   8\n",
      "\n",
      ":-   |2+:-   8:-   8:-   |8:2   8:0   8:-   8:-   8:-   8:-   8:-   8:-   |8:-  \n",
      ":0   |2+:-   8:-   8:-   |8:-   8:-   8:3   8:2   8:0   8:-   8:-   8:-   |8:-  \n",
      ":-   |2+:3   8:~   8:-   |8:-   8:-   8:-   8:-   8:-   8:3   8:0   8:-   |8:0  \n",
      ":-   |2+:-   8:-   8:3   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:3   |8:-  \n",
      "\n",
      " 8:-   8:-   8:-   8:-   8:-   8:-   8:-   |4:-   8:-   8:-   8:-   8:-   8:-   \n",
      " 8:-   8:-   8:-   8:-   8:-   8:-   8:-   |4:-   8:-   8:-   8:-   8:-   8:-   \n",
      " 8:0   8:0   8:0   8:0   8:0   8:-   8:0   |4:~   8:0   8:0   8:0   8:0   8:0   \n",
      " 8:-   8:-   8:-   8:-   8:-   8:3   8:-   |4:-   8:-   8:-   8:-   8:-   8:-   \n",
      "\n",
      "8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-   \n",
      "8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-   \n",
      "8:0   |8:1   8:1   8:1   8:1   8:1   8:1   8:1   8:3   |8:~   8:3   8:3   8:3   \n",
      "8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-   \n",
      "\n",
      "8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   \n",
      "8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   \n",
      "8:3   8:1   8:0   8:-   |8:0   8:0   8:0   8:0   8:0   8:0   8:-   8:0   |8:~   \n",
      "8:-   8:-   8:-   8:3   |8:-   8:-   8:-   8:-   8:-   8:-   8:3   8:-   |8:-   \n",
      "\n",
      "8:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8\n",
      "8:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8\n",
      "8:0   8:0   8:0   8:0   8:0   8:0   8:0   |8:1   8:1   8:1   8:1   8:1   8:1   8\n",
      "8:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8\n",
      "\n",
      ":-   8:-   |4:-   4+:-   8:-   8:-   8:-   |2:-   8:-   8:-   8:-   8:-   |8:-  \n",
      ":-   8:-   |4:-   4+:-   8:-   8:-   8:-   |2:0   8:-   8:-   8:-   8:-   |8:-  \n",
      ":1   8:3   |4:~   4+:-   8:0   8:3   8:0   |2:-   8:3   8:0   8:3   8:1   |8:~  \n",
      ":-   8:-   |4:-   4+:-   8:-   8:-   8:-   |2:-   8:-   8:-   8:-   8:-   |8:-  \n",
      "\n",
      " 8:-   4:-   8:-   8:-   8:-   8:-   |4:-   2:-   8:-   8:-   |8:-   8:-   4:-  \n",
      " 8:-   4:-   8:-   8:-   8:-   8:-   |4:-   2:-   8:-   8:-   |8:-   8:-   4:-  \n",
      " 8:1   4:1   8:-   8:-   8:1   8:-   |4:-   2:-   8:-   8:3   |8:~   8:3   4:3  \n",
      " 8:-   4:-   8:1   8:3   8:-   8:-   |4:1   2:1   8:~   8:-   |8:-   8:-   4:-  \n",
      "\n",
      " 8:-   8:-   8:-   8:-   |2:-   8:-   8:-   8:-   8:-   |8:-   8:-   4:-   8:-  \n",
      " 8:-   8:-   8:-   8:-   |2:0   8:-   8:-   8:-   8:-   |8:-   8:-   4:-   8:-  \n",
      " 8:-   8:1   8:3   8:-   |2:-   8:3   8:0   8:3   8:1   |8:~   8:1   4:1   8:-  \n",
      " 8:3   8:-   8:-   8:3   |2:-   8:-   8:-   8:-   8:-   |8:-   8:-   4:-   8:1  \n",
      "\n",
      " 8:-   8:-   8:-   |4:-   2:-   8:-   8:-   |8:-   8:-   4:-   8:-   8:-   8:-  \n",
      " 8:-   8:-   8:-   |4:-   2:-   8:-   8:-   |8:-   8:-   4:-   8:-   8:-   8:-  \n",
      " 8:-   8:1   8:-   |4:-   2:-   8:-   8:3   |8:~   8:3   4:3   8:-   8:1   8:3  \n",
      " 8:3   8:-   8:-   |4:1   2:1   8:~   8:-   |8:-   8:-   4:-   8:3   8:-   8:-  \n",
      "\n",
      " 8:-   |2:-   8:-   8:-   8:-   8:-   |8:-   8:-   4:-   8:-   8:-   8:-   8:-  \n",
      " 8:-   |2:0   8:-   8:-   8:-   8:-   |8:-   8:-   4:-   8:-   8:-   8:-   8:-  \n",
      " 8:-   |2:-   8:3   8:0   8:3   8:1   |8:~   8:1   4:1   8:-   8:-   8:1   8:-  \n",
      " 8:3   |2:-   8:-   8:-   8:-   8:-   |8:-   8:-   4:-   8:1   8:3   8:-   8:-  \n",
      "\n",
      " |4:-   2:-   8:-   8:-   |8:-   8:-   4:-   8:-   8:-   8:-   8:-   |2:-   8:- \n",
      " |4:-   2:-   8:-   8:-   |8:-   8:-   4:-   8:-   8:-   8:-   8:-   |2:0   8:- \n",
      " |4:-   2:-   8:-   8:3   |8:~   8:3   4:3   8:-   8:1   8:3   8:-   |2:-   8:3 \n",
      " |4:1   2:1   8:~   8:-   |8:-   8:-   4:-   8:3   8:-   8:-   8:3   |2:-   8:- \n",
      "\n",
      "  8:-   8:-   8:-   |8:-   8:-   4:-   8:-   8:-   8:-   8:-   |4:-   2:-   8:- \n",
      "  8:-   8:-   8:-   |8:-   8:-   4:-   8:-   8:-   8:-   8:-   |4:-   2:-   8:- \n",
      "  8:0   8:3   8:1   |8:~   8:1   4:1   8:-   8:-   8:1   8:-   |4:-   2:-   8:- \n",
      "  8:-   8:-   8:-   |8:-   8:-   4:-   8:1   8:3   8:-   8:-   |4:1   2:1   8:~ \n",
      "\n",
      "  8:-   |8:-   8:-   2+:-   |4+:7   4+:7   4:7   |8:~   4+:7   4:7   4:7   |4+:7\n",
      "  8:-   |8:-   8:-   2+:-   |4+:-   4+:-   4:-   |8:-   4+:-   4:-   4:-   |4+:-\n",
      "  8:3   |8:~   8:3   2+:-   |4+:-   4+:-   4:-   |8:-   4+:-   4:-   4:-   |4+:-\n",
      "  8:-   |8:-   8:-   2+:-   |4+:-   4+:-   4:-   |8:-   4+:-   4:-   4:-   |4+:-\n",
      "\n",
      "   4+:7   4:7   |8:~   4+:7   4:7   4:7   |4+:7   4+:7   4:7   |8:~   4+:7   4:7\n",
      "   4+:-   4:-   |8:-   4+:-   4:-   4:-   |4+:-   4+:-   4:-   |8:-   4+:-   4:-\n",
      "   4+:-   4:-   |8:-   4+:-   4:-   4:-   |4+:-   4+:-   4:-   |8:-   4+:-   4:-\n",
      "   4+:-   4:-   |8:-   4+:-   4:-   4:-   |4+:-   4+:-   4:-   |8:-   4+:-   4:-\n",
      "\n",
      "   4:7   |4+:7   4+:7   4:7   |8:~   4+:7   4+:7   8:-   |8+:-   16:-   8:-   8:\n",
      "   4:-   |4+:-   4+:-   4:-   |8:-   4+:-   4+:-   8:8   |8+:7   16:-   8:-   8:\n",
      "   4:-   |4+:-   4+:-   4:-   |8:-   4+:-   4+:-   8:-   |8+:-   16:0   8:0   8:\n",
      "   4:-   |4+:-   4+:-   4:-   |8:-   4+:-   4+:-   8:-   |8+:-   16:-   8:-   8:\n",
      "\n",
      "2   8+:0   16:-   8:-   8:-   |8+:-   16:-   8:-   4:-   16:-   16:-   8:-   8:3\n",
      "-   8+:-   16:-   8:-   8:3   |8+:2   16:-   8:-   4:-   16:-   16:-   8:-   8:-\n",
      "-   8+:-   16:0   8:0   8:-   |8+:-   16:0   8:0   4:0   16:~   16:0   8:0   8:-\n",
      "-   8+:-   16:-   8:-   8:-   |8+:-   16:-   8:-   4:-   16:-   16:-   8:-   8:-\n",
      "\n",
      "   |8+:2   16:-   8:-   8:2   8+:0   16:-   8:-   8:-   |8+:-   16:-   8:-   8:-\n",
      "   |8+:-   16:-   8:-   8:-   8+:-   16:-   8:-   8:3   |8+:2   16:-   8:-   8:-\n",
      "   |8+:-   16:0   8:0   8:-   8+:-   16:0   8:0   8:-   |8+:-   16:0   8:0   8:0\n",
      "   |8+:-   16:-   8:-   8:-   8+:-   16:-   8:-   8:-   |8+:-   16:-   8:-   8:-\n",
      "\n",
      "   8+:-   8+:-   8:-   |8+:2   16:-   8:-   8:2   8+:0   16:-   8:-   8:-   |8+:\n",
      "   8+:-   8+:-   8:-   |8+:-   16:-   8:-   8:-   8+:-   16:-   8:-   8:3   |8+:\n",
      "   8+:1   8+:0   8:-   |8+:-   16:0   8:0   8:-   8+:-   16:0   8:0   8:-   |8+:\n",
      "   8+:-   8+:-   8:3   |8+:-   16:-   8:-   8:-   8+:-   16:-   8:-   8:-   |8+:\n",
      "\n",
      "-   16:-   8:-   4:-   16:-   16:-   8:-   8:3   |8+:2   16:-   8:-   8:2   8+:0\n",
      "2   16:-   8:-   4:-   16:-   16:-   8:-   8:-   |8+:-   16:-   8:-   8:-   8+:-\n",
      "-   16:0   8:0   4:0   16:~   16:0   8:0   8:-   |8+:-   16:0   8:0   8:-   8+:-\n",
      "-   16:-   8:-   4:-   16:-   16:-   8:-   8:-   |8+:-   16:-   8:-   8:-   8+:-\n",
      "\n",
      "   16:-   8:-   8:-   |8+:-   16:-   8:-   4:-   8:-   16:-   8+:-   |1:-   |1:-\n",
      "   16:-   8:-   8:3   |8+:2   16:-   8:-   4:-   8:-   16:-   8+:-   |1:-   |1:-\n",
      "   16:0   8:0   8:-   |8+:-   16:0   8:0   4:0   8:0   16:0   8+:0   |1:-   |1:-\n",
      "   16:-   8:-   8:-   |8+:-   16:-   8:-   4:-   8:-   16:-   8+:-   |1:-   |1:-\n",
      "\n",
      "   |1:-   |2:-   8:-   16:-   16:-   8:-   8:3   |8+:2   16:-   8:-   8:2   8+:0\n",
      "   |1:-   |2:-   8:-   16:-   16:-   8:-   8:-   |8+:-   16:-   8:-   8:-   8+:-\n",
      "   |1:-   |2:-   8:-   16:-   16:-   8:0   8:-   |8+:-   16:0   8:0   8:-   8+:-\n",
      "   |1:-   |2:-   8:-   16:1   16:3   8:-   8:-   |8+:-   16:-   8:-   8:-   8+:-\n",
      "\n",
      "   16:-   8:-   8:-   |8+:-   16:-   8:-   4:-   16:-   16:-   8:-   8:3   |8+:2\n",
      "   16:-   8:-   8:3   |8+:2   16:-   8:-   4:-   16:-   16:-   8:-   8:-   |8+:-\n",
      "   16:0   8:0   8:-   |8+:-   16:0   8:0   4:0   16:~   16:0   8:0   8:-   |8+:-\n",
      "   16:-   8:-   8:-   |8+:-   16:-   8:-   4:-   16:-   16:-   8:-   8:-   |8+:-\n",
      "\n",
      "   16:-   8:-   8:2   8+:0   16:-   8:-   8:-   |8+:-   16:-   8:-   8:-   8+:- \n",
      "   16:-   8:-   8:-   8+:-   16:-   8:-   8:3   |8+:2   16:-   8:-   8:-   8+:- \n",
      "   16:0   8:0   8:-   8+:-   16:0   8:0   8:-   |8+:-   16:0   8:0   8:0   8+:1 \n",
      "   16:-   8:-   8:-   8+:-   16:-   8:-   8:-   |8+:-   16:-   8:-   8:-   8+:- \n",
      "\n",
      "  8+:-   8:-   |1:-   |1:-   |8:-   16:-   16:-   16:-   16:-   8:-   16:-   16:\n",
      "  8+:-   8:-   |1:-   |1:-   |8:-   16:0   16:0   16:0   16:0   8:-   16:0   16:\n",
      "  8+:0   8:-   |1:-   |1:-   |8:-   16:-   16:-   16:-   16:-   8:-   16:-   16:\n",
      "  8+:-   8:3   |1:-   |1:-   |8:-   16:-   16:-   16:-   16:-   8:-   16:-   16:\n",
      "\n",
      "-   16:-   16:-   8:-   16:-   16:-   |4:-   4:-   2:-   |8:-   8:-   8:-   8:- \n",
      "0   16:0   16:0   8:-   16:-   16:-   |4:-   4:0   2:-   |8:-   8:-   8:-   8:- \n",
      "-   16:-   16:-   8:-   16:-   16:-   |4:-   4:-   2:-   |8:-   8:-   8:-   8:- \n",
      "-   16:-   16:-   8:-   16:-   16:-   |4:-   4:-   2:-   |8:-   8:0   8:0   8:0 \n",
      "\n",
      "  8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:- \n",
      "  8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:- \n",
      "  8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:- \n",
      "  8:0   8:0   8:0   8:-   |8:-   8:0   8:0   8:0   8:0   8:0   8:0   8:0   |8:0 \n",
      "\n",
      "  8:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-   8:-   8:-  \n",
      "  8:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-   8:-   8:-  \n",
      "  8:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-   8:-   8:-  \n",
      "  8:1   8:1   8:1   8:1   8:1   8:1   8:3   |8:~   8:3   8:3   8:3   8:3   8:3  \n",
      "\n",
      " 8:-   8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8:-  \n",
      " 8:-   8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8:-  \n",
      " 8:-   8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8:-  \n",
      " 8:3   8:3   |8:-   8:0   8:0   8:0   8:0   8:0   8:0   8:-   |8:-   8:0   8:0  \n",
      "\n",
      " 8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   \n",
      " 8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   \n",
      " 8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   \n",
      " 8:0   8:0   8:0   8:0   8:0   |8:0   8:1   8:1   8:1   8:1   8:1   8:1   8:3   \n",
      "\n",
      "|8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-   8:-   \n",
      "|8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-   8:-   \n",
      "|8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-   8:-   \n",
      "|8:~   8:3   8:3   8:3   8:3   8:3   8:3   8:3   |8:-   8:0   8:0   8:0   8:0   \n",
      "\n",
      "8:-   8:-   8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8:-   \n",
      "8:-   8:-   8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8:-   \n",
      "8:-   8:-   8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8:-   \n",
      "8:0   8:0   8:-   |8:-   8:0   8:0   8:0   8:0   8:0   8:0   8:0   |8:0   8:1   \n",
      "\n",
      "8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8\n",
      "8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8\n",
      "8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8\n",
      "8:1   8:1   8:1   8:1   8:1   8:3   |8:~   8:3   8:3   8:3   8:3   8:3   8:3   8\n",
      "\n",
      ":-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-   8\n",
      ":-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-   8\n",
      ":-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-   8\n",
      ":3   |8:-   8:0   8:0   8:0   8:0   8:0   8:0   8:-   |8:-   8:0   8:0   8:0   8\n",
      "\n",
      ":-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   |2:-   2\n",
      ":-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   |2:-   2\n",
      ":-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   |2:-   2\n",
      ":0   8:0   8:0   8:0   |8:0   8:1   8:1   8:1   8:1   8:1   8:1   8:3   |2:~   2\n",
      "\n",
      ":-   |1:-   |1:-   |1:-   |1:-   |1:-   |1:-   |1:-   |1:-   |1:-   |1:-   |1:- \n",
      ":-   |1:-   |1:-   |1:-   |1:-   |1:-   |1:-   |1:-   |1:-   |1:-   |1:-   |1:- \n",
      ":-   |1:-   |1:-   |1:-   |1:-   |1:-   |1:-   |1:-   |1:-   |1:-   |1:-   |1:- \n",
      ":-   |1:-   |1:-   |1:-   |1:-   |1:-   |1:-   |1:-   |1:-   |1:-   |1:-   |1:- \n",
      "\n",
      "  |1:-   |1:-   |1:-   |1:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   |\n",
      "  |1:-   |1:-   |1:-   |1:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   |\n",
      "  |1:-   |1:-   |1:-   |1:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:2   |\n",
      "  |1:-   |1:-   |1:-   |1:-   |8:-   8:3   8:-   8:3   8:-   8:0   8:3   8:-   |\n",
      "\n",
      "2+:-   8:-   8:-   |4+:-   8:-   8:-   8:-   8:-   8:-   |2+:-   8:-   8:-   |4+\n",
      "2+:-   8:-   8:-   |4+:-   8:-   8:-   8:-   8:-   8:-   |2+:-   8:-   8:-   |4+\n",
      "2+:0   8:~   8:-   |4+:0   8:-   8:0   8:-   8:0   8:-   |2+:-   8:-   8:-   |4+\n",
      "2+:-   8:-   8:0   |4+:-   8:0   8:-   8:0   8:-   8:4   |2+:3   8:~   8:-   |4+\n",
      "\n",
      ":-   8:-   8:-   8:-   8:-   8:-   |2+:-   8:-   8:-   |4+:-   8:-   8:-   8:-  \n",
      ":-   8:-   8:-   8:-   8:-   8:-   |2+:-   8:-   8:-   |4+:-   8:-   8:-   8:-  \n",
      ":-   8:-   8:-   8:-   8:0   8:-   |2+:-   8:-   8:-   |4+:-   8:-   8:-   8:-  \n",
      ":3   8:-   8:3   8:-   8:-   8:3   |2+:1   8:~   8:-   |4+:1   8:-   8:1   8:-  \n",
      "\n",
      " 8:-   8:-   |4+:-   8:-   4+:0   8:-   |8:0   4:-   4:-   8:-   4:0   |2+:-   8\n",
      " 8:-   8:-   |4+:-   8:-   4+:-   8:-   |8:-   4:0   4:-   8:-   4:-   |2+:-   8\n",
      " 8:-   8:-   |4+:-   8:-   4+:-   8:-   |8:-   4:-   4:2   8:-   4:-   |2+:0   8\n",
      " 8:1   8:2   |4+:3   8:3   4+:-   8:3   |8:-   4:-   4:-   8:3   4:-   |2+:-   8\n",
      "\n",
      ":-   8:-   |8:2   4:-   4:4   8:2   8:-   8:-   |4+:-   8:-   4:0   16+:~   16:0\n",
      ":-   8:2   |8:-   4:2   4:-   8:-   8:2   8:-   |4+:-   8:-   4:-   16+:-   16:-\n",
      ":~   8:-   |8:-   4:-   4:-   8:-   8:-   8:0   |4+:-   8:-   4:-   16+:-   16:-\n",
      ":-   8:-   |8:-   4:-   4:-   8:-   8:-   8:-   |4+:3   8:3   4:-   16+:-   16:-\n",
      "\n",
      "   16+:2   |8:~   4:0   4:-   8:-   8:-   8:-   |1:-   |2:-   8:-   8:-   8:-   \n",
      "   16+:-   |8:-   4:-   4:2   8:-   8:-   8:-   |1:-   |2:-   8:-   8:-   8:-   \n",
      "   16+:-   |8:-   4:-   4:-   8:-   8:-   8:-   |1:-   |2:-   8:-   8:-   8:-   \n",
      "   16+:-   |8:-   4:-   4:-   8:3   8:-   8:3   |1:1   |2:1   8:~   8:0   8:1   \n",
      "\n",
      "8:-   |4+:-   8:-   4+:0   8:-   |4:0   4:-   4:-   4:-   |4+:-   8:-   4:-   8:\n",
      "8:-   |4+:-   8:-   4+:-   8:0   |4:-   4:0   4:-   4:-   |4+:-   8:-   4:-   8:\n",
      "8:-   |4+:-   8:-   4+:-   8:-   |4:-   4:-   4:2   4:-   |4+:0   8:0   4:0   8:\n",
      "8:2   |4+:3   8:3   4+:-   8:-   |4:-   4:-   4:-   4:3   |4+:-   8:-   4:-   8:\n",
      "\n",
      "-   8:-   |4:-   8:-   8:-   8:-   8:-   8:-   8:-   |4+:-   8:-   4:0   8:0   8\n",
      "-   8:-   |4:-   8:-   8:-   8:-   8:-   8:-   8:-   |4+:-   8:-   4:-   8:-   8\n",
      "-   8:0   |4:~   8:0   8:0   8:0   8:3   8:2   8:0   |4+:-   8:-   4:-   8:-   8\n",
      "0   8:-   |4:-   8:-   8:-   8:-   8:-   8:-   8:-   |4+:3   8:3   4:-   8:-   8\n",
      "\n",
      ":2   |8:~   4:0   4:-   8:-   8:-   8:-   |4:-   8:-   8:-   4:-   8:-   8:-   |\n",
      ":-   |8:-   4:-   4:2   8:0   8:-   8:-   |4:-   8:-   8:-   4:-   8:-   8:-   |\n",
      ":-   |8:-   4:-   4:-   8:-   8:0   8:-   |4:-   8:-   8:-   4:-   8:-   8:-   |\n",
      ":-   |8:-   4:-   4:-   8:-   8:-   8:-   |4:1   8:1   8:1   4:1   8:-   8:1   |\n",
      "\n",
      "4:-   8:-   8:-   8:-   8:-   8:-   8:-   |4+:-   8:-   4+:0   8:-   |4+:0   8:-\n",
      "4:-   8:-   8:-   8:-   8:-   8:-   8:-   |4+:-   8:-   4+:-   8:-   |4+:-   8:-\n",
      "4:-   8:-   8:-   8:-   8:3   8:2   8:0   |4+:-   8:-   4+:-   8:-   |4+:-   8:-\n",
      "4:~   8:1   8:1   8:1   8:-   8:-   8:-   |4+:3   8:3   4+:-   8:3   |4+:-   8:3\n",
      "\n",
      "   8:0   8:-   8:-   8:-   |4+:-   8:-   4:-   8:-   8:-   |4:-   8:-   8:-   8:\n",
      "   8:-   8:-   8:-   8:-   |4+:-   8:-   4:-   8:-   8:-   |4:-   8:-   8:-   8:\n",
      "   8:-   8:-   8:-   8:-   |4+:2   8:2   4:2   8:0   8:2   |4:~   8:2   8:2   8:\n",
      "   8:-   8:3   8:-   8:3   |4+:-   8:-   4:-   8:-   8:-   |4:-   8:-   8:-   8:\n",
      "\n",
      "-   8:-   8:-   8:-   |4+:-   8:-   4:2   8:-   8:4   |8:~   4:2   4:-   8:-   8\n",
      "-   8:0   8:-   8:-   |4+:-   8:2   4:-   8:2   8:-   |8:-   4:-   4:4   8:2   8\n",
      "2   8:-   8:4   8:2   |4+:0   8:-   4:-   8:-   8:-   |8:-   4:-   4:-   8:-   8\n",
      "-   8:-   8:-   8:-   |4+:-   8:-   4:-   8:-   8:-   |8:-   4:-   4:-   8:-   8\n",
      "\n",
      ":-   8:-   |4:-   8:-   8:-   8:-   8:-   8:-   8:-   |4:-   8:-   8:-   8:-   8\n",
      ":0   8:-   |4:-   8:-   8:-   8:-   8:-   8:-   8:-   |4:-   8:-   8:-   8:-   8\n",
      ":-   8:0   |4:-   8:-   8:-   8:-   8:-   8:-   8:-   |4:-   8:-   8:-   8:-   8\n",
      ":-   8:-   |4:3   8:3   8:3   8:3   8:-   8:3   8:3   |4:~   8:3   8:3   8:3   8\n",
      "\n",
      ":-   8:-   8:-   |4+:-   8:-   4+:2   8:-   |4:2   8:-   8:-   8:-   8:-   8:-  \n",
      ":-   8:-   8:-   |4+:-   8:2   4+:-   8:2   |4:-   8:0   8:-   8:-   8:-   8:-  \n",
      ":-   8:-   8:-   |4+:0   8:-   4+:-   8:-   |4:-   8:-   8:4   8:2   8:0   8:-  \n",
      ":-   8:0   8:3   |4+:-   8:-   4+:-   8:-   |4:-   8:-   8:-   8:-   8:-   8:2  \n",
      "\n",
      " 8:-   |1:-   |1:-   |1:-   |1:-   |1:-   |1:-   |2:7   2:5   |1:3   |1:10  |1:9\n",
      " 8:-   |1:-   |1:-   |1:-   |1:-   |1:-   |1:-   |2:-   2:-   |1:-   |1:-   |1:-\n",
      " 8:0   |1:-   |1:-   |1:-   |1:-   |1:-   |1:-   |2:-   2:-   |1:-   |1:-   |1:-\n",
      " 8:-   |1:3   |1:~   |1:2   |1:~   |1:1   |1:~   |2:-   2:-   |1:-   |1:-   |1:-\n",
      "\n",
      "   |2:7   2:5   |1:3   |1:10  |2+:9   8:-   8:-   |2:-   8:-   8:-   8:-   8:-  \n",
      "   |2:-   2:-   |1:-   |1:-   |2+:-   8:-   8:-   |2:0   8:-   8:-   8:-   8:-  \n",
      "   |2:-   2:-   |1:-   |1:-   |2+:-   8:-   8:0   |2:-   8:3   8:0   8:3   8:1  \n",
      "   |2:-   2:-   |1:-   |1:-   |2+:-   8:8   8:-   |2:-   8:-   8:-   8:-   8:-  \n",
      "\n",
      " |8:-   8:-   4:-   8:-   8:-   8:-   8:-   |4:-   4:-   8:-   8:-   8:-   8:-  \n",
      " |8:-   8:-   4:-   8:-   8:-   8:-   8:-   |4:-   4:-   8:-   8:-   8:-   8:-  \n",
      " |8:~   8:1   4:1   8:-   8:-   8:1   8:-   |4:-   4:-   8:-   8:-   8:-   8:3  \n",
      " |8:-   8:-   4:-   8:1   8:3   8:-   8:-   |4:1   4:1   8:1   8:1   8:1   8:-  \n",
      "\n",
      " |8:-   8:-   4:-   8:-   8:-   8:-   8:-   |4+:-   8:-   8:-   8:-   8:-   8:- \n",
      " |8:-   8:-   4:-   8:-   8:-   8:-   8:-   |4+:0   8:~   8:-   8:-   8:-   8:- \n",
      " |8:~   8:3   4:3   8:-   8:1   8:3   8:-   |4+:-   8:-   8:3   8:0   8:3   8:1 \n",
      " |8:-   8:-   4:-   8:3   8:-   8:-   8:3   |4+:-   8:-   8:-   8:-   8:-   8:- \n",
      "\n",
      "  |8:-   8:-   4:-   8:-   8:-   8:-   8:-   |4:-   4:-   8:-   8:-   8:-   8:- \n",
      "  |8:-   8:-   4:-   8:-   8:-   8:-   8:-   |4:-   4:-   8:-   8:-   8:-   8:- \n",
      "  |8:~   8:1   4:1   8:-   8:-   8:1   8:-   |4:-   4:-   8:-   8:-   8:-   8:3 \n",
      "  |8:-   8:-   4:-   8:1   8:3   8:-   8:-   |4:1   4:1   8:1   8:1   8:1   8:- \n",
      "\n",
      "  |8:-   8:-   4:-   8:5   8:0   8:-   8:-   |2:-   8:-   8:-   8:-   8:-   |8:-\n",
      "  |8:-   8:-   4:-   8:-   8:-   8:-   8:-   |2:0   8:-   8:-   8:-   8:-   |8:-\n",
      "  |8:~   8:3   4:3   8:-   8:-   8:3   8:-   |2:-   8:3   8:0   8:3   8:1   |8:~\n",
      "  |8:-   8:-   4:-   8:-   8:-   8:-   8:3   |2:-   8:-   8:-   8:-   8:-   |8:-\n",
      "\n",
      "   8:-   4:-   8:-   8:-   8:-   8:-   |4:-   4:-   8:-   8:-   8:-   8:-   |8:-\n",
      "   8:-   4:-   8:-   8:-   8:-   8:-   |4:-   4:-   8:-   8:-   8:-   8:-   |8:-\n",
      "   8:1   4:1   8:-   8:-   8:1   8:-   |4:-   4:-   8:-   8:-   8:-   8:3   |8:~\n",
      "   8:-   4:-   8:1   8:3   8:-   8:-   |4:1   4:1   8:1   8:1   8:1   8:-   |8:-\n",
      "\n",
      "   8:-   4:-   8:-   8:-   8:-   8:-   |2:-   8:-   8:-   8:-   8:-   |8:-   8:-\n",
      "   8:-   4:-   8:-   8:-   8:-   8:-   |2:0   8:-   8:-   8:-   8:-   |8:-   8:-\n",
      "   8:3   4:3   8:-   8:1   8:3   8:-   |2:-   8:3   8:0   8:3   8:1   |8:~   8:1\n",
      "   8:-   4:-   8:3   8:-   8:-   8:3   |2:-   8:-   8:-   8:-   8:-   |8:-   8:-\n",
      "\n",
      "   4:-   8:-   8:-   8:-   8:-   |4:-   4:-   8:-   8:-   8:-   8:-   |8:-   4+:\n",
      "   4:-   8:-   8:-   8:-   8:-   |4:-   4:-   8:-   8:-   8:-   8:-   |8:-   4+:\n",
      "   4:1   8:-   8:-   8:1   8:-   |4:-   4:-   8:-   8:-   8:-   8:3   |8:~   4+:\n",
      "   4:-   8:1   8:3   8:-   8:-   |4:1   4:1   8:1   8:1   8:1   8:-   |8:-   4+:\n",
      "\n",
      "-   8:-   8+:-   8+:-   |4+:-   2:-   8:-   |4+:-   4:-   8+:-   8+:-   |4+:-   \n",
      "-   8:-   8+:-   8+:-   |4+:-   2:0   8:~   |4+:-   4:-   8+:-   8+:-   |4+:-   \n",
      "3   8:3   8+:-   8+:-   |4+:-   2:-   8:-   |4+:-   4:-   8+:-   8+:-   |4+:3   \n",
      "-   8:-   8+:1   8+:0   |4+:-   2:-   8:-   |4+:-   4:-   8+:1   8+:0   |4+:-   \n",
      "\n",
      "2:5   8:~   |4:6   8:~   4:-   8+:-   8+:-   |4+:-   2:-   8:-   |4+:-   4:-   8\n",
      "2:-   8:-   |4:-   8:-   4:7   8+:-   8+:-   |4+:-   2:0   8:~   |4+:-   4:-   8\n",
      "2:-   8:-   |4:-   8:-   4:-   8+:-   8+:-   |4+:-   2:-   8:-   |4+:-   4:-   8\n",
      "2:-   8:-   |4:-   8:-   4:-   8+:1   8+:0   |4+:-   2:-   8:-   |4+:-   4:-   8\n",
      "\n",
      "+:-   8+:-   |4+:-   2:5   8:~   |4+:6   4:-   8+:-   8+:-   |4+:-   2:-   8:-  \n",
      "+:-   8+:-   |4+:-   2:-   8:-   |4+:-   4:7   8+:-   8+:-   |4+:-   2:0   8:~  \n",
      "+:-   8+:-   |4+:3   2:-   8:-   |4+:-   4:-   8+:-   8+:-   |4+:-   2:-   8:-  \n",
      "+:1   8+:0   |4+:-   2:-   8:-   |4+:-   4:-   8+:1   8+:0   |4+:-   2:-   8:-  \n",
      "\n",
      " |16:-   16:-   16:-   16:-   8:-   4:-   8+:-   8+:-   |4+:-   2:5   8:~   |4+:\n",
      " |16:0   16:0   16:0   16:0   8:0   4:-   8+:-   8+:-   |4+:-   2:-   8:-   |4+:\n",
      " |16:-   16:-   16:-   16:-   8:-   4:-   8+:-   8+:-   |4+:3   2:-   8:-   |4+:\n",
      " |16:-   16:-   16:-   16:-   8:-   4:-   8+:1   8+:0   |4+:-   2:-   8:-   |4+:\n",
      "\n",
      "6   4:-   8+:-   8+:-   |4+:-   2:-   8:-   |16:-   16:-   16:-   16:-   8:-   1\n",
      "-   4:7   8+:-   8+:-   |4+:-   2:0   8:~   |16:0   16:0   16:0   16:0   8:0   1\n",
      "-   4:-   8+:-   8+:-   |4+:-   2:-   8:-   |16:-   16:-   16:-   16:-   8:-   1\n",
      "-   4:-   8+:1   8+:0   |4+:-   2:-   8:-   |16:-   16:-   16:-   16:-   8:-   1\n",
      "\n",
      "6:-   16:-   8:-   8+:-   8+:-   |4+:-   2:5   8:~   |4+:6   4:-   8+:-   8+:-  \n",
      "6:0   16:0   8:0   8+:-   8+:-   |4+:-   2:-   8:-   |4+:-   4:7   8+:-   8+:-  \n",
      "6:-   16:-   8:-   8+:-   8+:-   |4+:3   2:-   8:-   |4+:-   4:-   8+:-   8+:-  \n",
      "6:-   16:-   8:-   8+:1   8+:0   |4+:-   2:-   8:-   |4+:-   4:-   8+:1   8+:0  \n",
      "\n",
      " |4+:-   2:-   8:-   |4+:-   4:-   8+:-   8+:-   |4+:-   2:5   8:~   |4+:6   4:-\n",
      " |4+:-   2:0   8:~   |4+:-   4:-   8+:-   8+:-   |4+:-   2:-   8:-   |4+:-   4:7\n",
      " |4+:-   2:-   8:-   |4+:-   4:-   8+:-   8+:-   |4+:3   2:-   8:-   |4+:-   4:-\n",
      " |4+:-   2:-   8:-   |4+:-   4:-   8+:1   8+:0   |4+:-   2:-   8:-   |4+:-   4:-\n",
      "\n",
      "   8+:-   8+:-   |4+:-   2:-   8:-   |4+:-   4:-   8+:-   8+:-   |4+:-   2:5   8\n",
      "   8+:-   8+:-   |4+:-   2:0   8:~   |4+:-   4:-   8+:-   8+:-   |4+:-   2:-   8\n",
      "   8+:-   8+:-   |4+:-   2:-   8:-   |4+:-   4:-   8+:-   8+:-   |4+:3   2:-   8\n",
      "   8+:1   8+:0   |4+:-   2:-   8:-   |4+:-   4:-   8+:1   8+:0   |4+:-   2:-   8\n",
      "\n",
      ":~   |4+:6   4:-   8+:-   8+:-   |\n",
      ":-   |4+:-   4:7   8+:-   8+:-   |\n",
      ":-   |4+:-   4:-   8+:-   8+:-   |\n",
      ":-   |4+:-   4:-   8+:1   8+:0   |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def pprint_track(track: guitarpro.Track):\n",
    "    lines = ['' for _ in range(N_STRINGS)]\n",
    "\n",
    "    cur_time_sig = None\n",
    "    for mi, measure in enumerate(track.measures):\n",
    "        if measure.timeSignature != cur_time_sig:\n",
    "            cur_time_sig = measure.timeSignature\n",
    "            lines[0] += '  '\n",
    "            lines[1] += f'{cur_time_sig.numerator} '\n",
    "            lines[2] += f'{cur_time_sig.denominator.value} '\n",
    "            lines[3] += '  '\n",
    "\n",
    "        voice = measure.voices[0]  # only the first voice is usually non-empty\n",
    "        for bi, beat in enumerate(voice.beats):\n",
    "            out = f'{beat.duration.value}{\"+\" if beat.duration.isDotted else \"\"}:'\n",
    "            note_by_string = {note.string - 1: note for note in beat.notes}\n",
    "            for s in range(N_STRINGS):\n",
    "                if n := note_by_string.get(s):\n",
    "                    if n.type == guitarpro.NoteType.tie:\n",
    "                        v = '~'\n",
    "                    elif n.type == guitarpro.NoteType.dead:\n",
    "                        v = 'x'\n",
    "                    else:\n",
    "                        v = n.value\n",
    "                else:\n",
    "                    v = '-'\n",
    "                lines[s] += f'{out}{v:<3} '\n",
    "        for s in range(N_STRINGS):\n",
    "            lines[s] += '|'\n",
    "\n",
    "    screen_width = 80\n",
    "    for screen_num in range(0, len(lines[0]), screen_width):\n",
    "        for line in lines:\n",
    "            print(line[screen_num:screen_num+screen_width])\n",
    "        print()\n",
    "\n",
    "path = list(tracks_by_path.keys())[0]\n",
    "track = tracks_by_path[path][0]\n",
    "print(path)\n",
    "print(track.name)\n",
    "pprint_track(track)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Encoding into flat string\n",
    " \n",
    "Now attempting to encode multi-string tabs into a flat string, suitable for training a transformer. In an NLP world, our token would encode all notes that sound at the same time during one beat, along with the beat duration. We would separate beats with a space (like words of text), and separate measures with a \"|\" character (like paragraphs/sentences)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/vlad/googledrive/PlayMusic/tabs/De Palmas/De Palmas - Regarde Moi Bien En Face (2).gp3\n",
      "4.E7 4.E7 4E7 | 8E~ 4.E7 4E7 4E7 | 4.E7 4.E7 4E7 | 8E~ 4.E7 4E7 4E7 | 4.E7 4.E7 4E7 | 8E~ 4.E7 4E7 4E7 | 4.E7 4.E7 4E7 | 8E~ 4.E7 8E7 8.G1 8.G0 | 4. 2A0 8A~ | 4. 4 8.G1 8.G0 | 4D3 8D3 2E5 8E~ | 4.E6 4A7 8.G1 8.G0 | 4. 2A0 8A~ | 4. 4 8.G1 8.G0 | 4D3 8D3 2E5 8E~ | 4.E6 4A7 8.G1 8.G0 | 4. 2A0 8A~ | 4. 4 8.G1 8.G0 | 4D3 8D3 4.E5 4E5 | 4.E6 4A7 8.G1 8.G0 | 4. 2A0 8A~ | 4 8 4 8.G1 8.G0 | 4D3 8D3 4.E5 4E5 | 4.E6 4.A7 4A7 | 4.D8 4D7 8 4D8 | 8D~ 4D7 8 4D8 8E0 8E0 | 1E~ | 1E~ | 2. 8 8D0 | 1A0 | 2.A~ 4 | 2. 8 8D0 | 4.A0 8D0 4A0 4A0 | 2.D3 8D~ 8D3 | 4.D3 8D3 8A0 8D3 8 8G3 | 2.G1 8G~ 8 | 4.G1 8 8G1 8G3 8D0 8A0 | 2.D3 8D~ 8G3 | 8E2 8E0 8A3 8A2 8A0 8D3 8D0 8G3 | 8D0 8D0 8D0 8D0 8D0 8D0 8G3 8D0 | 4D~ 8D0 8D0 8D0 8D0 8D0 8D0 | 8D1 8D1 8D1 8D1 8D1 8D1 8D1 8D3 | 8D~ 8D3 8D3 8D3 8D3 8D1 8D0 8G3 | 8D0 8D0 8D0 8D0 8D0 8D0 8G3 8D0 | 8D~ 8D0 8D0 8D0 8D0 8D0 8D0 8D0 | 8D1 8D1 8D1 8D1 8D1 8D1 8D1 8D3 | 4D~ 2. | 2.D3 8D~ 8G3 | 4.D3 8G3 4D3 8D3 8 | 2.G1 8G~ 8 | 4.G1 8 4G1 8D0 8A0 | 2.D3 8D~ 8G3 | 4.D3 8G3 4A0 8D3 8G3 | 2.D3 8D~ 8G3 | 4.D3 8G3 8A0 8D3 8D0 8 | 2.G1 8G~ 8 | 4.G1 8 8G1 8G3 8D0 8A0 | 2.D3 8D~ 8G3 | 8E2 8E0 8A3 8A2 8A0 8D3 8D0 8G3 | 8D0 8D0 8D0 8D0 8D0 8D0 8G3 8D0 | 4D~ 8D0 8D0 8D0 8D0 8D0 8D0 | 8D1 8D1 8D1 8D1 8D1 8D1 8D1 8D3 | 8D~ 8D3 8D3 8D3 8D3 8D1 8D0 8G3 | 8D0 8D0 8D0 8D0 8D0 8D0 8G3 8D0 | 8D~ 8D0 8D0 8D0 8D0 8D0 8D0 8D0 | 8D1 8D1 8D1 8D1 8D1 8D1 8D1 8D3 | 4D~ 4. 8D0 8D3 8D0 | 2A0 8D3 8D0 8D3 8D1 | 8D~ 8D1 4D1 8G1 8G3 8D1 8 | 4G1 2G1 8G~ 8D3 | 8D~ 8D3 4D3 8G3 8D1 8D3 8G3 | 2A0 8D3 8D0 8D3 8D1 | 8D~ 8D1 4D1 8G1 8G3 8D1 8 | 4G1 2G1 8G~ 8D3 | 8D~ 8D3 4D3 8G3 8D1 8D3 8G3 | 2A0 8D3 8D0 8D3 8D1 | 8D~ 8D1 4D1 8G1 8G3 8D1 8 | 4G1 2G1 8G~ 8D3 | 8D~ 8D3 4D3 8G3 8D1 8D3 8G3 | 2A0 8D3 8D0 8D3 8D1 | 8D~ 8D1 4D1 8G1 8G3 8D1 8 | 4G1 2G1 8G~ 8D3 | 8D~ 8D3 2. | 4.E7 4.E7 4E7 | 8E~ 4.E7 4E7 4E7 | 4.E7 4.E7 4E7 | 8E~ 4.E7 4E7 4E7 | 4.E7 4.E7 4E7 | 8E~ 4.E7 4E7 4E7 | 4.E7 4.E7 4E7 | 8E~ 4.E7 4.E7 8A8 | 8.A7 FD0 8D0 8E2 8.E0 FD0 8D0 8A3 | 8.A2 FD0 8D0 4D0 FD~ FD0 8D0 8E3 | 8.E2 FD0 8D0 8E2 8.E0 FD0 8D0 8A3 | 8.A2 FD0 8D0 8D0 8.D1 8.D0 8G3 | 8.E2 FD0 8D0 8E2 8.E0 FD0 8D0 8A3 | 8.A2 FD0 8D0 4D0 FD~ FD0 8D0 8E3 | 8.E2 FD0 8D0 8E2 8.E0 FD0 8D0 8A3 | 8.A2 FD0 8D0 4D0 8D0 FD0 8.D0 | 2 8 FG1 FG3 8D0 8E3 | 8.E2 FD0 8D0 8E2 8.E0 FD0 8D0 8A3 | 8.A2 FD0 8D0 4D0 FD~ FD0 8D0 8E3 | 8.E2 FD0 8D0 8E2 8.E0 FD0 8D0 8A3 | 8.A2 FD0 8D0 8D0 8.D1 8.D0 8G3 | 8 FA0 FA0 FA0 FA0 8 FA0 FA0 FA0 FA0 8 F F | 4 4A0 2 | 8 8G0 8G0 8G0 8G0 8G0 8G0 8 | 8 8G0 8G0 8G0 8G0 8G0 8G0 8G0 | 8G0 8G1 8G1 8G1 8G1 8G1 8G1 8G3 | 8G~ 8G3 8G3 8G3 8G3 8G3 8G3 8G3 | 8 8G0 8G0 8G0 8G0 8G0 8G0 8 | 8 8G0 8G0 8G0 8G0 8G0 8G0 8G0 | 8G0 8G1 8G1 8G1 8G1 8G1 8G1 8G3 | 8G~ 8G3 8G3 8G3 8G3 8G3 8G3 8G3 | 8 8G0 8G0 8G0 8G0 8G0 8G0 8 | 8 8G0 8G0 8G0 8G0 8G0 8G0 8G0 | 8G0 8G1 8G1 8G1 8G1 8G1 8G1 8G3 | 8G~ 8G3 8G3 8G3 8G3 8G3 8G3 8G3 | 8 8G0 8G0 8G0 8G0 8G0 8G0 8 | 8 8G0 8G0 8G0 8G0 8G0 8G0 8G0 | 8G0 8G1 8G1 8G1 8G1 8G1 8G1 8G3 | 2G~ 2 | 8 8G3 8 8G3 8 8G0 8G3 8D2 | 2.D0 8D~ 8G0 | 4.D0 8G0 8D0 8G0 8D0 8G4 | 2.G3 8G~ 8 | 4.G3 8 8G3 8 8D0 8G3 | 2.G1 8G~ 8 | 4.G1 8 8G1 8 8G1 8G2 | 4.G3 8G3 4.E0 8G3 | 8E0 4A0 4D2 8G3 4E0 | 2.D0 8D~ 8A2 | 8E2 4A2 4E4 8E2 8A2 8D0 | 4.G3 8G3 4E0 F.E~ FE0 F.E2 | 8E~ 4E0 4A2 8G3 8 8G3 | 1G1 | 2G1 8G~ 8G0 8G1 8G2 | 4.G3 8G3 4.E0 8A0 | 4E0 4A0 4D2 4G3 | 4.D0 8D0 4D0 8G0 8D0 | 4D~ 8D0 8D0 8D0 8D3 8D2 8D0 | 4.G3 8G3 4E0 8E0 8E2 | 8E~ 4E0 4A2 8A0 8D0 8 | 4G1 8G1 8G1 4G1 8 8G1 | 4G~ 8G1 8G1 8G1 8D3 8D2 8D0 | 4.G3 8G3 4.E0 8G3 | 4.E0 8G3 8E0 8G3 8 8G3 | 4.D2 8D2 4D2 8D0 8D2 | 4D~ 8D2 8D2 8D2 8A0 8D4 8D2 | 4.D0 8A2 4E2 8A2 8E4 | 8E~ 4E2 4A4 8A2 8A0 8D0 | 4G3 8G3 8G3 8G3 8 8G3 8G3 | 4G~ 8G3 8G3 8G3 8 8G0 8G3 | 4.D0 8A2 4.E2 8A2 | 4E2 8A0 8D4 8D2 8D0 8G2 8D0 | 1G3 | 1G~ | 1G2 | 1G~ | 1G1 | 1G~ | 2E7 2E5 | 1E3 | 1E10 | 1E9 | 2E7 2E5 | 1E3 | 1E10 | 2.E9 8G8 8D0 | 2A0 8D3 8D0 8D3 8D1 | 8D~ 8D1 4D1 8G1 8G3 8D1 8 | 4G1 4G1 8G1 8G1 8G1 8D3 | 8D~ 8D3 4D3 8G3 8D1 8D3 8G3 | 4.A0 8A~ 8D3 8D0 8D3 8D1 | 8D~ 8D1 4D1 8G1 8G3 8D1 8 | 4G1 4G1 8G1 8G1 8G1 8D3 | 8D~ 8D3 4D3 8E5 8E0 8D3 8G3 | 2A0 8D3 8D0 8D3 8D1 | 8D~ 8D1 4D1 8G1 8G3 8D1 8 | 4G1 4G1 8G1 8G1 8G1 8D3 | 8D~ 8D3 4D3 8G3 8D1 8D3 8G3 | 2A0 8D3 8D0 8D3 8D1 | 8D~ 8D1 4D1 8G1 8G3 8D1 8 | 4G1 4G1 8G1 8G1 8G1 8D3 | 8D~ 4.D3 8D3 8.G1 8.G0 | 4. 2A0 8A~ | 4. 4 8.G1 8.G0 | 4.D3 2E5 8E~ | 4E6 8E~ 4A7 8.G1 8.G0 | 4. 2A0 8A~ | 4. 4 8.G1 8.G0 | 4.D3 2E5 8E~ | 4.E6 4A7 8.G1 8.G0 | 4. 2A0 8A~ | FA0 FA0 FA0 FA0 8A0 4 8.G1 8.G0 | 4.D3 2E5 8E~ | 4.E6 4A7 8.G1 8.G0 | 4. 2A0 8A~ | FA0 FA0 FA0 FA0 8A0 FA0 FA0 8A0 8.G1 8.G0 | 4.D3 2E5 8E~ | 4.E6 4A7 8.G1 8.G0 | 4. 2A0 8A~ | 4. 4 8.G1 8.G0 | 4.D3 2E5 8E~ | 4.E6 4A7 8.G1 8.G0 | 4. 2A0 8A~ | 4. 4 8.G1 8.G0 | 4.D3 2E5 8E~ | 4.E6 4A7 8.G1 8.G0 |\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "duration_alphabet = ['1', '2', '4', '8', 'F', 'H', 'G', 'I']\n",
    "strings_alphabet = ['E', 'A', 'D', 'G', 'B', 'e']\n",
    "\n",
    "save_dir = drive_path / 'AI/datasets/gtp_gpt'\n",
    "save_dir.mkdir(exist_ok=True)\n",
    "\n",
    "def encode_track(track):\n",
    "    out = []\n",
    "    \n",
    "    for mi, measure in enumerate(track.measures):\n",
    "        beats = measure.voices[0].beats\n",
    "        if not any(len(b.notes) > 0 for b in beats):\n",
    "            continue\n",
    "        \n",
    "        for bi, beat in enumerate(beats):\n",
    "            s = duration_alphabet[int(math.log2(beat.duration.value))]\n",
    "            if beat.duration.isDotted:\n",
    "                s += '.'\n",
    "            \n",
    "            if beat.notes:\n",
    "                notes = []\n",
    "                for n in beat.notes:\n",
    "                    if n.type == guitarpro.NoteType.tie:\n",
    "                        v = '~'\n",
    "                    elif n.type == guitarpro.NoteType.dead:\n",
    "                        v = 'x'\n",
    "                    else:\n",
    "                        v = n.value\n",
    "                    notes.append(f'{strings_alphabet[n.string - 1]}{v}')\n",
    "                s += \"\".join(notes)\n",
    "            out.append(s)\n",
    "        out.append('|')\n",
    "    return out\n",
    "\n",
    "for path, tracks in tracks_by_path.items():\n",
    "    out_path = save_dir / (path.name + '-bass.txt')\n",
    "    if out_path.exists():\n",
    "        continue\n",
    "\n",
    "    enc_tracks = [encode_track(t) for t in tracks]\n",
    "    with out_path.open('w') as f:\n",
    "        for t in enc_tracks:\n",
    "            f.write(' '.join(t) + '\\n')\n",
    "\n",
    "encoded = encode_track(track)\n",
    "print(path)\n",
    "print(' '.join(encoded))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Decode into human-readable tab\n",
    "\n",
    "Decoding back into human-readable tab to verify correctness."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2:-   2:3   |2:2   2:5   |2:1   2:1   |2:0   2:0   |2:0   2:3   |2:2   2:5   |2:\n",
      "2:5   2:-   |2:-   2:3   |2:-   2:0   |2:1   2:-   |2:1   2:1   |2:-   2:3   |2:\n",
      "2:5   2:5   |2:2   2:-   |2:2   2:-   |2:-   2:-   |2:-   2:-   |2:2   2:-   |2:\n",
      "2:-   2:-   |2:-   2:-   |2:-   2:-   |2:-   2:-   |2:-   2:-   |2:-   2:-   |2:\n",
      "\n",
      "1   2:1   |2:0   2:0   |2:0   2:0   |2:0   2:0   |2:0   2:0   |2:0   2:0   |2:0 \n",
      "-   2:0   |2:1   2:-   |2:1   2:1   |2:0   2:0   |2:-   2:-   |2:-   2:-   |2:1 \n",
      "2   2:-   |2:-   2:-   |2:-   2:-   |2:-   2:-   |2:2   2:2   |2:1   2:1   |2:- \n",
      "-   2:-   |2:-   2:-   |2:-   2:-   |2:-   2:-   |2:-   2:-   |2:-   2:-   |2:- \n",
      "\n",
      "  2:3   |2:2   2:5   |2:1   2:1   |2:0   2:0   |4:0   4:0   4:1   4:0   |4:-   8\n",
      "  2:1   |2:-   2:3   |2:-   2:0   |2:1   2:-   |4:-   4:-   4:-   4:-   |4:3   8\n",
      "  2:-   |2:2   2:-   |2:2   2:-   |2:-   2:-   |4:-   4:-   4:-   4:-   |4:-   8\n",
      "  2:-   |2:-   2:-   |2:-   2:-   |2:-   2:-   |4:-   4:-   4:-   4:-   |4:-   8\n",
      "\n",
      ":-   2:-   |4:-   4:-   4:-   4:-   |1:-   |2:0   2:3   |2:2   2:5   |2:1   2:1 \n",
      ":-   2:3   |4:1   4:0   4:-   4:0   |1:1   |2:1   2:1   |2:-   2:3   |2:-   2:0 \n",
      ":2   2:-   |4:-   4:-   4:2   4:-   |1:-   |2:-   2:-   |2:2   2:-   |2:2   2:- \n",
      ":-   2:-   |4:-   4:-   4:-   4:-   |1:-   |2:-   2:-   |2:-   2:-   |2:-   2:- \n",
      "\n",
      "  |2:0   2:0   |2:0   2:3   |2:2   2:5   |2:1   2:1   |2:0   2:0   |2:0   2:0   \n",
      "  |2:1   2:-   |2:1   2:1   |2:-   2:3   |2:-   2:0   |2:1   2:-   |2:1   2:1   \n",
      "  |2:-   2:-   |2:-   2:-   |2:2   2:-   |2:2   2:-   |2:-   2:-   |2:-   2:-   \n",
      "  |2:-   2:-   |2:-   2:-   |2:-   2:-   |2:-   2:-   |2:-   2:-   |2:-   2:-   \n",
      "\n",
      "|2:0   2:0   |2:0   2:0   |2:0   2:0   |2:0   2:3   |2:2   2:5   |2:1   2:1   |2\n",
      "|2:0   2:0   |2:-   2:-   |2:-   2:-   |2:1   2:1   |2:-   2:3   |2:-   2:0   |2\n",
      "|2:-   2:-   |2:2   2:2   |2:1   2:1   |2:-   2:-   |2:2   2:-   |2:2   2:-   |2\n",
      "|2:-   2:-   |2:-   2:-   |2:-   2:-   |2:-   2:-   |2:-   2:-   |2:-   2:-   |2\n",
      "\n",
      ":0   2:0   |4:0   4:0   4:1   4:0   |4:-   8:-   2:-   |4:-   4:-   4:-   4:-   \n",
      ":1   2:-   |4:-   4:-   4:-   4:-   |4:3   8:-   2:3   |4:1   4:0   4:-   4:0   \n",
      ":-   2:-   |4:-   4:-   4:-   4:-   |4:-   8:2   2:-   |4:-   4:-   4:2   4:-   \n",
      ":-   2:-   |4:-   4:-   4:-   4:-   |4:-   8:-   2:-   |4:-   4:-   4:-   4:-   \n",
      "\n",
      "|1:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-  \n",
      "|1:1   |8:-   8:-   8:-   8:1   8:-   8:-   8:-   8:1   |8:-   8:-   8:-   8:3  \n",
      "|1:-   |8:-   8:-   8:0   8:-   8:-   8:-   8:0   8:-   |8:-   8:-   8:-   8:-  \n",
      "|1:-   |8:-   8:2   8:-   8:-   8:-   8:2   8:-   8:-   |8:-   8:0   8:4   8:-  \n",
      "\n",
      " 8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-  \n",
      " 8:-   8:-   8:-   8:3   |8:-   8:-   8:-   8:1   8:-   8:-   8:-   8:3   |8:-  \n",
      " 8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-  \n",
      " 8:-   8:0   8:4   8:-   |8:-   8:0   8:3   8:-   8:-   8:0   8:3   8:-   |8:-  \n",
      "\n",
      " 8:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-   8:-   8:-   \n",
      " 8:-   8:-   8:1   8:-   8:-   8:-   8:1   |8:-   8:-   8:-   8:1   8:-   8:-   \n",
      " 8:-   8:0   8:-   8:-   8:-   8:0   8:-   |8:-   8:-   8:0   8:-   8:-   8:-   \n",
      " 8:2   8:-   8:-   8:-   8:2   8:-   8:-   |8:-   8:2   8:-   8:-   8:-   8:2   \n",
      "\n",
      "8:-   8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8:-   \n",
      "8:-   8:1   |8:-   8:-   8:-   8:3   8:-   8:-   8:-   8:3   |8:-   8:-   8:-   \n",
      "8:0   8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8:-   \n",
      "8:-   8:-   |8:-   8:0   8:4   8:-   8:-   8:0   8:4   8:-   |8:-   8:0   8:3   \n",
      "\n",
      "8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:0   |\n",
      "8:1   8:-   8:-   8:-   8:3   |8:-   8:-   8:-   8:1   8:-   8:-   8:-   8:-   |\n",
      "8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8:0   8:-   8:-   8:-   8:0   8:-   |\n",
      "8:-   8:-   8:0   8:3   8:-   |8:-   8:2   8:-   8:-   8:-   8:2   8:-   8:-   |\n",
      "\n",
      "8:-   8:-   8:-   8:0   8:-   8:-   8:-   8:0   |8:-   8:-   8:-   8:0   8:-   8\n",
      "8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-   8:-   8\n",
      "8:-   8:-   8:0   8:-   8:-   8:-   8:0   8:-   |8:-   8:-   8:1   8:-   8:-   8\n",
      "8:-   8:2   8:-   8:-   8:-   8:2   8:-   8:-   |8:-   8:2   8:-   8:-   8:-   8\n",
      "\n",
      ":-   8:-   8:0   |8:-   8:-   8:-   8:0   8:-   8:-   8:-   8:0   |8:-   8:-   8\n",
      ":-   8:-   8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8\n",
      ":-   8:1   8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8\n",
      ":2   8:-   8:-   |8:-   8:-   8:2   8:-   8:-   8:-   8:2   8:-   |8:-   8:2   8\n",
      "\n",
      ":-   8:0   8:-   8:-   8:-   8:0   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:\n",
      ":-   8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:1   8:-   8:-   8:-   8:\n",
      ":1   8:-   8:-   8:-   8:1   8:-   |8:-   8:-   8:0   8:-   8:-   8:-   8:0   8:\n",
      ":-   8:-   8:-   8:2   8:-   8:-   |8:-   8:2   8:-   8:-   8:-   8:2   8:-   8:\n",
      "\n",
      "-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-   8:\n",
      "1   |8:-   8:-   8:-   8:3   8:-   8:-   8:-   8:3   |8:-   8:-   8:-   8:1   8:\n",
      "-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-   8:\n",
      "-   |8:-   8:0   8:4   8:-   8:-   8:0   8:4   8:-   |8:-   8:0   8:3   8:-   8:\n",
      "\n",
      "-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8:\n",
      "-   8:-   8:-   8:3   |8:-   8:-   8:-   8:1   8:-   8:-   8:-   8:1   |8:-   8:\n",
      "-   8:-   8:-   8:-   |8:-   8:-   8:0   8:-   8:-   8:-   8:0   8:-   |8:-   8:\n",
      "-   8:0   8:3   8:-   |8:-   8:2   8:-   8:-   8:-   8:2   8:-   8:-   |8:-   8:\n",
      "\n",
      "-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-\n",
      "-   8:-   8:1   8:-   8:-   8:-   8:1   |8:-   8:-   8:-   8:3   8:-   8:-   8:-\n",
      "-   8:0   8:-   8:-   8:-   8:0   8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-\n",
      "2   8:-   8:-   8:-   8:2   8:-   8:-   |8:-   8:0   8:4   8:-   8:-   8:0   8:4\n",
      "\n",
      "   8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8:-   8:-\n",
      "   8:3   |8:-   8:-   8:-   8:1   8:-   8:-   8:-   8:3   |8:-   8:-   8:-   8:1\n",
      "   8:-   |8:-   8:-   8:-   8:-   8:-   8:-   8:-   8:-   |8:-   8:-   8:0   8:-\n",
      "   8:-   |8:-   8:0   8:3   8:-   8:-   8:0   8:3   8:-   |8:-   8:2   8:-   8:-\n",
      "\n",
      "   2:3   |4:~   2:-   4:-   ||\n",
      "   2:1   |4:~   2:-   4:-   ||\n",
      "   2:-   |4:-   2:-   4:-   ||\n",
      "   2:-   |4:-   2:-   4:-   ||\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def decode_and_print(encoded: list[str]):\n",
    "    decoded_by_string = defaultdict(str)\n",
    "\n",
    "    for measure in ' '.join(encoded).strip().split('|'):\n",
    "        for beat in measure.strip().split(' '):\n",
    "            if not beat:\n",
    "                continue\n",
    "\n",
    "            i = 0\n",
    "            duration = str(2 ** duration_alphabet.index(beat[i]))\n",
    "            i += 1\n",
    "            \n",
    "            if i < len(beat) and beat[i] == '·':\n",
    "                duration += '·'\n",
    "                i += 1\n",
    "    \n",
    "            for si in range(N_STRINGS):\n",
    "                decoded_by_string[si] += f'{duration}:'\n",
    "             \n",
    "            note_by_string = {}\n",
    "            cur_string, cur_note = None, ''\n",
    "            while i < len(beat):\n",
    "                if beat[i] in strings_alphabet:\n",
    "                    if cur_string is not None:\n",
    "                        note_by_string[cur_string] = cur_note\n",
    "                    cur_string = strings_alphabet.index(beat[i])\n",
    "                    cur_note = ''\n",
    "                else:\n",
    "                    cur_note += beat[i]\n",
    "                i += 1\n",
    "            \n",
    "            if cur_string is not None:\n",
    "                note_by_string[cur_string] = cur_note\n",
    "            \n",
    "            for si in range(N_STRINGS):\n",
    "                if si in note_by_string:\n",
    "                    decoded_by_string[si] += f'{note_by_string[si]:<3}'\n",
    "                else:\n",
    "                    decoded_by_string[si] += f'{\"-\":<3}'\n",
    "                decoded_by_string[si] += ' '\n",
    "    \n",
    "        for si in range(N_STRINGS):\n",
    "            decoded_by_string[si] += '|'\n",
    "    \n",
    "    screen_width = 80\n",
    "    for screen_num in range(0, len(decoded_by_string[0]), screen_width):\n",
    "        for line in decoded_by_string.values():\n",
    "            print(line[screen_num:screen_num+screen_width])\n",
    "        print()\n",
    "        \n",
    "decode_and_print(encoded)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Prepare dataset\n",
    "\n",
    "First, we concatenate all encoded tracks in one file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12067/12067 [00:23<00:00, 516.01it/s]\n"
     ]
    }
   ],
   "source": [
    "concat_text_path = drive_path / 'AI/datasets/gtp_gpt/concat.txt'\n",
    "\n",
    "paths = list((drive_path / 'AI/datasets/gtp_gpt').iterdir())\n",
    "with open(concat_text_path, 'w') as f:\n",
    "    for path in tqdm(paths):\n",
    "        if path.is_file():\n",
    "            with open(path, 'r') as f2:\n",
    "                f.write(f2.read() + '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Tokenizing\n",
    "\n",
    "The choice of tokenizer is not important here, so just arbitrary picking SentencePieceBPETokenizer. We might consider building a more music-specified custom tokenizer, but trusting transformers to figure out the song structure on their own. Interesting to see if it will figure out proper time signatures.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tracks: 17\n",
      "\n",
      "\n",
      "\n",
      "Tokenizer vocab (277 tokens):\n",
      "[('<s>', 0),\n",
      " ('<unk>', 1),\n",
      " ('.', 2),\n",
      " ('0', 3),\n",
      " ('1', 4),\n",
      " ('2', 5),\n",
      " ('3', 6),\n",
      " ('4', 7),\n",
      " ('5', 8),\n",
      " ('6', 9),\n",
      " ('7', 10),\n",
      " ('8', 11),\n",
      " ('9', 12),\n",
      " ('A', 13),\n",
      " ('D', 14),\n",
      " ('E', 15),\n",
      " ('F', 16),\n",
      " ('G', 17),\n",
      " ('H', 18),\n",
      " ('x', 19),\n",
      " ('|', 20),\n",
      " ('~', 21),\n",
      " ('▁', 22),\n",
      " ('▁8', 23),\n",
      " ('▁|', 24),\n",
      " ('▁4', 25),\n",
      " ('▁F', 26),\n",
      " ('▁8D', 27),\n",
      " ('▁2', 28),\n",
      " ('▁8G', 29),\n",
      " ('▁FD', 30),\n",
      " ('▁4D', 31),\n",
      " ('▁4G', 32),\n",
      " ('▁FG', 33),\n",
      " ('▁8D0', 34),\n",
      " ('▁4.', 35),\n",
      " ('▁8A', 36),\n",
      " ('▁8D2', 37),\n",
      " ('▁8.', 38),\n",
      " ('▁8D4', 39),\n",
      " ('▁8E', 40),\n",
      " ('▁FA', 41),\n",
      " ('▁2D', 42),\n",
      " ('▁1', 43),\n",
      " ('▁FD0', 44),\n",
      " ('▁2G', 45),\n",
      " ('▁FG0', 46),\n",
      " ('▁8D1', 47),\n",
      " ('▁2E', 48),\n",
      " ('▁8G3', 49),\n",
      " ('▁4D3', 50),\n",
      " ('▁4G1', 51),\n",
      " ('▁8D3', 52),\n",
      " ('▁8G0', 53),\n",
      " ('▁4A', 54),\n",
      " ('▁8D7', 55),\n",
      " ('▁1G', 56),\n",
      " ('▁8G4', 57),\n",
      " ('▁FD2', 58),\n",
      " ('▁4D0', 59),\n",
      " ('▁FD1', 60),\n",
      " ('▁4E', 61),\n",
      " ('▁FA0', 62),\n",
      " ('▁4.D', 63),\n",
      " ('▁4.G', 64),\n",
      " ('▁2A', 65),\n",
      " ('▁2D0', 66),\n",
      " ('▁FA1', 67),\n",
      " ('▁FD4', 68),\n",
      " ('▁8G1', 69),\n",
      " ('▁4A0', 70),\n",
      " ('▁4G3', 71),\n",
      " ('▁4.E', 72),\n",
      " ('▁1D', 73),\n",
      " ('▁8.G', 74),\n",
      " ('▁8A1', 75),\n",
      " ('▁8A3', 76),\n",
      " ('▁8D5', 77),\n",
      " ('▁2.', 78),\n",
      " ('▁2E5', 79),\n",
      " ('▁8D~', 80),\n",
      " ('▁8A0', 81),\n",
      " ('▁4D1', 82),\n",
      " ('▁8E5', 83),\n",
      " ('▁8D6', 84),\n",
      " ('▁4D7', 85),\n",
      " ('▁FG1', 86),\n",
      " ('▁8G5', 87),\n",
      " ('▁4D5', 88),\n",
      " ('▁4G2', 89),\n",
      " ('▁2G3', 90),\n",
      " ('▁4G5', 91),\n",
      " ('▁8G~', 92),\n",
      " ('▁4G0', 93),\n",
      " ('▁2G0', 94),\n",
      " ('▁8G6', 95),\n",
      " ('▁8E0', 96),\n",
      " ('▁FG~', 97),\n",
      " ('▁8A2', 98),\n",
      " ('▁4D2', 99),\n",
      " ('▁8E~', 100),\n",
      " ('▁4G4', 101),\n",
      " ('▁8.G1', 102),\n",
      " ('▁2D2', 103),\n",
      " ('▁2D5', 104),\n",
      " ('▁FE', 105),\n",
      " ('▁FD3', 106),\n",
      " ('▁4D4', 107),\n",
      " ('▁4.E7', 108),\n",
      " ('▁2A0', 109),\n",
      " ('▁FG3', 110),\n",
      " ('▁1D0', 111),\n",
      " ('▁8.G0', 112),\n",
      " ('▁4E7', 113),\n",
      " ('▁FG4', 114),\n",
      " ('▁8A~', 115),\n",
      " ('▁1G0', 116),\n",
      " ('▁2.G', 117),\n",
      " ('▁8G2', 118),\n",
      " ('▁2G5', 119),\n",
      " ('▁1G5', 120),\n",
      " ('▁H', 121),\n",
      " ('▁8.E', 122),\n",
      " ('▁8E2', 123),\n",
      " ('▁2D3', 124),\n",
      " ('▁4.D5', 125),\n",
      " ('▁2G4', 126),\n",
      " ('▁4.D3', 127),\n",
      " ('▁4.G1', 128),\n",
      " ('13', 129),\n",
      " ('▁8E7', 130),\n",
      " ('▁2G1', 131),\n",
      " ('▁1G7', 132),\n",
      " ('▁2A7', 133),\n",
      " ('▁FD~', 134),\n",
      " ('▁2E0', 135),\n",
      " ('▁1G4', 136),\n",
      " ('▁4.G3', 137),\n",
      " ('▁4.G~', 138),\n",
      " ('▁2.D', 139),\n",
      " ('▁FE2', 140),\n",
      " ('E~', 141),\n",
      " ('▁4D~', 142),\n",
      " ('▁2E2', 143),\n",
      " ('10', 144),\n",
      " ('▁4E5', 145),\n",
      " ('▁8G8', 146),\n",
      " ('▁FD6', 147),\n",
      " ('▁FG6', 148),\n",
      " ('▁8A7', 149),\n",
      " ('▁FA3', 150),\n",
      " ('▁2E9', 151),\n",
      " ('▁4A2', 152),\n",
      " ('▁4A7', 153),\n",
      " ('▁2A3', 154),\n",
      " ('▁4.E6', 155),\n",
      " ('▁1D~', 156),\n",
      " ('▁8.A', 157),\n",
      " ('▁1D5', 158),\n",
      " ('▁4.A', 159),\n",
      " ('▁8.D', 160),\n",
      " ('▁FA2', 161),\n",
      " ('▁2D~', 162),\n",
      " ('▁2G2', 163),\n",
      " ('▁2E~', 164),\n",
      " ('▁4.D0', 165),\n",
      " ('▁4.D1', 166),\n",
      " ('▁2A~', 167),\n",
      " ('▁8D8', 168),\n",
      " ('▁FG2', 169),\n",
      " ('▁FG5', 170),\n",
      " ('▁1E', 171),\n",
      " ('▁2E7', 172),\n",
      " ('▁FE~', 173),\n",
      " ('15', 174),\n",
      " ('▁8A9', 175),\n",
      " ('▁2E1', 176),\n",
      " ('▁2E4', 177),\n",
      " ('▁4E0', 178),\n",
      " ('▁4.G4', 179),\n",
      " ('▁4.E8', 180),\n",
      " ('▁2.G2', 181),\n",
      " ('▁HE~', 182),\n",
      " ('▁8.E0', 183),\n",
      " ('▁2.D3', 184),\n",
      " ('▁8.A2', 185),\n",
      " ('▁F.', 186),\n",
      " ('▁FD7', 187),\n",
      " ('▁4D8', 188),\n",
      " ('▁8E3', 189),\n",
      " ('▁8E4', 190),\n",
      " ('▁FA4', 191),\n",
      " ('▁FA6', 192),\n",
      " ('▁2D4', 193),\n",
      " ('▁1A', 194),\n",
      " ('▁2G6', 195),\n",
      " ('▁1G2', 196),\n",
      " ('▁4E13', 197),\n",
      " ('▁4.D~', 198),\n",
      " ('▁4.G6', 199),\n",
      " ('▁4.G7', 200),\n",
      " ('▁2.G5', 201),\n",
      " ('▁8.E2', 202),\n",
      " ('▁8.D1', 203),\n",
      " ('▁8D9', 204),\n",
      " ('▁4D9', 205),\n",
      " ('▁8A4', 206),\n",
      " ('▁8A8', 207),\n",
      " ('▁8E8', 208),\n",
      " ('▁2D8', 209),\n",
      " ('▁4A8', 210),\n",
      " ('▁4A13', 211),\n",
      " ('▁4E6', 212),\n",
      " ('▁4.D4', 213),\n",
      " ('▁4.E0', 214),\n",
      " ('▁1D1', 215),\n",
      " ('▁2.G1', 216),\n",
      " ('▁F.E~', 217),\n",
      " ('▁1A0', 218),\n",
      " ('12', 219),\n",
      " ('17', 220),\n",
      " ('▁8G9', 221),\n",
      " ('▁FD5', 222),\n",
      " ('▁4D6', 223),\n",
      " ('▁2D7', 224),\n",
      " ('▁2G7', 225),\n",
      " ('▁2G~', 226),\n",
      " ('▁8D11', 227),\n",
      " ('▁2E8', 228),\n",
      " ('▁2E10', 229),\n",
      " ('▁4A5', 230),\n",
      " ('▁1G1', 231),\n",
      " ('▁1G~', 232),\n",
      " ('▁4E2', 233),\n",
      " ('▁4E8', 234),\n",
      " ('▁4E12', 235),\n",
      " ('▁4.E5', 236),\n",
      " ('▁2.E', 237),\n",
      " ('▁FE5', 238),\n",
      " ('▁2.G4', 239),\n",
      " ('▁4.G10', 240),\n",
      " ('▁2.D0', 241),\n",
      " ('▁2.D5', 242),\n",
      " ('▁8.D0', 243),\n",
      " ('▁1D14', 244),\n",
      " ('A~', 245),\n",
      " ('▁FD9', 246),\n",
      " ('▁4G~', 247),\n",
      " ('▁FG7', 248),\n",
      " ('▁8E6', 249),\n",
      " ('▁8E13', 250),\n",
      " ('▁8E15', 251),\n",
      " ('▁1E~', 252),\n",
      " ('▁2G9', 253),\n",
      " ('▁4A10', 254),\n",
      " ('▁1G3', 255),\n",
      " ('▁1G8', 256),\n",
      " ('▁FD11', 257),\n",
      " ('▁4E9', 258),\n",
      " ('▁4.G2', 259),\n",
      " ('▁2A5', 260),\n",
      " ('▁FA10', 261),\n",
      " ('▁4.E17', 262),\n",
      " ('▁1D2', 263),\n",
      " ('▁1D3', 264),\n",
      " ('▁8.G5', 265),\n",
      " ('▁FE0', 266),\n",
      " ('▁2.G3', 267),\n",
      " ('▁8.E13', 268),\n",
      " ('▁4.A0', 269),\n",
      " ('▁4.A6', 270),\n",
      " ('▁4.A7', 271),\n",
      " ('▁1E2', 272),\n",
      " ('▁1E3', 273),\n",
      " ('▁1E10', 274),\n",
      " ('▁8.D11', 275),\n",
      " ('▁2.E3', 276)]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "import itertools\n",
    "from torch.utils.data import random_split, TensorDataset\n",
    "from tokenizers.implementations import SentencePieceBPETokenizer\n",
    "\n",
    "print(f'Total tracks: {len(tracks_by_path)}')\n",
    "tracks = list(itertools.chain.from_iterable(tracks_by_path.values()))\n",
    "\n",
    "tokenizer = SentencePieceBPETokenizer()\n",
    "vocab_size = 50_000\n",
    "with concat_text_path.open() as f:\n",
    "    tokenizer.train_from_iterator(\n",
    "        (line.strip() for line in f), \n",
    "        vocab_size=vocab_size, \n",
    "        special_tokens=['<s>', '<unk>']\n",
    "    )\n",
    "print(f'Tokenizer vocab ({tokenizer.get_vocab_size()} tokens):')\n",
    "pprint.pprint(sorted(tokenizer.get_vocab().items(), key=lambda kv: kv[1])[:1000])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[183, 96, 194, 9] ['▁8.E0', '▁8E0', '▁1A', '6']\n"
     ]
    }
   ],
   "source": [
    "t = \"8.E0 8E0 1A6\"\n",
    "print(tokenizer.encode(t).ids, tokenizer.encode(t).tokens)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Initialising a model\n",
    "\n",
    "A smaller version of GPT2 for now."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.random.manual_seed(42)\n",
    "torch.cuda.random.manual_seed(42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "GPT2LMHeadModel(\n  (transformer): GPT2Model(\n    (wte): Embedding(277, 96)\n    (wpe): Embedding(120, 96)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0): GPT2Block(\n        (ln_1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (1): GPT2Block(\n        (ln_1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (2): GPT2Block(\n        (ln_1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (3): GPT2Block(\n        (ln_1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (4): GPT2Block(\n        (ln_1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (5): GPT2Block(\n        (ln_1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=96, out_features=277, bias=False)\n)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Config\n",
    "\n",
    "config = GPT2Config(\n",
    "    bos_token_id=0,\n",
    "    eos_token_id=0,\n",
    "    vocab_size=tokenizer.get_vocab_size(),\n",
    "    n_positions=120,  # 1024\n",
    "    n_embd=96,        # 768,\n",
    "    n_layer=6,        # 12,\n",
    "    n_head=6,         # 12,\n",
    ")\n",
    "\n",
    "model = GPT2LMHeadModel(config)\n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Building a dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    83699  35131828 130807398 /Users/vlad/googledrive/AI/gtp_gpt/encoded/concat.txt\r\n"
     ]
    }
   ],
   "source": [
    "!wc {concat_text_path}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating examples from dataset file /Users/vlad/googledrive/AI/gtp_gpt/encoded/concat.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 368.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 481085\n",
      "Train size: 480085\n",
      "Test size: 1000\n"
     ]
    }
   ],
   "source": [
    "class Dataset(TensorDataset):\n",
    "    def __init__(self, file_path: Path, block_size: int):\n",
    "        self.block_size = block_size\n",
    "        \n",
    "        cache_path = file_path.with_name(file_path.name + '.pt')\n",
    "        if cache_path.exists():\n",
    "            self.data = torch.load(str(cache_path))\n",
    "            print(f\"Loading data from cache {cache_path}\")\n",
    "            return\n",
    "    \n",
    "        print(f\"Creating examples from dataset file {file_path}\")\n",
    "        with open(file_path, encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "        ids = [0]\n",
    "        for line in tqdm(lines):\n",
    "            if line := line.strip():\n",
    "                ids.extend(tokenizer.encode(line).ids + [0])\n",
    "        super().__init__(torch.LongTensor(ids))\n",
    "\n",
    "        test_n = min(1000, int(len(self) * 0.1))\n",
    "        self.train, self.test = random_split(self, [len(self) - test_n, test_n])\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        t = torch.LongTensor(self.tensors[0][idx:idx + self.block_size])\n",
    "        return {\"input_ids\": t, \"labels\": t}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tensors[0]) - self.block_size + 1\n",
    "\n",
    "ds = Dataset(concat_text_path, block_size=config.n_positions)\n",
    "print(f'Dataset size: {len(ds)}')\n",
    "print(f'Train size: {len(ds.train)}')\n",
    "print(f'Test size: {len(ds.test)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Sampling\n",
    "\n",
    "We would sample and also immediately decode our string into a more human-readable tab format."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 FA1 8E6 8E6 1G3 2E0 1 1G7 8G2 8G57 FE2 2G5\n",
      "16:-   8:6   8:6   1:-   2:0   1:-   1:-   8:-   8:-   16:2   2:-   |\n",
      "16:1   8:-   8:-   1:-   2:-   1:-   1:-   8:-   8:-   16:-   2:-   |\n",
      "16:-   8:-   8:-   1:-   2:-   1:-   1:-   8:-   8:-   16:-   2:-   |\n",
      "16:-   8:-   8:-   1:3   2:-   1:-   1:7   8:2   8:57  16:-   2:5   |\n",
      "\n",
      "2 4.D5 8.G5 4E8 4 4.EG 8A3 4.D4 2G0 FE 4D2 2.D\n",
      "4:-   8:-   4:8   4:-   4:    8:-   4:-   2:-   16:    4:-   2:-   |\n",
      "4:-   8:-   4:-   4:-   4:-   8:3   4:-   2:-   16:-   4:-   2:-   |\n",
      "4:5   8:-   4:-   4:-   4:-   8:-   4:4   2:-   16:-   4:2   2:    |\n",
      "4:-   8:5   4:-   4:-   4:    8:-   4:-   2:0   16:-   4:-   2:-   |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def sample(num_seqs=1, max_length=13):\n",
    "    torch.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    for i, seq in enumerate(model.generate(\n",
    "        max_length=max_length,\n",
    "        top_p=0.95,\n",
    "        num_return_sequences=num_seqs,\n",
    "        do_sample=True, \n",
    "        top_k=50,\n",
    "        pad_token_id=0,\n",
    "        eos_token_id=0,\n",
    "        bos_token_id=0,\n",
    "    )):\n",
    "        seq = tokenizer.decode(seq.tolist())\n",
    "        print(i + 1, seq)\n",
    "        decode_and_print(seq.split())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Training the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vlad/git/vladsaveliev/deeplearning/gtp_gpt/venv/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 480085\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 720129\n",
      "  Number of trainable parameters = 709344\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='720129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [     2/720129 : < :, Epoch 0.00/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[64], line 33\u001B[0m\n\u001B[1;32m     15\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(\n\u001B[1;32m     16\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[1;32m     17\u001B[0m     args\u001B[38;5;241m=\u001B[39mTrainingArguments(\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     30\u001B[0m     callbacks\u001B[38;5;241m=\u001B[39m[MyCallback],\n\u001B[1;32m     31\u001B[0m )\n\u001B[1;32m     32\u001B[0m \u001B[38;5;66;03m# trainer.train(resume_from_checkpoint=last_checkpoint_dir)\u001B[39;00m\n\u001B[0;32m---> 33\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/git/vladsaveliev/deeplearning/gtp_gpt/venv/lib/python3.10/site-packages/transformers/trainer.py:1543\u001B[0m, in \u001B[0;36mTrainer.train\u001B[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[1;32m   1538\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_wrapped \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\n\u001B[1;32m   1540\u001B[0m inner_training_loop \u001B[38;5;241m=\u001B[39m find_executable_batch_size(\n\u001B[1;32m   1541\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inner_training_loop, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_train_batch_size, args\u001B[38;5;241m.\u001B[39mauto_find_batch_size\n\u001B[1;32m   1542\u001B[0m )\n\u001B[0;32m-> 1543\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1544\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1545\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1546\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1547\u001B[0m \u001B[43m    \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1548\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/git/vladsaveliev/deeplearning/gtp_gpt/venv/lib/python3.10/site-packages/transformers/trainer.py:1791\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[1;32m   1789\u001B[0m         tr_loss_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining_step(model, inputs)\n\u001B[1;32m   1790\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1791\u001B[0m     tr_loss_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1793\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m   1794\u001B[0m     args\u001B[38;5;241m.\u001B[39mlogging_nan_inf_filter\n\u001B[1;32m   1795\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torch_tpu_available()\n\u001B[1;32m   1796\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (torch\u001B[38;5;241m.\u001B[39misnan(tr_loss_step) \u001B[38;5;129;01mor\u001B[39;00m torch\u001B[38;5;241m.\u001B[39misinf(tr_loss_step))\n\u001B[1;32m   1797\u001B[0m ):\n\u001B[1;32m   1798\u001B[0m     \u001B[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001B[39;00m\n\u001B[1;32m   1799\u001B[0m     tr_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m tr_loss \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mglobal_step \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_globalstep_last_logged)\n",
      "File \u001B[0;32m~/git/vladsaveliev/deeplearning/gtp_gpt/venv/lib/python3.10/site-packages/transformers/trainer.py:2557\u001B[0m, in \u001B[0;36mTrainer.training_step\u001B[0;34m(self, model, inputs)\u001B[0m\n\u001B[1;32m   2555\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdeepspeed\u001B[38;5;241m.\u001B[39mbackward(loss)\n\u001B[1;32m   2556\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 2557\u001B[0m     \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2559\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\u001B[38;5;241m.\u001B[39mdetach()\n",
      "File \u001B[0;32m~/git/vladsaveliev/deeplearning/gtp_gpt/venv/lib/python3.10/site-packages/torch/_tensor.py:488\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    478\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    479\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    480\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    481\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    486\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    487\u001B[0m     )\n\u001B[0;32m--> 488\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    489\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    490\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/git/vladsaveliev/deeplearning/gtp_gpt/venv/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    192\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    194\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[1;32m    195\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    196\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 197\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    198\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    199\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from transformers import Trainer, TrainingArguments, TrainerCallback\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "\n",
    "save_dir = DRIVE_PATH / \"AI\" / \"gtp_gpt\"\n",
    "save_dir.mkdir(exist_ok=True)\n",
    "if last_checkpoint_dir := get_last_checkpoint(str(save_dir)):\n",
    "    last_checkpoint_dir = Path(last_checkpoint_dir)\n",
    "    print([t.name for t in last_checkpoint_dir.iterdir()])\n",
    "\n",
    "class MyCallback(TrainerCallback):\n",
    "    def on_save(self, args, state, control, **kwargs):\n",
    "        sample()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=str(save_dir),\n",
    "        report_to=['wandb'] if 'WANDB_API_KEY' in os.environ else [],\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        overwrite_output_dir=True,\n",
    "        eval_steps=500,\n",
    "        save_steps=500,\n",
    "        save_total_limit=2,\n",
    "        per_device_train_batch_size=2,\n",
    "        per_device_eval_batch_size=2,\n",
    "        ignore_data_skip=True,\n",
    "    ),\n",
    "    train_dataset=ds.train,\n",
    "    callbacks=[MyCallback],\n",
    ")\n",
    "trainer.train(resume_from_checkpoint=last_checkpoint_dir)\n",
    "# trainer.train()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}