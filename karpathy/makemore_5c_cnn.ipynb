{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## makemore: part 5.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt  # for making figures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033 words: emma, olivia, ava, isabella, sophia, charlotte, mia, amelia... Max word len: 15\n"
     ]
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "print(f'{len(words)} words: {\", \".join(words[:8])}... Max word len:', max(len(w) for w in words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s: i + 1 for i, s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i: s for s, i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# shuffle up the words\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "max_word_len = max(len(w) for w in words)\n",
    "# adjusting to the nearest power of 2:\n",
    "word_buffer_size = 2 ** (list(itertools.takewhile((lambda p: 2**p < max_word_len + 1), itertools.count(1)))[-1] + 1)\n",
    "print(word_buffer_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25626, 16]) torch.Size([25626])\n",
      "torch.Size([3203, 16]) torch.Size([3203])\n",
      "torch.Size([3204, 16]) torch.Size([3204])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Dataset:\n",
    "    x: torch.tensor\n",
    "    y: torch.tensor\n",
    "\n",
    "@dataclass\n",
    "class Datasets:\n",
    "    train: Dataset\n",
    "    dev: Dataset\n",
    "    test: Dataset\n",
    "\n",
    "def build_dataset(words) -> Dataset:\n",
    "    x = torch.zeros((len(words), word_buffer_size), dtype=torch.int)  # 32033 x 16\n",
    "    y = torch.ones(len(words), dtype=torch.int)\n",
    "\n",
    "    for wi, word in enumerate(words):\n",
    "        for ci, ch in enumerate(word):\n",
    "            x[wi][ci + 1] = stoi[ch]\n",
    "\n",
    "    ds = Dataset(x, y)\n",
    "    print(ds.x.shape, ds.y.shape)\n",
    "    return ds\n",
    "\n",
    "n1 = int(0.8 * len(words))\n",
    "n2 = int(0.9 * len(words))\n",
    "datasets = Datasets(\n",
    "    build_dataset(words[:n1]),    # 80%,\n",
    "    build_dataset(words[n1:n2]),  # 10%\n",
    "    build_dataset(words[n2:])     # 10%\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xb.shape=torch.Size([32, 16]), yb.shape=torch.Size([32])\n",
      "emb.shape=torch.Size([32, 16, 10])\n",
      "c1_out.shape=torch.Size([32, 24, 16])\n",
      "p1_out.shape=torch.Size([32, 24, 8])\n",
      "c2_out.shape=torch.Size([32, 24, 8])\n",
      "p2_out.shape=torch.Size([32, 24, 4])\n",
      "c3_out.shape=torch.Size([32, 24, 4])\n",
      "p3_out.shape=torch.Size([32, 24, 2])\n",
      "c4_out.shape=torch.Size([32, 24, 2])\n",
      "p4_out.shape=torch.Size([32, 24, 1])\n",
      "flatten_out.shape=torch.Size([32, 24])\n",
      "logits.shape=torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "embedding_dim = 10\n",
    "hidden_size = 24\n",
    "\n",
    "xb = datasets.train.x[:batch_size]  # 32 words, with each word consisting of 15 character vectors\n",
    "yb = datasets.train.y[:batch_size]\n",
    "print(f'{xb.shape=}, {yb.shape=}')\n",
    "\n",
    "emb_l = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
    "emb = emb_l(xb)\n",
    "print(f'{emb.shape=}')\n",
    "\n",
    "c1 = nn.Conv1d(embedding_dim, hidden_size, 2, padding='same')\n",
    "c1_out = c1(emb.transpose(2, 1))\n",
    "print(f'{c1_out.shape=}')  # batch_size, n_hidden, max_word_len+1\n",
    "\n",
    "p1 = nn.AvgPool1d(2)\n",
    "p1_out = p1(c1_out)\n",
    "print(f'{p1_out.shape=}')\n",
    "\n",
    "c2 = nn.Conv1d(hidden_size, hidden_size, 2, padding='same')\n",
    "c2_out = c2(p1_out)\n",
    "print(f'{c2_out.shape=}')  # batch_size, n_hidden, max_word_len+1\n",
    "\n",
    "p2 = nn.AvgPool1d(2)\n",
    "p2_out = p1(c2_out)\n",
    "print(f'{p2_out.shape=}')\n",
    "\n",
    "c3 = nn.Conv1d(hidden_size, hidden_size, 2, padding='same')\n",
    "c3_out = c3(p2_out)\n",
    "print(f'{c3_out.shape=}')  # batch_size, n_hidden, max_word_len+1\n",
    "\n",
    "p3 = nn.AvgPool1d(2)\n",
    "p3_out = p1(c3_out)\n",
    "print(f'{p3_out.shape=}')\n",
    "\n",
    "c4 = nn.Conv1d(hidden_size, hidden_size, 2, padding='same')\n",
    "c4_out = c4(p3_out)\n",
    "print(f'{c4_out.shape=}')  # batch_size, n_hidden, max_word_len+1\n",
    "\n",
    "p4 = nn.AvgPool1d(2)\n",
    "p4_out = p1(c4_out)\n",
    "print(f'{p4_out.shape=}')\n",
    "\n",
    "flatten = nn.Flatten(start_dim=1)\n",
    "flatten_out = flatten(p4_out)\n",
    "print(f'{flatten_out.shape=}')\n",
    "\n",
    "# gru = nn.GRU(p2_out.shape[-1], hidden_size, 1, dropout=0.01)\n",
    "# gru_out, res = gru(p2_out)\n",
    "# print(f'{gru_out.shape=}, {res.shape=}')\n",
    "\n",
    "linear = nn.Linear(hidden_size, 1)\n",
    "logits = nn.Tanh()(linear(flatten_out))\n",
    "print(f'{logits.shape=}')\n",
    "\n",
    "# loss = nn.MSELoss()(logits.squeeze(), yb)\n",
    "# print(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 15])\n",
      "torch.Size([16, 15, 10])\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total model parameters: 22370\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Embedding(vocab_size, n_embd),\n",
    "    nn.Conv1d(n_embd, n_hidden, kernel_size=2),\n",
    ")\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, n_embd),\n",
    "    FlattenConsecutive(2), Linear(n_embd * 2,   n_hidden,     bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    FlattenConsecutive(2), Linear(n_hidden * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    FlattenConsecutive(2), Linear(n_hidden * 2, n_hidden, bias=False), BatchNorm1d(n_hidden),     Tanh(),\n",
    "    Linear(n_hidden, vocab_size),\n",
    "])\n",
    "with torch.no_grad():\n",
    "    if isinstance(model.layers[-1], BatchNorm1d):\n",
    "        model.layers[-1].gain *= 0.1\n",
    "    if isinstance(model.layers[-1], Linear):\n",
    "        model.layers[-1].w *= 0.1\n",
    "    \n",
    "    for l in model.layers:\n",
    "        if isinstance(l, Linear):\n",
    "            # tanh is a shrinking function, so need to initialise wights a bit larger\n",
    "            # to compensate this shrinkage and keep weights a unit gaussian on each step\n",
    "            l.w *= 5/3\n",
    "\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "print('Total model parameters:', sum(p.nelement() for p in model.parameters()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "embedding_dim = 10\n",
    "n_conv_channels = 24\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim),\n",
    "    nn.Conv1d(in_channels=embedding_dim, out_channels=n_conv_channels, kernel_size=2, padding='same'),\n",
    "    nn.Conv1d(in_channels=n_conv_channels, out_channels=n_conv_channels, kernel_size=4, padding='same'),\n",
    "    nn.Conv1d(in_channels=n_conv_channels, out_channels=n_conv_channels, kernel_size=8, padding='same'),\n",
    "    nn.MaxPool1d(2),\n",
    "    nn.Flatten(start_dim=1, end_dim=2),\n",
    "    nn.Linear(in_features=flatten.shape[-1], out_features=1),\n",
    "    nn.BatchNorm1d(1),\n",
    "    nn.Tanh(),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [24, 10, 2], expected input[32, 16, 11] to have 10 channels, but got 16 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[101], line 16\u001B[0m\n\u001B[1;32m     13\u001B[0m xb \u001B[38;5;241m=\u001B[39m datasets\u001B[38;5;241m.\u001B[39mtrain\u001B[38;5;241m.\u001B[39mx[batch_ix]\n\u001B[1;32m     14\u001B[0m yb \u001B[38;5;241m=\u001B[39m datasets\u001B[38;5;241m.\u001B[39mtrain\u001B[38;5;241m.\u001B[39my[batch_ix]\n\u001B[0;32m---> 16\u001B[0m logits \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mxb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     17\u001B[0m loss \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mMSELoss()(logits\u001B[38;5;241m.\u001B[39msqueeze(), yb)\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n_steps \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m step_i \u001B[38;5;241m%\u001B[39m (n_steps \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;241m10\u001B[39m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/git/vladsaveliev/deeplearning/karpathy/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/git/vladsaveliev/deeplearning/karpathy/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    202\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    203\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 204\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    205\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/git/vladsaveliev/deeplearning/karpathy/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/git/vladsaveliev/deeplearning/karpathy/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:313\u001B[0m, in \u001B[0;36mConv1d.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    312\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 313\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/git/vladsaveliev/deeplearning/karpathy/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:309\u001B[0m, in \u001B[0;36mConv1d._conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    305\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    306\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv1d(F\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode),\n\u001B[1;32m    307\u001B[0m                     weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[1;32m    308\u001B[0m                     _single(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n\u001B[0;32m--> 309\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv1d\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    310\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Given groups=1, weight of size [24, 10, 2], expected input[32, 16, 11] to have 10 channels, but got 16 channels instead"
     ]
    }
   ],
   "source": [
    "DEBUG = False\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "n_steps = 1001\n",
    "learning_rate = 0.1\n",
    "\n",
    "losses = []\n",
    "\n",
    "\n",
    "for step_i in range(n_steps):\n",
    "    batch_ix = torch.randint(high=datasets.train.x.shape[0], size=(batch_size,))\n",
    "    xb = datasets.train.x[batch_ix]\n",
    "    yb = datasets.train.y[batch_ix]\n",
    "\n",
    "    logits = model(xb)\n",
    "    loss = nn.MSELoss()(logits.squeeze(), yb)\n",
    "\n",
    "    if n_steps == 1 or step_i % (n_steps // 10) == 0:\n",
    "        print(f'Step {step_i}: training loss: {loss.item()}')\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    for p in model.parameters():\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    lr = learning_rate if (step_i < (n_steps / 2)) else learning_rate / 10\n",
    "    for p in model.parameters():\n",
    "        p.data -= lr * p.grad\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def loss_for_split(split: str):\n",
    "    ds = datasets.__getattribute__(split)\n",
    "    logits = model(ds.x)\n",
    "    loss = F.MSELoss()(logits.squeeze(), ds.y)\n",
    "    print(f'{split} loss={loss}')\n",
    "\n",
    "loss_for_split('train')\n",
    "loss_for_split('test')\n",
    "loss_for_split('dev')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}