{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://huggingface.co\"\n",
    "\n",
    "prompt = \"Охота на овец\"\n",
    "kwargs = dict(max_new_tokens=100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Large model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "tokenizer_l = AutoTokenizer.from_pretrained(\"sberbank-ai/rugpt3large_based_on_gpt2\")\n",
    "model_l = AutoModelForCausalLM.from_pretrained(\"sberbank-ai/rugpt3large_based_on_gpt2\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "pipe_l = pipeline(task=\"text-generation\", model=model_l, tokenizer=tokenizer_l)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Охота на овец» (1936) и «Смерть в Венеции» (1937).\n",
      "\n",
      "В 1939 году, после начала Второй мировой войны, он был призван в армию и направлен в Италию. В 1940 году он был ранен в бою и попал в плен. В 1941 году он был освобождён и вернулся в Италию.\n",
      "\n",
      "В 1943 году он был назначен на должность заместителя начальника штаба полка, а в 1944 году — на должность командира полка. В 1945 году он был назначен на должность командира дивизии,\n"
     ]
    }
   ],
   "source": [
    "t = pipe_l(prompt, **kwargs, do_sample=False)  # greedy decoding\n",
    "print(t[0]['generated_text'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Охота на овец\n",
      "Елена Лядова Охота на овец\n",
      "Крошка Монти\n",
      "Крошка Монти и Крошка Сью\n",
      "Крошка Монти и Крошка Сью\n",
      "Крошка Монти и Крошка Сюзанна\n",
      "Крошка Монти и Крошка Сьюзанн\n",
      "Крошка Монти и Крошка Сюзанна\n",
      "Иллюстрации: Александр Голубев\n",
      "Рисунки Елены Лядовой\n",
      "\n",
      "http://www.zaycev.net/p\n"
     ]
    }
   ],
   "source": [
    "t2 = pipe_l(prompt, **kwargs, do_sample=True)  # multinomial sampling\n",
    "print(t2[0]['generated_text'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Охота на овец»\n",
      "\n",
      "В «Охоте на овец» (1892) Ф. М. Достоевский, как и в «Преступлении и наказании», рисует образ человека, попавшего в ловушку, из которой не может вырваться. Но если в «Преступлении и наказании» человек, попавший в ловушку, не может вырваться, то в «Охоте на овец» человек, попавший в ловушку, может это сделать.\n",
      "\n",
      "В «Охот\n"
     ]
    }
   ],
   "source": [
    "t3 = pipe_l(prompt, **kwargs, num_beams=4, do_sample=True)  # multinomial beam-search sampling\n",
    "print(t3[0]['generated_text'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Small model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "tokenizer_s = AutoTokenizer.from_pretrained(\"sberbank-ai/rugpt3small_based_on_gpt2\")\n",
    "model_s = AutoModelForCausalLM.from_pretrained(\"sberbank-ai/rugpt3small_based_on_gpt2\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "pipe_s = pipeline(task=\"text-generation\", model=model_s, tokenizer=tokenizer_s)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Охота на овец\n",
      "Александр Сергеевич Пушкин\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Александр Сергеевич Пушкин\n",
      "\n",
      "Охота на овец\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t = pipe_s(prompt, **kwargs, do_sample=False)  # greedy decoding\n",
    "print(t[0]['generated_text'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Охота на овец», где фигурирует еще одно имя - «Айзек Азимов и его сыновья», но эта версия еще не стала достоянием широких СМИ, а уже стала бестселлером, а то в эпоху постмодерна даже такие вещи просто невозможно представить!\n",
      "И да, с таким сюжетом вряд ли кого-то пустят в кинотеатр в видеоряде в оригинале, но мы-то знаем, почему.\n",
      "\n",
      "И с теми, кто будет слушать эту «Твин Пик\n"
     ]
    }
   ],
   "source": [
    "t = pipe_s(prompt, **kwargs, do_sample=True)  # multinomial sampling\n",
    "print(t[0]['generated_text'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Охота на овец.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t = pipe_s(prompt, **kwargs, num_beams=4, do_sample=True)  # multinomial beam-search sampling\n",
    "print(t[0]['generated_text'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fine-tuning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pre-process dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sberbank-ai/rugpt3small_based_on_gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"sberbank-ai/rugpt3small_based_on_gpt2\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPastAndCrossAttentions(last_hidden_state=tensor([[[ 0.1629, -0.2166, -0.1410,  ..., -0.2619, -0.0819,  0.0092],\n",
      "         [ 0.4628,  0.0248, -0.0785,  ..., -0.0859,  0.5122, -0.3939],\n",
      "         [-0.0644,  0.1551, -0.6306,  ...,  0.2488,  0.3691,  0.0833]]],\n",
      "       grad_fn=<ViewBackward0>), past_key_values=((tensor([[[[-1.0719,  2.4170,  0.9660,  ..., -0.4787, -0.3316,  1.7925],\n",
      "          [-2.2897,  2.5424,  0.8317,  ..., -0.5299, -2.4828,  1.3537],\n",
      "          [-2.2856,  2.7125,  2.4725,  ..., -1.4911, -1.8427,  1.6493]],\n",
      "\n",
      "         [[ 0.4796, -0.1131, -1.4854,  ...,  1.1607,  1.8412,  1.3682],\n",
      "          [-0.7273, -1.1362, -1.0850,  ..., -0.6736,  3.2618,  0.2099],\n",
      "          [-1.4441, -3.0647, -4.1612,  ..., -1.4788,  3.2718, -0.2803]],\n",
      "\n",
      "         [[-0.2338, -0.8688,  1.6542,  ..., -1.5964, -1.5636,  1.0931],\n",
      "          [ 0.3698,  0.4929,  1.4155,  ..., -2.0162, -1.0246,  1.9822],\n",
      "          [ 0.4509,  1.0144,  0.1189,  ..., -3.1880,  0.4529,  1.3746]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4012, -0.0278, -0.1031,  ...,  0.2614,  0.9767,  0.5994],\n",
      "          [ 0.2222,  0.3167, -0.2024,  ...,  0.9616,  0.3658,  1.0162],\n",
      "          [ 0.3276,  0.0629,  0.1905,  ...,  1.0855,  0.8707,  0.0940]],\n",
      "\n",
      "         [[ 0.9759,  1.3121, -0.6612,  ..., -0.3228,  1.1476, -1.2349],\n",
      "          [ 1.0862,  0.3406, -0.6767,  ..., -1.0748,  1.4611,  0.6789],\n",
      "          [ 0.6566,  0.1325, -0.5036,  ..., -1.9292,  1.4180,  0.0719]],\n",
      "\n",
      "         [[ 0.6922,  0.4421,  0.2786,  ..., -0.2213,  0.2488,  1.8778],\n",
      "          [-0.1203, -0.2795, -0.0287,  ..., -0.2255,  0.5681,  1.2821],\n",
      "          [ 0.3923,  0.6569,  0.0967,  ..., -0.0928,  0.2676,  2.2244]]]],\n",
      "       grad_fn=<PermuteBackward0>), tensor([[[[ 0.0358,  0.0450, -0.0323,  ...,  0.1130,  0.0034, -0.0738],\n",
      "          [ 0.0242, -0.2317,  0.0799,  ..., -0.0396,  0.1347, -0.0889],\n",
      "          [ 0.1318,  0.0427,  0.0077,  ...,  0.1165,  0.1436, -0.0303]],\n",
      "\n",
      "         [[ 0.4651,  0.2930, -0.2600,  ..., -0.4890, -0.3983,  0.0520],\n",
      "          [ 0.3622, -0.2101,  0.2311,  ...,  0.0127, -0.0099, -0.1905],\n",
      "          [ 0.5059, -0.2870, -0.0373,  ...,  0.1338,  0.1482, -0.0704]],\n",
      "\n",
      "         [[-0.0353,  0.0570, -0.0739,  ..., -0.0122, -0.0891, -0.1076],\n",
      "          [-0.1452, -0.1109, -0.3124,  ...,  0.0080,  0.1051, -0.0682],\n",
      "          [-0.2972, -0.1087, -0.3765,  ..., -0.4500, -0.3935, -0.0587]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1693, -0.1686, -0.1308,  ..., -0.0455,  0.0165, -0.0049],\n",
      "          [-0.1829, -0.0730,  0.0891,  ...,  0.2858,  0.1652,  0.3990],\n",
      "          [ 0.0181,  0.1486,  0.1400,  ..., -0.2019, -0.3116,  0.1883]],\n",
      "\n",
      "         [[ 0.1166, -0.0952, -0.0801,  ...,  0.1180,  0.1444,  0.0806],\n",
      "          [-0.4098,  0.1798,  0.0621,  ..., -0.4601, -0.1591,  0.1654],\n",
      "          [ 0.1071, -0.1444, -0.0386,  ..., -0.3147, -0.1142,  0.1169]],\n",
      "\n",
      "         [[-0.1403, -0.2172,  0.2116,  ...,  0.0113, -0.1694, -0.0567],\n",
      "          [ 0.1650,  0.1475,  0.1232,  ...,  0.5281,  0.3752,  0.0566],\n",
      "          [-0.1617, -0.0952, -0.3001,  ..., -0.1390,  0.0763,  0.1500]]]],\n",
      "       grad_fn=<PermuteBackward0>)), (tensor([[[[-2.3234e-01,  1.7469e+00, -1.3506e+00,  ...,  1.3035e+00,\n",
      "           -1.1436e+00,  1.3027e+00],\n",
      "          [ 3.7144e-01,  1.5962e+00, -9.8959e-01,  ..., -3.7702e-01,\n",
      "           -1.6238e+00,  4.9728e-01],\n",
      "          [ 1.5475e+00,  1.7371e+00, -1.1542e+00,  ...,  2.6362e-02,\n",
      "           -2.4185e+00,  6.0650e-02]],\n",
      "\n",
      "         [[-1.4716e+00, -7.0062e-01, -8.4053e-01,  ..., -3.4795e-01,\n",
      "            9.0868e-01, -5.7943e-01],\n",
      "          [-6.7887e-01, -8.5541e-01, -1.9801e+00,  ..., -1.3131e+00,\n",
      "           -2.7207e-01,  1.9432e-01],\n",
      "          [-8.6449e-01,  1.6246e-02, -1.5927e+00,  ..., -1.5577e-01,\n",
      "            4.3638e-01,  3.4525e-01]],\n",
      "\n",
      "         [[ 3.3298e-01,  1.1988e-01, -2.9469e-02,  ..., -1.2560e+00,\n",
      "            1.5321e-01, -2.1866e-01],\n",
      "          [ 3.3311e-01,  6.0987e-01, -3.2191e-01,  ..., -1.2439e+00,\n",
      "           -7.9251e-02,  7.9439e-02],\n",
      "          [-1.3959e-01,  2.9871e-01, -1.1090e-01,  ..., -8.7817e-01,\n",
      "           -2.1968e-01,  5.7344e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.1961e-01, -5.4149e-01, -6.5129e-01,  ..., -1.3049e-01,\n",
      "            6.4293e-01, -1.0648e+00],\n",
      "          [-1.1139e+00,  1.7472e+00,  1.9236e+00,  ..., -5.2888e-01,\n",
      "           -8.8113e-01, -1.1274e+00],\n",
      "          [-3.5029e-02,  1.6498e+00,  1.5704e+00,  ...,  1.8705e+00,\n",
      "            4.4842e-01,  1.7473e-01]],\n",
      "\n",
      "         [[-1.2016e+00, -2.7812e+00,  1.2903e-01,  ...,  1.6795e+00,\n",
      "            1.5993e+00, -1.5680e+00],\n",
      "          [-2.4824e-01,  9.6243e-01, -6.0818e-01,  ..., -6.4028e-01,\n",
      "            7.3015e-01,  1.6932e-03],\n",
      "          [ 3.7342e-01,  7.0263e-01, -5.0011e-01,  ..., -6.0883e-01,\n",
      "            4.8429e-01, -9.1718e-02]],\n",
      "\n",
      "         [[ 1.2471e+00,  1.8337e+00,  1.4891e+00,  ..., -2.7984e-01,\n",
      "            8.3699e-02, -4.6373e-01],\n",
      "          [-7.5651e-03,  2.5955e+00,  5.7040e-01,  ...,  1.0415e+00,\n",
      "           -1.6044e-01, -3.6244e-01],\n",
      "          [ 7.7530e-02,  2.8104e+00,  1.5624e+00,  ...,  1.5091e+00,\n",
      "           -1.8090e-02, -1.2300e+00]]]], grad_fn=<PermuteBackward0>), tensor([[[[ 1.8121e-01, -1.3411e-01, -2.1478e-01,  ...,  7.0410e-02,\n",
      "            2.1432e-01, -4.1736e-01],\n",
      "          [-3.4722e-01, -2.4165e-01, -3.5845e-01,  ..., -4.0394e-03,\n",
      "            6.8928e-01,  6.3408e-01],\n",
      "          [ 1.8921e-01,  1.1412e-01, -3.7454e-01,  ..., -6.1886e-01,\n",
      "            1.5584e-01, -3.3977e-01]],\n",
      "\n",
      "         [[-1.2948e-01, -1.3113e-01,  3.0471e-01,  ..., -9.5208e-02,\n",
      "           -5.2637e-01,  2.0391e-02],\n",
      "          [-5.2768e-01, -2.4699e-01, -1.2828e-01,  ..., -1.3858e-01,\n",
      "            1.6376e-01,  3.1491e-01],\n",
      "          [ 3.4299e-02,  2.9798e-01, -1.8136e-01,  ...,  3.7112e-01,\n",
      "           -1.1525e-02, -2.1673e-01]],\n",
      "\n",
      "         [[ 4.5340e-02, -4.0817e-01,  5.3539e-02,  ..., -4.7963e-01,\n",
      "           -2.8298e-01,  2.7899e-02],\n",
      "          [ 8.4529e-01,  9.4444e-02,  2.4181e-02,  ..., -7.5536e-01,\n",
      "           -4.6340e-02,  1.8064e-01],\n",
      "          [ 8.0320e-01,  1.4924e-01,  5.8457e-01,  ..., -8.3811e-01,\n",
      "            1.0063e-01,  2.5599e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4653e-01,  6.2398e-01, -1.6506e-01,  ...,  1.2628e-01,\n",
      "           -9.4077e-01, -1.0024e-01],\n",
      "          [ 8.5481e-02, -3.7416e-01,  6.1154e-02,  ...,  2.1396e-01,\n",
      "           -6.8562e-01, -1.3296e-01],\n",
      "          [-2.7189e-01,  7.6010e-02,  5.0749e-01,  ...,  6.4782e-02,\n",
      "           -6.3529e-01, -3.4742e-01]],\n",
      "\n",
      "         [[ 1.9841e-01, -1.6214e-01,  8.8751e-02,  ...,  3.8060e-01,\n",
      "           -3.5175e+00, -4.8737e-02],\n",
      "          [ 4.8521e-02, -4.2689e-01,  2.9560e-03,  ...,  4.1736e-01,\n",
      "            3.3646e-02, -1.3576e-01],\n",
      "          [-2.3386e-01,  4.3438e-02,  1.9538e-01,  ...,  2.6902e-02,\n",
      "            7.1384e-02,  8.4704e-02]],\n",
      "\n",
      "         [[-5.0851e-02, -5.9927e-02, -5.6214e-02,  ..., -2.0252e-01,\n",
      "            1.2368e-01, -3.3855e-02],\n",
      "          [-1.1510e-02, -7.6934e-02,  2.3691e-01,  ...,  6.5874e-02,\n",
      "            1.5216e-02,  1.8671e-01],\n",
      "          [ 1.5296e-01, -1.3156e-01,  1.3923e-01,  ...,  1.8831e-01,\n",
      "           -8.2086e-02,  1.2744e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-0.1322, -1.1527,  0.3087,  ..., -0.6205, -0.1060, -0.0181],\n",
      "          [ 0.5456, -2.5518, -0.2942,  ..., -1.2907,  0.0803,  0.1253],\n",
      "          [ 0.9459, -2.5900,  0.3366,  ...,  0.2387,  0.0244, -0.0984]],\n",
      "\n",
      "         [[-0.4981,  0.4839, -0.4288,  ...,  1.2952, -0.4981, -0.4568],\n",
      "          [-1.4536, -0.2465, -0.9163,  ...,  0.4530,  0.6458,  0.4874],\n",
      "          [-1.6652, -0.9680, -1.0875,  ..., -0.0277,  1.3271, -0.3510]],\n",
      "\n",
      "         [[ 1.3747,  3.0648,  3.7658,  ...,  0.6805,  1.6251, -0.7113],\n",
      "          [-3.6194,  2.6739, -2.5109,  ..., -3.2047,  2.9450, -0.3144],\n",
      "          [-3.1928,  1.5469, -3.1628,  ..., -2.9214,  3.4801,  1.2360]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3571, -2.6940, -2.5864,  ...,  0.9747,  0.4724,  2.7245],\n",
      "          [-3.2790,  1.4895,  0.4607,  ...,  0.6635, -1.8444, -0.3443],\n",
      "          [-3.4600,  2.6956,  1.3558,  ..., -0.1266, -2.7145,  0.0972]],\n",
      "\n",
      "         [[ 1.7131,  0.4496,  0.9466,  ...,  0.0104, -0.9866, -0.3256],\n",
      "          [ 2.1683,  0.8876,  1.4803,  ...,  0.1768, -1.8011, -1.9908],\n",
      "          [ 2.0806,  1.0288,  1.1972,  ..., -0.0733, -1.5057, -1.4346]],\n",
      "\n",
      "         [[-0.2538,  0.1160, -0.5586,  ...,  0.2681,  0.2844,  0.1296],\n",
      "          [-0.2222,  0.8479, -0.4422,  ..., -0.2732,  0.8777,  0.8108],\n",
      "          [-0.6727,  0.5071,  0.0572,  ...,  0.0786,  0.3229,  0.3834]]]],\n",
      "       grad_fn=<PermuteBackward0>), tensor([[[[-2.6110e-02, -6.3369e-03, -1.2897e-01,  ..., -2.7515e-02,\n",
      "            3.0886e-02, -5.4642e-01],\n",
      "          [ 2.8421e-01, -8.6539e-01, -2.9025e-01,  ...,  2.3311e-01,\n",
      "           -8.4891e-01,  1.3338e+00],\n",
      "          [ 2.4186e-01, -2.5358e-01, -8.4709e-01,  ..., -4.7114e-01,\n",
      "           -4.3807e-01,  8.2508e-01]],\n",
      "\n",
      "         [[ 3.3488e-02, -2.1709e-02,  3.1775e-02,  ..., -3.6363e-02,\n",
      "           -2.0804e-02,  7.0153e-02],\n",
      "          [-2.9799e-02,  6.2118e-01, -3.6438e-01,  ...,  4.9336e-02,\n",
      "           -1.8000e-01,  3.8404e-01],\n",
      "          [-4.7976e-01,  1.9055e-02, -1.4230e+00,  ..., -4.2935e-01,\n",
      "            4.5856e-01,  1.0601e-01]],\n",
      "\n",
      "         [[ 6.9997e-03, -7.2047e-01, -1.4875e-02,  ...,  5.4531e-02,\n",
      "            3.6829e-02, -1.3042e-02],\n",
      "          [ 7.3096e-01, -1.3004e+00,  2.5491e-02,  ..., -2.0688e-01,\n",
      "            2.1388e-01, -1.9886e-01],\n",
      "          [-5.9057e-01, -1.3042e+00,  1.9017e-01,  ..., -1.8207e-01,\n",
      "           -3.5324e-03,  3.4668e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.0108e-02, -5.6756e-02,  1.3052e+00,  ...,  1.0925e-03,\n",
      "            1.9278e-01, -2.0603e-03],\n",
      "          [-2.6232e-02,  3.2866e-01,  1.9221e+00,  ...,  1.4766e-01,\n",
      "           -6.7259e-02,  2.4187e-01],\n",
      "          [-4.8278e-01, -4.2951e-01,  1.8054e+00,  ...,  3.6253e-01,\n",
      "           -3.1257e-01,  3.7770e-01]],\n",
      "\n",
      "         [[-1.5290e-02, -6.3416e-02, -1.4310e-01,  ...,  1.6105e-01,\n",
      "            1.1368e-01,  1.8954e-01],\n",
      "          [-9.1473e-01,  2.2297e-01,  1.4207e-01,  ...,  3.7581e-02,\n",
      "           -3.2340e-01, -1.5199e-01],\n",
      "          [ 3.7227e-01, -4.9001e-01,  1.7333e-01,  ..., -1.4885e-01,\n",
      "           -6.3321e-01, -2.0094e-01]],\n",
      "\n",
      "         [[ 2.3022e-02,  2.4736e-02,  1.4599e-02,  ..., -1.3392e-02,\n",
      "            2.2758e-01, -6.3206e-03],\n",
      "          [ 4.9218e-02,  5.3240e-01,  9.0467e-01,  ...,  1.1255e-01,\n",
      "           -2.0287e+00,  9.8514e-01],\n",
      "          [-4.7997e-01, -7.5515e-02, -1.9737e-01,  ..., -6.4949e-02,\n",
      "           -1.9641e+00,  1.0550e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[ 5.1604e-03, -1.8791e-01,  1.4746e-01,  ..., -8.8068e-01,\n",
      "            7.5894e-01, -1.1973e+00],\n",
      "          [-2.5677e+00,  1.7679e+00, -3.9106e+00,  ...,  1.2833e+00,\n",
      "           -1.2259e+00,  2.1156e+00],\n",
      "          [-1.6822e+00, -3.9114e-01, -1.4672e+00,  ..., -1.2825e-01,\n",
      "            5.9892e-01,  4.3526e-01]],\n",
      "\n",
      "         [[ 8.0498e-01,  2.0352e-01,  1.7896e-02,  ..., -1.6228e-01,\n",
      "           -1.0867e+00, -2.0632e-01],\n",
      "          [ 6.3069e-01, -1.4465e+00,  5.0411e-01,  ...,  3.4637e-01,\n",
      "            5.0468e+00,  2.1150e+00],\n",
      "          [-1.1162e+00, -1.3258e+00,  6.3189e-01,  ...,  1.2063e+00,\n",
      "            4.4761e+00,  1.0679e+00]],\n",
      "\n",
      "         [[ 3.3238e-01, -3.5263e-01, -3.3511e-01,  ...,  3.3173e-01,\n",
      "            1.4302e+00,  2.7422e-01],\n",
      "          [-3.7069e-01, -6.1829e+00, -2.2466e+00,  ..., -3.6439e+00,\n",
      "           -2.1060e+00, -7.4567e+00],\n",
      "          [-4.5128e-01, -5.9982e+00, -2.4673e+00,  ..., -4.1265e+00,\n",
      "           -3.8545e+00, -6.1227e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.3405e-01,  1.8003e+00,  5.3820e-01,  ...,  2.6242e-01,\n",
      "            4.4859e-01, -1.6709e+00],\n",
      "          [ 1.3520e+00, -5.1191e+00,  2.9198e+00,  ..., -8.6180e-01,\n",
      "           -1.6337e+00,  5.9583e+00],\n",
      "          [-8.9199e-02, -6.2376e+00,  4.5249e-01,  ..., -1.8860e+00,\n",
      "           -2.1434e+00,  7.1481e+00]],\n",
      "\n",
      "         [[ 7.0162e-02, -5.0270e-02,  1.6436e-01,  ..., -8.4555e-02,\n",
      "           -8.5299e-02, -1.4128e-01],\n",
      "          [ 4.7663e-01, -5.4246e-01,  6.5545e-01,  ...,  4.4172e-01,\n",
      "           -1.1501e+00, -1.4259e+00],\n",
      "          [ 1.6341e+00, -1.9560e+00, -1.2453e+00,  ..., -1.1005e+00,\n",
      "           -1.0474e-01, -3.4483e-01]],\n",
      "\n",
      "         [[ 4.0545e-01, -3.8652e-02,  1.8953e+00,  ..., -2.2527e-01,\n",
      "           -1.9901e-01, -9.9290e-01],\n",
      "          [ 3.7929e+00,  9.7979e-01, -1.5706e+00,  ...,  8.7371e-01,\n",
      "            1.3123e+00,  4.0946e+00],\n",
      "          [ 2.6437e+00,  2.8533e+00, -1.1851e+00,  ...,  1.4979e+00,\n",
      "            1.7340e+00,  2.7878e+00]]]], grad_fn=<PermuteBackward0>), tensor([[[[ 3.9765e-02,  6.3191e-02,  6.3375e-04,  ...,  1.9104e-02,\n",
      "            9.9082e-02,  3.4521e-02],\n",
      "          [ 1.1378e+00, -1.2861e+00, -1.2908e-01,  ..., -3.3004e-01,\n",
      "           -1.3635e+00, -2.2904e+00],\n",
      "          [-8.1626e-02,  9.3745e-02, -2.8481e-01,  ...,  2.1468e-01,\n",
      "           -9.6816e-01,  2.9894e-01]],\n",
      "\n",
      "         [[-4.9772e-02,  4.5371e-03,  8.2704e-02,  ..., -5.1366e-02,\n",
      "           -3.5350e-02, -4.1695e-02],\n",
      "          [ 9.3125e-01,  4.8477e-01,  1.2722e-02,  ...,  2.5011e-01,\n",
      "            5.0911e-01,  7.7029e-02],\n",
      "          [ 5.3607e-01,  3.6337e-01,  5.9256e-01,  ...,  1.3317e-01,\n",
      "            2.4218e-01,  5.0219e-01]],\n",
      "\n",
      "         [[ 2.8733e-02, -1.1324e-01, -6.5474e-02,  ..., -2.8632e-02,\n",
      "            7.8444e-02, -1.6102e-01],\n",
      "          [-4.5820e-01,  4.7828e-01,  7.0547e-02,  ...,  5.3585e-01,\n",
      "           -4.5617e-01, -2.3535e-01],\n",
      "          [-3.3742e-01, -4.2131e-02,  5.9882e-01,  ...,  2.5610e-01,\n",
      "            7.7897e-02, -4.0960e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.0445e-02,  1.2575e-01, -8.2247e-03,  ..., -3.0457e-02,\n",
      "            6.6124e-02, -3.3832e-02],\n",
      "          [-7.7384e-01,  4.6625e-01, -8.6402e-01,  ...,  1.1561e+00,\n",
      "            1.9820e-01, -3.0625e-01],\n",
      "          [-2.7738e-04,  6.3935e-01, -1.8950e-01,  ...,  2.0117e-01,\n",
      "           -1.7873e-02,  5.5499e-01]],\n",
      "\n",
      "         [[-1.7626e-01, -1.0919e-01, -8.4360e-02,  ..., -2.3040e-01,\n",
      "           -1.7456e-02, -4.5445e-02],\n",
      "          [-7.3267e-01,  3.0908e-01, -6.8270e-01,  ...,  1.1911e+00,\n",
      "            6.0792e-01, -5.9669e-01],\n",
      "          [ 3.2711e-01, -8.1702e-01, -6.7690e-01,  ..., -1.4106e-01,\n",
      "            5.1631e-01,  1.7033e+00]],\n",
      "\n",
      "         [[ 1.2476e-01, -6.5556e-02, -2.6808e-02,  ..., -8.9693e-03,\n",
      "           -9.2486e-02, -8.6446e-02],\n",
      "          [-3.6288e-01, -4.0901e-01,  4.7382e-02,  ...,  7.5869e-01,\n",
      "            2.6507e-01, -2.3738e-01],\n",
      "          [-3.1819e-01,  4.7386e-01,  2.4661e-01,  ...,  1.0666e-02,\n",
      "            2.0598e-01, -6.8917e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-8.9410e-01, -1.4102e-01,  3.3448e-01,  ..., -9.8900e-01,\n",
      "            2.4201e-02, -2.9690e+00],\n",
      "          [ 2.0739e+00, -6.6276e-01, -9.6401e-01,  ..., -2.2700e+00,\n",
      "           -2.5282e+00,  5.5307e+00],\n",
      "          [ 1.4538e+00,  9.1335e-01, -1.2821e+00,  ..., -1.7829e+00,\n",
      "           -2.5922e+00,  7.0503e+00]],\n",
      "\n",
      "         [[ 3.3228e-01, -5.2100e-02,  4.4828e-01,  ..., -1.3505e-01,\n",
      "           -6.7878e-02, -2.2125e+00],\n",
      "          [-1.9308e+00,  1.9478e-01,  3.7004e+00,  ..., -7.5413e-01,\n",
      "           -1.4453e+00,  5.9218e+00],\n",
      "          [-2.3695e+00,  6.8371e-01,  3.6881e+00,  ...,  4.3966e-01,\n",
      "           -1.1369e+00,  6.4070e+00]],\n",
      "\n",
      "         [[ 1.3868e-01, -6.5963e-01, -2.3258e-01,  ...,  1.4861e-01,\n",
      "            2.7447e-01, -1.6060e-01],\n",
      "          [ 8.7126e-02,  1.5625e+00,  8.7948e-01,  ..., -5.6050e-02,\n",
      "            6.4115e-01, -2.2401e-02],\n",
      "          [-1.3730e+00,  1.8783e+00,  1.0146e+00,  ..., -7.2353e-01,\n",
      "           -1.0071e+00, -1.1916e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.8548e-01,  3.3657e-02, -8.6137e-04,  ...,  1.2389e+00,\n",
      "            4.4031e-02,  1.7787e+00],\n",
      "          [-3.3900e-01, -1.1665e+00, -1.6126e+00,  ..., -2.2094e+00,\n",
      "           -1.2285e+00, -8.3998e-01],\n",
      "          [ 1.1457e+00, -1.9595e+00, -2.7776e+00,  ..., -2.5459e+00,\n",
      "           -2.1862e+00, -6.8518e-01]],\n",
      "\n",
      "         [[-3.5278e-01, -1.6115e-01,  2.2002e-01,  ...,  2.5153e-01,\n",
      "           -2.5440e-02,  2.5464e-02],\n",
      "          [-5.8535e-01, -1.6797e+00, -9.7090e-02,  ...,  1.3156e+00,\n",
      "           -4.3526e-01, -3.6301e-01],\n",
      "          [-1.4276e+00, -4.4909e-01,  4.2122e-01,  ...,  8.0923e-01,\n",
      "            2.0564e+00,  5.5882e-01]],\n",
      "\n",
      "         [[ 3.4287e+00,  2.1075e+00, -2.1753e+00,  ..., -2.8384e+00,\n",
      "           -3.9170e+00, -1.1987e+00],\n",
      "          [-2.3681e+00,  6.4387e-01,  2.7032e+00,  ...,  9.6174e-01,\n",
      "            5.6489e+00, -3.8173e+00],\n",
      "          [-1.7256e+00, -6.4346e-01,  3.3742e+00,  ...,  1.0354e-01,\n",
      "            1.0917e+01, -2.0007e+00]]]], grad_fn=<PermuteBackward0>), tensor([[[[-9.6097e-04, -5.7273e-02,  1.4961e-02,  ...,  5.1007e-02,\n",
      "            2.4101e-02,  6.1853e-02],\n",
      "          [ 8.1719e-01,  3.1389e-01,  4.9729e-01,  ..., -4.4034e-01,\n",
      "           -5.6994e-01,  1.1864e+00],\n",
      "          [ 9.6676e-03, -1.2195e-01,  9.2736e-02,  ..., -8.4646e-01,\n",
      "            1.8833e-01, -2.2715e-02]],\n",
      "\n",
      "         [[-5.8025e-02, -2.3602e-02, -1.3654e-01,  ..., -3.6943e-02,\n",
      "            4.6139e-02, -3.2083e-04],\n",
      "          [ 5.3729e-01,  2.3710e-01,  3.6851e-01,  ...,  3.0927e-01,\n",
      "           -7.5684e-01,  6.9841e-01],\n",
      "          [ 8.7620e-02, -3.0468e-01, -4.1744e-01,  ...,  4.6823e-01,\n",
      "           -5.7566e-01,  6.2960e-01]],\n",
      "\n",
      "         [[ 5.9868e-02,  9.4087e-02,  8.9803e-02,  ...,  1.8043e-02,\n",
      "           -8.2018e-02, -7.6688e-03],\n",
      "          [ 4.6110e-03, -1.3464e-01,  5.5771e-01,  ..., -1.0991e+00,\n",
      "           -1.0160e-01, -4.8283e-01],\n",
      "          [-5.1055e-01, -3.0271e-01, -7.6251e-01,  ..., -5.6935e-02,\n",
      "           -4.8848e-01,  6.0690e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.9281e-03,  8.4553e-02, -7.0813e-02,  ...,  4.7959e-02,\n",
      "            4.0231e-02, -1.3932e-01],\n",
      "          [-6.4524e-02, -1.8763e-01, -5.0959e-01,  ...,  1.2312e-01,\n",
      "            9.9802e-01, -5.4559e-01],\n",
      "          [ 2.7483e-01,  5.9988e-01, -8.3259e-01,  ...,  2.9059e-01,\n",
      "           -1.6327e-01,  5.9452e-01]],\n",
      "\n",
      "         [[-1.4771e-01, -5.4743e-02,  1.0354e-01,  ..., -6.4467e-02,\n",
      "            5.0235e-02, -4.7105e-03],\n",
      "          [ 2.0542e-01,  7.5674e-01, -3.8195e-01,  ...,  7.9123e-01,\n",
      "            3.3666e-01,  3.1182e-01],\n",
      "          [ 1.7716e-02, -2.9456e-01, -4.1132e-01,  ..., -3.7351e-02,\n",
      "           -5.0875e-01,  7.6014e-01]],\n",
      "\n",
      "         [[-1.8205e-02, -3.0886e-03, -1.9086e-02,  ..., -2.5844e-02,\n",
      "            8.7407e-03, -1.7466e-02],\n",
      "          [-7.2501e-01, -4.0966e-01, -5.0878e-02,  ...,  7.9444e-01,\n",
      "           -4.2704e-01, -3.8911e-01],\n",
      "          [-2.3777e-01,  1.8286e-01, -1.1924e-01,  ...,  3.9828e-01,\n",
      "           -9.7823e-02, -7.2584e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[ 1.7386e-02, -2.9366e-01,  2.2930e-01,  ...,  1.6992e+00,\n",
      "           -2.1956e-01, -6.9672e-02],\n",
      "          [ 1.3258e+00,  4.3527e-03, -4.5178e-01,  ..., -3.3861e+00,\n",
      "            6.0934e-01, -9.7994e-02],\n",
      "          [-3.8393e-03,  6.8534e-01, -4.5098e-01,  ..., -3.5777e+00,\n",
      "            4.3510e-01, -1.0692e+00]],\n",
      "\n",
      "         [[ 1.4856e-01,  9.7933e-01, -1.4228e+00,  ..., -1.2427e-01,\n",
      "            2.7183e-01,  9.2512e-01],\n",
      "          [-4.5280e+00, -5.5021e+00,  7.7566e-01,  ...,  3.7731e-02,\n",
      "            2.0070e+00, -6.6960e-01],\n",
      "          [-1.8428e+00, -5.4617e+00, -1.5096e+00,  ..., -1.3806e-01,\n",
      "           -1.6786e+00, -1.6976e+00]],\n",
      "\n",
      "         [[-6.7567e-01,  2.5791e-01, -4.4622e-02,  ...,  1.8188e-01,\n",
      "            3.5410e-02, -2.7977e-01],\n",
      "          [ 7.9076e-01, -6.6335e-01, -1.7585e+00,  ..., -1.6750e+00,\n",
      "           -1.0765e+00, -1.3595e+00],\n",
      "          [ 2.1679e+00, -6.9918e-02,  4.3477e-01,  ...,  1.2724e-01,\n",
      "           -4.9424e-01, -1.1511e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.6750e-02,  1.1317e-01,  1.4411e-01,  ..., -9.5337e-02,\n",
      "            2.8758e-02,  1.7906e-01],\n",
      "          [ 5.2997e-01, -2.4245e-01, -8.6441e-03,  ...,  1.7977e+00,\n",
      "           -1.2685e+00,  6.6169e-01],\n",
      "          [ 1.3688e+00, -5.8446e-01, -1.0249e+00,  ...,  6.1781e-01,\n",
      "           -1.2555e+00,  1.8549e-01]],\n",
      "\n",
      "         [[-3.0175e+00,  3.9929e-01, -3.6378e-02,  ..., -4.7122e-01,\n",
      "           -3.4804e-01,  1.2437e+00],\n",
      "          [ 5.1598e+00, -6.4113e-01, -1.2113e+00,  ..., -5.4299e-01,\n",
      "           -6.3423e-01, -2.7111e+00],\n",
      "          [ 3.9647e+00, -4.5006e-01, -8.1767e-01,  ...,  1.3302e+00,\n",
      "            1.0222e+00, -3.6523e-01]],\n",
      "\n",
      "         [[-1.4068e-02, -2.3846e-01,  2.5290e-02,  ..., -1.6074e-01,\n",
      "            3.3649e-01,  8.6691e-02],\n",
      "          [ 2.8667e-02, -2.1868e+00,  1.7570e-01,  ...,  3.2765e-01,\n",
      "            3.8849e-01, -1.7206e+00],\n",
      "          [-2.3774e-02, -1.9333e+00, -1.1854e-01,  ..., -5.0054e-01,\n",
      "            1.4996e+00, -2.0566e-01]]]], grad_fn=<PermuteBackward0>), tensor([[[[-0.0283, -0.0237, -0.0065,  ..., -0.0032, -0.0248,  0.3515],\n",
      "          [ 0.8264,  0.2939, -0.5176,  ..., -0.2927, -0.2171,  0.0181],\n",
      "          [ 1.9226, -0.7101,  0.3985,  ...,  0.1594,  0.7347, -0.2097]],\n",
      "\n",
      "         [[ 0.0052, -0.0295,  0.0151,  ..., -0.0267,  0.0140,  0.0122],\n",
      "          [-0.5628, -0.9254,  0.9794,  ..., -0.2008,  1.3605, -0.3241],\n",
      "          [ 0.7993,  0.5138, -0.2952,  ..., -0.7700,  0.4493, -0.8436]],\n",
      "\n",
      "         [[-0.0587,  0.0065, -0.0385,  ..., -0.0367,  0.0108, -0.0737],\n",
      "          [-0.3782,  0.4603, -0.0197,  ..., -0.0948, -0.1734, -0.0478],\n",
      "          [-1.0508, -0.9034, -0.1986,  ...,  0.7021,  0.1026,  0.6465]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3268, -0.1926, -0.0725,  ..., -0.4884,  0.2164,  0.0924],\n",
      "          [ 2.4077, -2.1106,  0.0814,  ...,  2.1166,  0.7840, -0.3542],\n",
      "          [ 0.7914, -2.0034, -1.2725,  ...,  0.1668,  0.2048, -0.0149]],\n",
      "\n",
      "         [[-0.0743, -0.1376, -0.0477,  ..., -0.1892, -0.1411,  0.1259],\n",
      "          [-0.8208, -0.8386,  0.6731,  ...,  0.6332,  0.0199, -0.7615],\n",
      "          [ 0.2827,  0.3740, -0.2432,  ...,  0.1827, -0.3376,  0.5142]],\n",
      "\n",
      "         [[-0.0376, -0.0407,  0.1040,  ...,  0.0808, -0.0425,  0.0137],\n",
      "          [ 0.1663, -0.5093,  0.4754,  ..., -0.8001, -0.2647, -0.0260],\n",
      "          [ 0.8517, -0.0424,  0.2084,  ..., -0.4614, -0.3543, -0.4421]]]],\n",
      "       grad_fn=<PermuteBackward0>)), (tensor([[[[-0.3424,  0.8859, -0.1580,  ...,  1.1261, -0.1952,  0.1418],\n",
      "          [-1.9220, -3.5766,  1.0735,  ..., -2.9989,  0.2446,  1.6964],\n",
      "          [ 0.2063, -4.5545, -0.3948,  ..., -2.3682,  0.7526,  1.9643]],\n",
      "\n",
      "         [[ 0.0438,  0.8553, -0.6502,  ..., -0.0481,  0.2985,  0.0131],\n",
      "          [ 1.8581, -0.8676,  0.1191,  ...,  1.4102, -1.5516, -0.8982],\n",
      "          [ 0.3974, -0.7426, -0.8703,  ...,  2.1461,  0.6702, -0.5775]],\n",
      "\n",
      "         [[-0.3069,  0.1418, -0.9771,  ..., -0.3524, -0.0653, -0.1569],\n",
      "          [ 0.5445,  0.2609,  3.3700,  ...,  0.5899,  0.3075,  0.1627],\n",
      "          [ 0.1818, -0.4297,  3.6656,  ...,  0.6535,  0.1625,  1.1807]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3762,  0.0884, -0.0695,  ..., -0.0477,  0.2284,  0.0190],\n",
      "          [ 0.7114,  0.1876, -0.3994,  ..., -0.4909, -1.2776,  0.6404],\n",
      "          [-0.3311,  1.5726, -0.1148,  ...,  1.2293, -0.3279,  1.3483]],\n",
      "\n",
      "         [[ 0.1903,  0.0594,  0.3352,  ...,  0.4228,  0.0194,  0.2240],\n",
      "          [ 0.5933,  0.2881, -0.1408,  ..., -1.5039, -0.2332,  0.3153],\n",
      "          [ 1.1468, -0.2167,  1.2189,  ..., -0.4955,  0.2995,  0.4266]],\n",
      "\n",
      "         [[-3.0269,  0.5562,  0.5756,  ..., -0.9350,  0.3144,  0.1854],\n",
      "          [ 6.4035, -0.2648, -1.7831,  ...,  0.9520, -1.3967, -0.0200],\n",
      "          [ 6.5658, -0.5853, -3.0053,  ...,  1.1486, -0.8413, -1.1981]]]],\n",
      "       grad_fn=<PermuteBackward0>), tensor([[[[ 4.2588e-02, -5.0356e-02,  8.1064e-03,  ..., -7.2504e-02,\n",
      "            9.6370e-03, -9.2134e-02],\n",
      "          [-4.3344e-01,  1.3342e-01, -4.7551e-02,  ...,  4.4079e-01,\n",
      "            2.6153e-01,  1.0634e+00],\n",
      "          [ 3.0987e-01, -1.2253e-01, -8.2554e-01,  ..., -5.1116e-01,\n",
      "           -7.1061e-01,  9.2578e-01]],\n",
      "\n",
      "         [[ 7.9494e-02,  1.9629e-02, -1.4942e-02,  ..., -3.9482e-02,\n",
      "            2.1056e-02, -1.7007e-02],\n",
      "          [ 4.6345e-01, -1.4725e-01,  8.2258e-01,  ...,  3.4143e-01,\n",
      "            6.6487e-02, -1.0046e+00],\n",
      "          [ 4.0347e-01, -8.7195e-01, -1.1793e+00,  ...,  1.0580e+00,\n",
      "            5.7153e-01,  5.3592e-01]],\n",
      "\n",
      "         [[ 6.5061e-02,  1.7394e-02, -1.3197e-02,  ...,  1.9595e-02,\n",
      "           -6.2144e-02, -6.3763e-02],\n",
      "          [-1.1359e-02,  6.8293e-01, -8.8521e-01,  ..., -8.8195e-01,\n",
      "           -9.2533e-01,  1.0995e+00],\n",
      "          [ 7.2526e-01, -6.4550e-01, -1.0321e-01,  ..., -6.4715e-01,\n",
      "           -5.5848e-01,  1.3314e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2369e-03,  2.0590e-02,  1.8059e-02,  ..., -6.7566e-02,\n",
      "           -2.1130e-02,  1.0344e-02],\n",
      "          [-2.6505e-01,  6.8229e-02, -5.8064e-01,  ...,  2.0919e+00,\n",
      "           -2.0487e-01, -6.2631e-02],\n",
      "          [-1.1090e+00, -4.0114e-01,  6.4974e-01,  ...,  1.8533e+00,\n",
      "           -5.9498e-01, -1.5189e+00]],\n",
      "\n",
      "         [[ 4.5884e-02, -1.3652e-02,  3.3538e-02,  ...,  4.2297e-02,\n",
      "           -1.0650e-02,  1.3725e-02],\n",
      "          [ 6.7968e-01, -6.1345e-01, -5.1771e-01,  ...,  3.9566e-01,\n",
      "           -6.3267e-01, -7.4087e-01],\n",
      "          [ 3.2293e-01, -5.0785e-01, -2.0838e+00,  ...,  1.2406e+00,\n",
      "            3.0909e-01,  7.6786e-01]],\n",
      "\n",
      "         [[ 7.6791e-02, -2.0113e-01, -8.1943e-02,  ..., -2.3764e-02,\n",
      "            2.0464e-01, -5.6837e-02],\n",
      "          [ 9.9648e-02, -2.1344e+00,  4.2548e-02,  ...,  4.3812e-01,\n",
      "           -7.9336e-01,  4.1660e-01],\n",
      "          [-1.0473e-01, -8.4764e-01, -1.0118e-01,  ...,  7.0098e-01,\n",
      "           -6.8366e-02, -1.1925e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[ 1.0446, -0.2861, -0.1417,  ...,  0.6163,  0.7392, -0.3206],\n",
      "          [-3.9079, -2.3097,  2.2869,  ..., -1.0490, -3.9810,  0.3166],\n",
      "          [-4.8613, -0.9516,  2.6062,  ..., -0.0303, -3.9882, -0.5383]],\n",
      "\n",
      "         [[-0.1387, -0.0569,  0.1582,  ..., -0.0465, -0.8847, -0.2043],\n",
      "          [-0.5542, -0.0729, -0.3130,  ..., -0.0560, -0.7031,  1.6099],\n",
      "          [-1.3839,  1.4181, -0.2936,  ...,  1.3373, -1.0466,  1.9511]],\n",
      "\n",
      "         [[ 0.1924,  0.3075,  1.1360,  ..., -0.4682,  0.4283, -0.5042],\n",
      "          [ 1.1163, -0.8514, -1.3363,  ..., -0.5048, -2.3173,  1.4079],\n",
      "          [-0.4352, -0.6518, -1.4657,  ...,  0.3762, -3.2430,  2.4583]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1552,  0.0680, -0.2229,  ..., -0.0112,  0.1523,  0.0379],\n",
      "          [-1.4715, -0.2699, -1.0010,  ...,  0.9816, -0.0131, -0.5940],\n",
      "          [-2.8031, -0.0749, -0.5765,  ...,  1.4030,  0.5713, -0.3813]],\n",
      "\n",
      "         [[-0.3520, -2.1820,  0.1305,  ..., -0.0781, -0.0452,  0.9126],\n",
      "          [-0.1676,  0.7424,  0.8457,  ..., -0.0430, -0.6897,  0.9972],\n",
      "          [-1.0619,  3.2376,  2.5831,  ...,  0.4896,  0.5569,  1.1650]],\n",
      "\n",
      "         [[ 0.3705,  0.0804, -0.1422,  ...,  0.6539,  0.1286,  0.2599],\n",
      "          [ 0.2785, -0.1845, -0.7767,  ..., -0.6425,  0.7165, -1.3394],\n",
      "          [-0.0426, -1.2866, -0.2084,  ...,  0.4318,  1.4718,  0.1445]]]],\n",
      "       grad_fn=<PermuteBackward0>), tensor([[[[-3.2128e-02,  4.2769e-02, -6.2959e-02,  ..., -2.4990e-02,\n",
      "           -5.5755e-04,  1.9665e-02],\n",
      "          [ 5.3965e-01,  1.5680e-02, -8.6195e-01,  ..., -6.3801e-01,\n",
      "            3.3483e-02,  2.0060e-01],\n",
      "          [-2.2824e-02,  1.7671e-01, -1.9057e-01,  ..., -6.8474e-01,\n",
      "           -7.3559e-01,  5.6330e-01]],\n",
      "\n",
      "         [[ 8.2081e-03, -2.1715e-02,  3.5759e-02,  ...,  2.5119e-02,\n",
      "           -4.6394e-02,  1.3449e-02],\n",
      "          [-5.6012e-01, -4.7913e-01, -7.3465e-01,  ...,  2.4955e-01,\n",
      "           -2.2302e-01,  1.7230e-02],\n",
      "          [-2.6670e-01, -5.7562e-02, -1.0933e+00,  ...,  6.9102e-01,\n",
      "            8.8651e-01,  2.3362e-01]],\n",
      "\n",
      "         [[ 5.1188e-02, -3.5194e-02,  2.7533e-02,  ...,  1.4181e-02,\n",
      "           -6.4940e-03,  2.2787e-02],\n",
      "          [ 5.1446e-01, -1.3208e+00, -1.0446e+00,  ...,  1.7528e-02,\n",
      "            1.7641e+00, -3.5737e-01],\n",
      "          [-2.7716e-01,  6.2415e-02, -1.8526e+00,  ..., -4.1313e-01,\n",
      "           -5.6179e-01,  1.0078e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8817e-01,  7.5630e-02,  5.1482e-02,  ...,  6.3044e-02,\n",
      "            4.5983e-02, -1.2272e-01],\n",
      "          [-4.8166e-01, -8.0081e-01,  4.7553e-01,  ...,  9.2073e-01,\n",
      "            1.4889e+00, -4.9100e-01],\n",
      "          [ 3.1190e-01, -1.7164e+00, -6.4195e-01,  ..., -3.0160e-01,\n",
      "            9.8333e-01, -1.3910e+00]],\n",
      "\n",
      "         [[-5.8365e-01, -2.0280e-02,  4.3795e-02,  ..., -1.2728e-02,\n",
      "            1.4847e-02, -1.1488e-02],\n",
      "          [ 2.1189e-01,  6.3309e-01, -8.5212e-01,  ...,  1.7114e-02,\n",
      "           -1.6814e-01,  3.3735e-01],\n",
      "          [-5.0398e-01,  1.2201e-01, -9.9508e-01,  ...,  1.0425e+00,\n",
      "            5.1320e-01,  8.6971e-01]],\n",
      "\n",
      "         [[ 1.8879e-02,  8.3848e-02, -5.0716e-02,  ...,  5.5664e-02,\n",
      "            2.9355e-02, -4.1400e-02],\n",
      "          [-3.1205e-01,  3.7567e-01,  3.4224e-01,  ...,  7.1520e-01,\n",
      "            7.5321e-01, -1.1299e-01],\n",
      "          [-1.0119e+00,  3.3448e-01, -1.2705e+00,  ..., -8.8392e-01,\n",
      "           -2.3355e+00, -2.2953e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-0.0307, -2.3328,  0.1644,  ..., -0.2487, -0.2196,  0.0678],\n",
      "          [ 0.6650,  3.8897,  0.2563,  ..., -1.2447, -0.5148,  0.1749],\n",
      "          [ 0.2356,  4.3144,  1.5203,  ..., -1.0305, -0.2740, -0.2970]],\n",
      "\n",
      "         [[-0.8123,  0.2031,  0.4682,  ..., -0.5152,  1.0709,  1.1254],\n",
      "          [ 0.1994,  0.0734,  1.8181,  ..., -0.3085,  1.3158,  0.0689],\n",
      "          [ 0.3287, -0.6436,  2.3493,  ..., -0.1556,  2.4417,  0.1891]],\n",
      "\n",
      "         [[-0.8305,  0.4920,  0.0157,  ...,  0.5054, -0.2322,  1.1760],\n",
      "          [ 1.8285, -1.1218, -0.6011,  ...,  0.1736,  1.3459,  0.1177],\n",
      "          [ 1.6429, -2.1772,  1.7248,  ...,  0.3004,  0.7788,  0.9906]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3011, -0.1166,  0.1344,  ...,  0.1896,  1.7320, -2.8680],\n",
      "          [ 1.9154,  1.2091,  0.2865,  ...,  0.1375, -3.8644,  3.9812],\n",
      "          [ 0.9297, -0.1016, -0.0131,  ..., -0.3652, -4.1451,  4.7426]],\n",
      "\n",
      "         [[ 0.1831,  0.3590,  0.2186,  ..., -0.2198,  0.0324, -0.1362],\n",
      "          [-1.1902,  0.2597,  1.3770,  ...,  1.6082,  0.5330,  0.1014],\n",
      "          [-1.6201,  0.3187,  0.5479,  ...,  0.7933,  0.4122, -0.9289]],\n",
      "\n",
      "         [[ 0.3854,  0.1150,  0.6390,  ...,  0.5310,  0.5793, -0.3318],\n",
      "          [ 0.4067, -0.9364, -1.0314,  ..., -0.6511, -3.1251, -0.3675],\n",
      "          [ 0.9793, -0.9106,  0.2097,  ..., -1.8782, -3.4683,  0.2060]]]],\n",
      "       grad_fn=<PermuteBackward0>), tensor([[[[ 5.3734e-02, -1.4238e-02, -3.5810e-02,  ...,  1.2174e-01,\n",
      "           -5.9948e-02, -4.3049e-02],\n",
      "          [-4.0712e-01,  2.3952e-01, -1.4630e-01,  ..., -4.0966e-01,\n",
      "            8.4789e-01, -2.2644e-01],\n",
      "          [-1.4474e+00, -8.4849e-01, -9.8838e-02,  ..., -2.0224e-01,\n",
      "            6.6301e-01,  7.1867e-01]],\n",
      "\n",
      "         [[ 1.7320e-02,  2.3816e-02,  4.7974e-02,  ..., -4.7309e-03,\n",
      "           -6.8243e-03,  3.2884e-03],\n",
      "          [ 5.4060e-01,  1.3387e+00,  1.0772e+00,  ..., -4.1183e-01,\n",
      "           -7.2695e-02,  7.3047e-01],\n",
      "          [ 1.6604e+00, -1.0405e+00, -4.6418e-02,  ..., -1.5549e-01,\n",
      "            4.8931e-01,  2.6706e-01]],\n",
      "\n",
      "         [[ 5.1727e-02, -3.2729e-02,  6.2675e-02,  ...,  3.5751e-02,\n",
      "           -7.1613e-02, -5.9328e-02],\n",
      "          [-3.5343e-01,  7.5885e-01, -4.1293e-02,  ...,  2.4424e-01,\n",
      "           -6.9912e-01, -5.4976e-01],\n",
      "          [ 7.8512e-02, -4.0856e-01,  5.3512e-01,  ..., -8.2215e-01,\n",
      "            1.6102e-03, -5.0301e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.5711e-02, -3.3712e-02,  3.5806e-02,  ..., -9.8101e-02,\n",
      "            3.3037e-02,  2.1276e-02],\n",
      "          [-1.0548e+00,  1.0086e+00,  3.5336e-01,  ...,  1.4173e-01,\n",
      "            1.1533e+00, -5.7750e-01],\n",
      "          [ 3.0501e-01,  3.8879e-01,  1.4593e+00,  ..., -1.5761e+00,\n",
      "            6.6029e-01, -2.4784e+00]],\n",
      "\n",
      "         [[ 1.5089e-01, -6.4248e-02,  1.3481e-01,  ...,  7.3110e-02,\n",
      "            4.8974e-03, -1.2889e-01],\n",
      "          [ 6.8720e-01,  5.7469e-02, -1.7870e-01,  ..., -1.1156e+00,\n",
      "           -1.2297e+00,  1.5925e-02],\n",
      "          [ 4.6848e-01,  6.8089e-01,  4.5960e-01,  ..., -3.4666e-01,\n",
      "           -8.2155e-01,  7.9260e-01]],\n",
      "\n",
      "         [[ 2.1724e-01, -6.2232e-02, -5.5712e-02,  ...,  2.1461e-02,\n",
      "            4.3089e-02,  3.7415e-02],\n",
      "          [ 1.3125e+00, -4.4910e-01, -7.5738e-01,  ...,  3.2747e-01,\n",
      "           -9.8980e-02, -8.0641e-02],\n",
      "          [-1.6063e-01, -7.7957e-01, -1.6312e-01,  ..., -4.8402e-01,\n",
      "            8.7137e-01, -2.5966e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[ 0.0330, -0.2443, -0.4450,  ...,  0.3008,  0.3268,  0.3659],\n",
      "          [-0.3192,  1.1035, -0.8162,  ..., -1.0129, -0.1036, -0.3472],\n",
      "          [ 0.1205,  0.8549, -0.4764,  ...,  0.2566, -0.7220,  0.7049]],\n",
      "\n",
      "         [[-0.2795,  0.1526,  0.1226,  ...,  0.0639, -1.1406, -0.1380],\n",
      "          [ 0.7580,  0.7341,  2.4232,  ..., -0.1708, -1.2876,  0.6498],\n",
      "          [ 0.5916, -0.2539,  0.9164,  ...,  1.4073, -0.9961,  1.3304]],\n",
      "\n",
      "         [[-1.2364, -0.1086,  0.5761,  ..., -0.6571,  0.4645, -0.2915],\n",
      "          [ 0.5420,  0.4598, -0.1322,  ...,  0.6880,  0.3785,  0.7010],\n",
      "          [ 1.0557,  0.3795,  0.1000,  ...,  1.0149, -0.0800,  0.3112]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.7895, -0.9088, -0.3937,  ..., -1.0515, -0.4384,  0.4840],\n",
      "          [ 1.0609, -1.1448, -0.7739,  ..., -0.4119, -0.8288, -0.6035],\n",
      "          [ 0.5019, -0.6596, -0.0573,  ..., -1.2351, -0.6160, -0.5357]],\n",
      "\n",
      "         [[-0.9265,  2.5459,  0.3060,  ...,  0.3449,  1.9553, -0.5489],\n",
      "          [ 0.4586, -2.1932,  0.1746,  ...,  1.7436, -2.5849,  2.2585],\n",
      "          [ 0.0179, -2.7316,  0.2156,  ...,  0.6861, -4.1920,  1.6138]],\n",
      "\n",
      "         [[-2.0252, -0.3505, -1.1153,  ..., -0.3979,  0.0609,  0.2531],\n",
      "          [ 2.0696, -0.4951,  1.0584,  ...,  0.7401,  0.4907,  0.5746],\n",
      "          [ 2.5638,  1.1148, -0.5530,  ...,  0.1207,  0.3651, -0.1726]]]],\n",
      "       grad_fn=<PermuteBackward0>), tensor([[[[-5.9407e-02, -8.5679e-02,  1.7007e-02,  ...,  1.0696e-01,\n",
      "           -2.7256e-02,  1.2712e-02],\n",
      "          [-1.1028e-01, -2.6695e-01, -2.7972e-01,  ...,  7.3320e-02,\n",
      "            8.1304e-02,  9.9563e-01],\n",
      "          [ 2.2058e-01,  5.5392e-01, -1.4877e+00,  ..., -2.8705e-01,\n",
      "            3.1862e-01,  8.9564e-01]],\n",
      "\n",
      "         [[ 1.9984e-02,  9.9456e-03, -1.8535e-02,  ...,  2.8180e-02,\n",
      "            3.0411e-02,  5.3315e-02],\n",
      "          [ 5.9644e-01,  5.1996e-01, -1.2417e+00,  ..., -7.3599e-02,\n",
      "            1.1115e+00,  4.7235e-01],\n",
      "          [ 9.7821e-01, -1.1090e+00, -1.6003e-01,  ...,  1.1247e+00,\n",
      "           -1.9147e-01,  2.4299e-01]],\n",
      "\n",
      "         [[ 3.0771e-02,  3.3925e-02, -9.5088e-02,  ...,  2.0078e-02,\n",
      "           -1.8055e-03,  3.6985e-03],\n",
      "          [-7.0360e-01,  1.2550e-01,  2.7324e-01,  ...,  2.4933e-01,\n",
      "           -1.0440e+00,  2.5170e+00],\n",
      "          [-3.4458e-01, -8.2069e-01, -4.0843e-01,  ..., -7.7839e-01,\n",
      "           -7.3081e-01, -2.8720e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.2988e-02,  1.8975e-02, -2.9906e-03,  ..., -2.4181e-03,\n",
      "           -7.7697e-04,  3.6506e-02],\n",
      "          [ 1.0896e+00, -5.7907e-01,  2.7873e-01,  ...,  5.9871e-01,\n",
      "            2.0423e+00, -1.8797e-01],\n",
      "          [ 1.1956e+00, -2.4500e-01,  9.7125e-01,  ...,  7.4841e-01,\n",
      "           -1.6449e-01, -7.1359e-01]],\n",
      "\n",
      "         [[-6.6889e-02, -4.6806e-02,  1.3993e-02,  ...,  1.3800e-02,\n",
      "           -6.0449e-02, -1.0146e-01],\n",
      "          [-1.2984e-01, -3.9512e-01,  9.2745e-02,  ...,  2.9087e-01,\n",
      "            1.8776e-01, -2.5012e-02],\n",
      "          [ 1.4572e+00, -1.4012e-01,  1.1444e-01,  ...,  2.8305e-01,\n",
      "           -3.2234e-01, -1.2569e-01]],\n",
      "\n",
      "         [[-1.5357e-02,  3.5532e-02, -6.0959e-02,  ..., -2.2750e-02,\n",
      "            4.1217e-03,  3.3249e-03],\n",
      "          [-4.9697e-01, -9.3557e-01, -6.3136e-02,  ...,  6.6151e-01,\n",
      "            4.0965e-01, -7.5031e-02],\n",
      "          [-4.4715e-02, -6.6199e-01, -9.2861e-01,  ...,  5.9766e-01,\n",
      "            2.3181e-01, -2.1284e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-0.5168,  0.5003, -0.8527,  ..., -1.0179, -1.3143,  0.2035],\n",
      "          [ 0.5839,  0.4706, -0.0539,  ...,  0.7804, -0.5336, -0.4840],\n",
      "          [ 0.6194, -0.1866,  0.5777,  ...,  1.4978, -0.3987, -1.0123]],\n",
      "\n",
      "         [[ 0.8600, -2.0708,  0.1513,  ...,  0.2453, -2.4785, -0.4229],\n",
      "          [ 1.3937, -0.5899,  1.3122,  ...,  1.7829, -0.9209,  0.0461],\n",
      "          [ 1.2642,  1.6078,  0.4370,  ...,  0.8510,  0.5742, -0.4311]],\n",
      "\n",
      "         [[ 1.0033,  0.3818, -0.1770,  ..., -0.8112, -1.4041, -0.3646],\n",
      "          [-0.8060, -0.2143, -1.7062,  ...,  1.3577, -0.0913,  0.3456],\n",
      "          [-0.1113, -0.4196, -1.3489,  ...,  1.2174,  0.0079,  0.0536]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2209, -0.5819,  0.4830,  ..., -0.6500,  1.0846,  0.2841],\n",
      "          [-0.4176, -0.2444, -0.1033,  ..., -1.9155, -1.5817,  0.6707],\n",
      "          [-1.1385,  1.7267, -2.5488,  ..., -2.3843, -1.3253,  0.6908]],\n",
      "\n",
      "         [[ 0.2557,  0.5515,  0.5423,  ...,  0.7245,  0.0758,  0.8386],\n",
      "          [ 0.0373,  1.1293, -0.8812,  ...,  1.3053,  0.1991,  1.0668],\n",
      "          [ 0.1955,  1.5928, -0.9004,  ...,  0.8965, -0.3034, -0.3748]],\n",
      "\n",
      "         [[-0.7103,  0.3011, -1.5822,  ..., -0.4242,  0.2360, -1.3157],\n",
      "          [ 0.0054,  1.0721,  1.2615,  ...,  0.6028, -0.2910,  0.4983],\n",
      "          [-0.3964,  0.6106, -0.1719,  ...,  1.1167, -0.9742,  1.4335]]]],\n",
      "       grad_fn=<PermuteBackward0>), tensor([[[[-6.0669e-03,  4.1580e-02, -6.0121e-02,  ...,  5.8650e-02,\n",
      "           -5.0545e-02, -7.4066e-02],\n",
      "          [-1.3468e+00,  1.2899e-01,  1.0814e+00,  ..., -3.7751e-01,\n",
      "           -3.3316e-01, -2.1959e-01],\n",
      "          [-5.5962e-01,  5.0996e-01,  1.2739e+00,  ..., -3.0220e-01,\n",
      "            1.1736e-01,  8.0562e-01]],\n",
      "\n",
      "         [[ 5.0298e-02, -3.1196e-03,  2.3202e-02,  ..., -2.5890e-02,\n",
      "           -1.5499e-02, -2.3228e-02],\n",
      "          [-1.0113e+00,  5.7627e-01,  4.9574e-01,  ..., -3.2675e-01,\n",
      "            1.8657e-01,  8.2123e-01],\n",
      "          [ 1.4849e-01,  7.7403e-01, -1.0155e+00,  ...,  3.1667e-01,\n",
      "           -1.8597e-01,  4.8591e-01]],\n",
      "\n",
      "         [[-2.1214e-02,  3.3352e-02, -8.7513e-02,  ..., -8.9314e-03,\n",
      "            3.0822e-02,  3.8786e-02],\n",
      "          [-5.2402e-01, -2.6213e-01, -2.3345e-01,  ...,  3.4806e-01,\n",
      "            1.7069e-01, -2.4748e-04],\n",
      "          [-4.9385e-01,  4.8865e-01, -4.3231e-01,  ...,  7.6064e-01,\n",
      "           -2.9905e-02,  1.8609e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0483e-01,  3.7457e-02, -1.1568e-03,  ..., -4.4699e-02,\n",
      "           -8.8918e-03,  1.7837e-02],\n",
      "          [ 8.6269e-01, -1.4697e-01,  3.6745e-01,  ...,  3.1546e-01,\n",
      "            3.5174e-02, -3.0443e-01],\n",
      "          [ 5.1551e-01,  2.5198e-01,  1.5730e-01,  ...,  1.4892e+00,\n",
      "           -5.0922e-01,  2.0167e+00]],\n",
      "\n",
      "         [[ 9.2671e-02,  1.3452e-02,  5.3226e-02,  ...,  3.1512e-03,\n",
      "            4.3145e-02,  1.1899e-02],\n",
      "          [-1.5642e-01,  1.9026e-01,  7.6595e-01,  ..., -1.3407e-01,\n",
      "            2.6676e-01, -5.0297e-01],\n",
      "          [ 6.1654e-01,  8.3766e-01,  1.0002e+00,  ...,  1.2987e-01,\n",
      "            1.4224e+00, -4.2694e-01]],\n",
      "\n",
      "         [[-1.0774e-01,  2.8406e-02, -5.5795e-02,  ..., -8.4050e-02,\n",
      "            6.1122e-02, -6.3834e-03],\n",
      "          [ 2.9482e-01, -4.6036e-01, -5.0067e-01,  ..., -4.2501e-01,\n",
      "            1.4048e+00,  3.5767e-02],\n",
      "          [-7.1402e-01, -6.3282e-01, -6.3516e-01,  ..., -1.0530e+00,\n",
      "            4.5487e-01, -1.2223e+00]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-1.7151, -0.3351, -0.2937,  ...,  0.1779,  0.3182, -0.4845],\n",
      "          [-0.0573, -0.2968, -0.2792,  ...,  1.8097, -0.9933, -0.0485],\n",
      "          [ 0.4551,  0.2350, -0.5202,  ...,  1.4073, -1.1556, -0.5031]],\n",
      "\n",
      "         [[ 0.1182, -0.0641,  2.3043,  ...,  0.2435,  0.0934, -0.1985],\n",
      "          [ 0.3078, -0.7078, -0.0229,  ..., -0.1684,  0.3255,  0.4997],\n",
      "          [-0.0072, -1.4351, -0.3262,  ..., -0.0116, -0.4237, -1.0236]],\n",
      "\n",
      "         [[-0.1897,  1.0560,  0.4685,  ..., -0.5601,  0.3216, -0.1095],\n",
      "          [-1.2898,  0.1961,  0.3851,  ...,  0.0611, -0.4468, -0.4500],\n",
      "          [-1.2418, -0.5390, -0.3550,  ...,  1.1175,  0.2285, -0.6764]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.5702,  0.9629, -0.8822,  ..., -0.7408,  0.6916,  0.8577],\n",
      "          [ 1.1006,  1.7073, -1.6259,  ..., -0.9801, -0.5523,  0.2173],\n",
      "          [ 0.6847,  1.8472, -0.7955,  ..., -0.5540, -0.5932,  0.3027]],\n",
      "\n",
      "         [[-0.4207,  0.3802,  0.3173,  ...,  0.7072,  0.0623, -0.0753],\n",
      "          [-0.9885,  1.0626, -0.9565,  ..., -0.0961, -0.5346, -1.2537],\n",
      "          [-0.8144,  1.0409, -0.3393,  ...,  0.7575, -0.7873, -0.3033]],\n",
      "\n",
      "         [[-0.7356, -0.0250,  0.4452,  ..., -0.0942,  0.0330, -0.0571],\n",
      "          [ 0.1039, -0.4520,  1.6473,  ...,  0.0384, -0.3122,  0.2989],\n",
      "          [ 0.0984, -1.1736,  1.5161,  ...,  0.2564, -0.7524, -0.1577]]]],\n",
      "       grad_fn=<PermuteBackward0>), tensor([[[[ 0.0627, -0.1041, -0.1861,  ..., -0.2973,  0.2617, -0.1300],\n",
      "          [ 0.9190, -0.4094,  0.9732,  ...,  0.7065, -1.3206,  1.6103],\n",
      "          [-0.3314,  0.7099,  0.8130,  ...,  1.2446, -1.0029,  1.6824]],\n",
      "\n",
      "         [[ 0.0701, -0.0366,  0.0433,  ..., -0.0205, -0.1226,  0.1881],\n",
      "          [-0.4828,  0.0397,  0.1133,  ...,  0.6646, -0.4122, -0.4976],\n",
      "          [-0.0560,  0.5185, -0.3796,  ..., -0.0358, -1.7324, -0.5987]],\n",
      "\n",
      "         [[ 0.0102,  0.0407, -0.0427,  ...,  0.0176,  0.0324,  0.0545],\n",
      "          [-0.8474, -0.1339,  0.6198,  ..., -1.1320, -0.1028,  0.0237],\n",
      "          [-0.3179,  0.2617, -0.2293,  ..., -0.3102, -0.2109,  0.9155]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0194, -0.0276,  0.0886,  ...,  0.0796, -0.0209,  0.0248],\n",
      "          [-0.7218,  0.9741,  0.7868,  ..., -0.1377, -0.3252, -1.0529],\n",
      "          [ 0.0102,  0.0130,  0.1943,  ...,  1.0051,  0.9481, -0.4571]],\n",
      "\n",
      "         [[-0.1515, -0.0920,  0.0492,  ..., -0.0616,  0.0336, -0.0914],\n",
      "          [ 0.1947,  0.3574,  0.4865,  ..., -0.0827, -0.0695,  0.1024],\n",
      "          [ 0.0617, -0.4696,  0.1419,  ..., -0.5913, -0.3143,  0.7776]],\n",
      "\n",
      "         [[ 0.1127, -0.1414,  0.0995,  ..., -0.1078,  0.0248, -0.1947],\n",
      "          [ 0.3453, -0.7535,  0.9195,  ...,  0.1146, -0.0401,  0.5830],\n",
      "          [-0.6160, -0.7786,  1.2499,  ..., -1.0763,  0.0126, -0.6472]]]],\n",
      "       grad_fn=<PermuteBackward0>))), hidden_states=None, attentions=None, cross_attentions=None)\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "gpt2_t = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "gpt2_m = GPT2Model.from_pretrained(\"gpt2\")\n",
    "text = \"Replace me\"\n",
    "encoded_input = gpt2_t(text, return_tensors=\"pt\")\n",
    "output = gpt2_m(**encoded_input)\n",
    "print(output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "<bound method Module._call_impl of GPT2Model(\n  (wte): Embedding(50257, 768)\n  (wpe): Embedding(1024, 768)\n  (drop): Dropout(p=0.1, inplace=False)\n  (h): ModuleList(\n    (0): GPT2Block(\n      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (attn): GPT2Attention(\n        (c_attn): Conv1D()\n        (c_proj): Conv1D()\n        (attn_dropout): Dropout(p=0.1, inplace=False)\n        (resid_dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPT2MLP(\n        (c_fc): Conv1D()\n        (c_proj): Conv1D()\n        (act): NewGELUActivation()\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n    )\n    (1): GPT2Block(\n      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (attn): GPT2Attention(\n        (c_attn): Conv1D()\n        (c_proj): Conv1D()\n        (attn_dropout): Dropout(p=0.1, inplace=False)\n        (resid_dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPT2MLP(\n        (c_fc): Conv1D()\n        (c_proj): Conv1D()\n        (act): NewGELUActivation()\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n    )\n    (2): GPT2Block(\n      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (attn): GPT2Attention(\n        (c_attn): Conv1D()\n        (c_proj): Conv1D()\n        (attn_dropout): Dropout(p=0.1, inplace=False)\n        (resid_dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPT2MLP(\n        (c_fc): Conv1D()\n        (c_proj): Conv1D()\n        (act): NewGELUActivation()\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n    )\n    (3): GPT2Block(\n      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (attn): GPT2Attention(\n        (c_attn): Conv1D()\n        (c_proj): Conv1D()\n        (attn_dropout): Dropout(p=0.1, inplace=False)\n        (resid_dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPT2MLP(\n        (c_fc): Conv1D()\n        (c_proj): Conv1D()\n        (act): NewGELUActivation()\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n    )\n    (4): GPT2Block(\n      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (attn): GPT2Attention(\n        (c_attn): Conv1D()\n        (c_proj): Conv1D()\n        (attn_dropout): Dropout(p=0.1, inplace=False)\n        (resid_dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPT2MLP(\n        (c_fc): Conv1D()\n        (c_proj): Conv1D()\n        (act): NewGELUActivation()\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n    )\n    (5): GPT2Block(\n      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (attn): GPT2Attention(\n        (c_attn): Conv1D()\n        (c_proj): Conv1D()\n        (attn_dropout): Dropout(p=0.1, inplace=False)\n        (resid_dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPT2MLP(\n        (c_fc): Conv1D()\n        (c_proj): Conv1D()\n        (act): NewGELUActivation()\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n    )\n    (6): GPT2Block(\n      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (attn): GPT2Attention(\n        (c_attn): Conv1D()\n        (c_proj): Conv1D()\n        (attn_dropout): Dropout(p=0.1, inplace=False)\n        (resid_dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPT2MLP(\n        (c_fc): Conv1D()\n        (c_proj): Conv1D()\n        (act): NewGELUActivation()\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n    )\n    (7): GPT2Block(\n      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (attn): GPT2Attention(\n        (c_attn): Conv1D()\n        (c_proj): Conv1D()\n        (attn_dropout): Dropout(p=0.1, inplace=False)\n        (resid_dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPT2MLP(\n        (c_fc): Conv1D()\n        (c_proj): Conv1D()\n        (act): NewGELUActivation()\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n    )\n    (8): GPT2Block(\n      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (attn): GPT2Attention(\n        (c_attn): Conv1D()\n        (c_proj): Conv1D()\n        (attn_dropout): Dropout(p=0.1, inplace=False)\n        (resid_dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPT2MLP(\n        (c_fc): Conv1D()\n        (c_proj): Conv1D()\n        (act): NewGELUActivation()\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n    )\n    (9): GPT2Block(\n      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (attn): GPT2Attention(\n        (c_attn): Conv1D()\n        (c_proj): Conv1D()\n        (attn_dropout): Dropout(p=0.1, inplace=False)\n        (resid_dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPT2MLP(\n        (c_fc): Conv1D()\n        (c_proj): Conv1D()\n        (act): NewGELUActivation()\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n    )\n    (10): GPT2Block(\n      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (attn): GPT2Attention(\n        (c_attn): Conv1D()\n        (c_proj): Conv1D()\n        (attn_dropout): Dropout(p=0.1, inplace=False)\n        (resid_dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPT2MLP(\n        (c_fc): Conv1D()\n        (c_proj): Conv1D()\n        (act): NewGELUActivation()\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n    )\n    (11): GPT2Block(\n      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (attn): GPT2Attention(\n        (c_attn): Conv1D()\n        (c_proj): Conv1D()\n        (attn_dropout): Dropout(p=0.1, inplace=False)\n        (resid_dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPT2MLP(\n        (c_fc): Conv1D()\n        (c_proj): Conv1D()\n        (act): NewGELUActivation()\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n    )\n  )\n  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n)>"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_m.__call__"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'GPT2Model' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'CodeGenForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegatronBertForCausalLM', 'MvpForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel'].\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "The current model class (GPT2Model) is not compatible with `.generate()`, as it doesn't have a language model head. Please use one of the following classes instead: {'GPT2LMHeadModel'}",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pipeline\n\u001B[1;32m      2\u001B[0m gpt2_p \u001B[38;5;241m=\u001B[39m pipeline(task\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext-generation\u001B[39m\u001B[38;5;124m\"\u001B[39m, model\u001B[38;5;241m=\u001B[39mgpt2_m, tokenizer\u001B[38;5;241m=\u001B[39mgpt2_t)\n\u001B[0;32m----> 3\u001B[0m \u001B[43mgpt2_p\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/git/vladsaveliev/deeplearning/pretgpt/venv/lib/python3.10/site-packages/transformers/pipelines/text_generation.py:210\u001B[0m, in \u001B[0;36mTextGenerationPipeline.__call__\u001B[0;34m(self, text_inputs, **kwargs)\u001B[0m\n\u001B[1;32m    169\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, text_inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    170\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    171\u001B[0m \u001B[38;5;124;03m    Complete the prompt(s) given as inputs.\u001B[39;00m\n\u001B[1;32m    172\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    208\u001B[0m \u001B[38;5;124;03m          ids of the generated text.\u001B[39;00m\n\u001B[1;32m    209\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 210\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtext_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/git/vladsaveliev/deeplearning/pretgpt/venv/lib/python3.10/site-packages/transformers/pipelines/base.py:1084\u001B[0m, in \u001B[0;36mPipeline.__call__\u001B[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1076\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mnext\u001B[39m(\n\u001B[1;32m   1077\u001B[0m         \u001B[38;5;28miter\u001B[39m(\n\u001B[1;32m   1078\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_iterator(\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1081\u001B[0m         )\n\u001B[1;32m   1082\u001B[0m     )\n\u001B[1;32m   1083\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1084\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_single\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreprocess_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforward_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpostprocess_params\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/git/vladsaveliev/deeplearning/pretgpt/venv/lib/python3.10/site-packages/transformers/pipelines/base.py:1091\u001B[0m, in \u001B[0;36mPipeline.run_single\u001B[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001B[0m\n\u001B[1;32m   1089\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun_single\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001B[1;32m   1090\u001B[0m     model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpreprocess(inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpreprocess_params)\n\u001B[0;32m-> 1091\u001B[0m     model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mforward_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1092\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpostprocess(model_outputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpostprocess_params)\n\u001B[1;32m   1093\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m outputs\n",
      "File \u001B[0;32m~/git/vladsaveliev/deeplearning/pretgpt/venv/lib/python3.10/site-packages/transformers/pipelines/base.py:992\u001B[0m, in \u001B[0;36mPipeline.forward\u001B[0;34m(self, model_inputs, **forward_params)\u001B[0m\n\u001B[1;32m    990\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m inference_context():\n\u001B[1;32m    991\u001B[0m         model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ensure_tensor_on_device(model_inputs, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m--> 992\u001B[0m         model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mforward_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    993\u001B[0m         model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ensure_tensor_on_device(model_outputs, device\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m    994\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/git/vladsaveliev/deeplearning/pretgpt/venv/lib/python3.10/site-packages/transformers/pipelines/text_generation.py:252\u001B[0m, in \u001B[0;36mTextGenerationPipeline._forward\u001B[0;34m(self, model_inputs, **generate_kwargs)\u001B[0m\n\u001B[1;32m    250\u001B[0m prompt_text \u001B[38;5;241m=\u001B[39m model_inputs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprompt_text\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    251\u001B[0m \u001B[38;5;66;03m# BS x SL\u001B[39;00m\n\u001B[0;32m--> 252\u001B[0m generated_sequence \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mgenerate_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    253\u001B[0m out_b \u001B[38;5;241m=\u001B[39m generated_sequence\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    254\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mframework \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[0;32m~/git/vladsaveliev/deeplearning/pretgpt/venv/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001B[0m, in \u001B[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclone():\n\u001B[0;32m---> 27\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/git/vladsaveliev/deeplearning/pretgpt/venv/lib/python3.10/site-packages/transformers/generation/utils.py:1177\u001B[0m, in \u001B[0;36mGenerationMixin.generate\u001B[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, **kwargs)\u001B[0m\n\u001B[1;32m   1106\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1107\u001B[0m \n\u001B[1;32m   1108\u001B[0m \u001B[38;5;124;03mGenerates sequences of token ids for models with a language modeling head.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1174\u001B[0m \u001B[38;5;124;03m            - [`~generation.BeamSampleEncoderDecoderOutput`]\u001B[39;00m\n\u001B[1;32m   1175\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1176\u001B[0m \u001B[38;5;66;03m# 1. Handle `generation_config` and kwargs that might update it, and validate the `.generate()` call\u001B[39;00m\n\u001B[0;32m-> 1177\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_model_class\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1179\u001B[0m \u001B[38;5;66;03m# priority: `generation_config` argument > `model.generation_config` (the default generation config)\u001B[39;00m\n\u001B[1;32m   1180\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m generation_config \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1181\u001B[0m     \u001B[38;5;66;03m# legacy: users may modify the model configuration to control generation -- update the generation config\u001B[39;00m\n\u001B[1;32m   1182\u001B[0m     \u001B[38;5;66;03m# model attribute accordingly, if it was created from the model config\u001B[39;00m\n",
      "File \u001B[0;32m~/git/vladsaveliev/deeplearning/pretgpt/venv/lib/python3.10/site-packages/transformers/generation/utils.py:1070\u001B[0m, in \u001B[0;36mGenerationMixin._validate_model_class\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1068\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m generate_compatible_classes:\n\u001B[1;32m   1069\u001B[0m     exception_message \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m Please use one of the following classes instead: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mgenerate_compatible_classes\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 1070\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(exception_message)\n",
      "\u001B[0;31mTypeError\u001B[0m: The current model class (GPT2Model) is not compatible with `.generate()`, as it doesn't have a language model head. Please use one of the following classes instead: {'GPT2LMHeadModel'}"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "gpt2_p = pipeline(task=\"text-generation\", model=gpt2_m, tokenizer=gpt2_t)\n",
    "gpt2_p(text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vlad/git/vladsaveliev/deeplearning/pretgpt/venv/lib/python3.10/site-packages/transformers/generation/utils.py:1186: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": "[{'generated_text': 'Replace me, you f****** dog, I\\'m your f***** partner, all the time.\" \"I won\\'t, I won\\'t let you get closer or leave.\" With that, the girl in the pink uniform left once more, leaving, and went off towards the side of the road on her way to meet the person at the door. \"Hey!\" Her voice was heavy with anger. \"Why am I not happy to see you again? Is that why you\\'re still here?!\" He looked out'}]"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_p = pipeline('text-generation', model='gpt2')\n",
    "gpt2_p(text, max_new_tokens=100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re\n",
      "place\n",
      " me\n"
     ]
    }
   ],
   "source": [
    "for id in gpt2_t(\"Replace me\")['input_ids']:\n",
    "    print(gpt2_t.decode(id))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters in train text: 10,127,380\n",
      "Characters in test text: 27,685\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "drive_path = Path(\"/Users/vlad/MyDrive/AI\")\n",
    "data_dir = drive_path / \"datasets\" / \"murakami\"\n",
    "with open(data_dir / \"murakami_train.txt\", \"r\") as f:\n",
    "    train_text = f.read()\n",
    "    print(f\"Characters in train text: {len(train_text):,}\")\n",
    "with open(data_dir / \"murakami_test.txt\", \"r\") as f:\n",
    "    test_text = f.read()\n",
    "    print(f\"Characters in test text: {len(test_text):,}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "train_ids = tokenizer(train_text)\n",
    "test_ids = tokenizer(test_text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens in train text: 2,503,609\n",
      "Tokens in test text: 7,521\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tokens in train text: {len(train_ids['input_ids']):,}\")\n",
    "print(f\"Tokens in test text: {len(test_ids['input_ids']):,}\")\n",
    "# Export to bin arrays\n",
    "import numpy as np\n",
    "np.save(data_dir / \"train_token_ids.npy\", np.array(train_ids['input_ids']))\n",
    "np.save(data_dir / \"test_token_ids.npy\", np.array(test_ids['input_ids']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "train_ids = np.memmap(data_dir / \"train_token_ids.npy\", mode=\"r\")\n",
    "test_ids = np.memmap(data_dir / \"test_token_ids.npy\", mode=\"r\")\n",
    "\n",
    "class MurakamiDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, token_ids: np.memmap):\n",
    "        self.token_ids = token_ids\n",
    "        self.n_ctx = model.config.n_ctx\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.token_ids[idx:idx + self.n_ctx])\n",
    "        y = torch.tensor(self.token_ids[idx + 1:idx + 1 + self.n_ctx])\n",
    "        item = {\"input_ids\": x, \"labels\": y}\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.token_ids) - self.n_ctx\n",
    "\n",
    "train_set = MurakamiDataset(train_ids)\n",
    "test_set = MurakamiDataset(test_ids)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vlad/git/vladsaveliev/deeplearning/pretgpt/venv/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 20026952\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7510107\n",
      "  Number of trainable parameters = 125231616\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.ByteTensor instead (while checking arguments for embedding)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 25\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# metric = evaluate.load(\"accuracy\")\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# \u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# def compute_metrics(eval_pred):\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m#     logits, labels = eval_pred\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m#     predictions = np.argmax(logits, axis=-1)\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m#     return metric.compute(predictions=predictions, references=labels)\u001B[39;00m\n\u001B[1;32m     12\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(\n\u001B[1;32m     13\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[1;32m     14\u001B[0m     args\u001B[38;5;241m=\u001B[39mTrainingArguments(\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     23\u001B[0m     \u001B[38;5;66;03m# compute_metrics=compute_metrics,\u001B[39;00m\n\u001B[1;32m     24\u001B[0m )\n\u001B[0;32m---> 25\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/git/vladsaveliev/deeplearning/pretgpt/venv/lib/python3.10/site-packages/transformers/trainer.py:1543\u001B[0m, in \u001B[0;36mTrainer.train\u001B[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[1;32m   1538\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_wrapped \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\n\u001B[1;32m   1540\u001B[0m inner_training_loop \u001B[38;5;241m=\u001B[39m find_executable_batch_size(\n\u001B[1;32m   1541\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inner_training_loop, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_train_batch_size, args\u001B[38;5;241m.\u001B[39mauto_find_batch_size\n\u001B[1;32m   1542\u001B[0m )\n\u001B[0;32m-> 1543\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1544\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1545\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1546\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1547\u001B[0m \u001B[43m    \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1548\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/git/vladsaveliev/deeplearning/pretgpt/venv/lib/python3.10/site-packages/transformers/trainer.py:1791\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[1;32m   1789\u001B[0m         tr_loss_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining_step(model, inputs)\n\u001B[1;32m   1790\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1791\u001B[0m     tr_loss_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1793\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m   1794\u001B[0m     args\u001B[38;5;241m.\u001B[39mlogging_nan_inf_filter\n\u001B[1;32m   1795\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torch_tpu_available()\n\u001B[1;32m   1796\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (torch\u001B[38;5;241m.\u001B[39misnan(tr_loss_step) \u001B[38;5;129;01mor\u001B[39;00m torch\u001B[38;5;241m.\u001B[39misinf(tr_loss_step))\n\u001B[1;32m   1797\u001B[0m ):\n\u001B[1;32m   1798\u001B[0m     \u001B[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001B[39;00m\n\u001B[1;32m   1799\u001B[0m     tr_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m tr_loss \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mglobal_step \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_globalstep_last_logged)\n",
      "File \u001B[0;32m~/git/vladsaveliev/deeplearning/pretgpt/venv/lib/python3.10/site-packages/transformers/trainer.py:2539\u001B[0m, in \u001B[0;36mTrainer.training_step\u001B[0;34m(self, model, inputs)\u001B[0m\n\u001B[1;32m   2536\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m loss_mb\u001B[38;5;241m.\u001B[39mreduce_mean()\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m   2538\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_loss_context_manager():\n\u001B[0;32m-> 2539\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2541\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mn_gpu \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   2542\u001B[0m     loss \u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mmean()  \u001B[38;5;66;03m# mean() to average on multi-gpu parallel training\u001B[39;00m\n",
      "File \u001B[0;32m~/git/vladsaveliev/deeplearning/pretgpt/venv/lib/python3.10/site-packages/transformers/trainer.py:2571\u001B[0m, in \u001B[0;36mTrainer.compute_loss\u001B[0;34m(self, model, inputs, return_outputs)\u001B[0m\n\u001B[1;32m   2569\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   2570\u001B[0m     labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 2571\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2572\u001B[0m \u001B[38;5;66;03m# Save past state if it exists\u001B[39;00m\n\u001B[1;32m   2573\u001B[0m \u001B[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001B[39;00m\n\u001B[1;32m   2574\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mpast_index \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/git/vladsaveliev/deeplearning/pretgpt/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/git/vladsaveliev/deeplearning/pretgpt/venv/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:1043\u001B[0m, in \u001B[0;36mGPT2LMHeadModel.forward\u001B[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1035\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1036\u001B[0m \u001B[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001B[39;00m\n\u001B[1;32m   1037\u001B[0m \u001B[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001B[39;00m\n\u001B[1;32m   1038\u001B[0m \u001B[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001B[39;00m\n\u001B[1;32m   1039\u001B[0m \u001B[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001B[39;00m\n\u001B[1;32m   1040\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1041\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[0;32m-> 1043\u001B[0m transformer_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransformer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1044\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1045\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1046\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1047\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1048\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1049\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1050\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1051\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1052\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1053\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1054\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1055\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1056\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1057\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1058\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m transformer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m   1060\u001B[0m \u001B[38;5;66;03m# Set device for model parallelism\u001B[39;00m\n",
      "File \u001B[0;32m~/git/vladsaveliev/deeplearning/pretgpt/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/git/vladsaveliev/deeplearning/pretgpt/venv/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:830\u001B[0m, in \u001B[0;36mGPT2Model.forward\u001B[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    827\u001B[0m head_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_head_mask(head_mask, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mn_layer)\n\u001B[1;32m    829\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m inputs_embeds \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 830\u001B[0m     inputs_embeds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwte\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    831\u001B[0m position_embeds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwpe(position_ids)\n\u001B[1;32m    832\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m inputs_embeds \u001B[38;5;241m+\u001B[39m position_embeds\n",
      "File \u001B[0;32m~/git/vladsaveliev/deeplearning/pretgpt/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/git/vladsaveliev/deeplearning/pretgpt/venv/lib/python3.10/site-packages/torch/nn/modules/sparse.py:160\u001B[0m, in \u001B[0;36mEmbedding.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    159\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 160\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    161\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_norm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    162\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnorm_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscale_grad_by_freq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msparse\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/git/vladsaveliev/deeplearning/pretgpt/venv/lib/python3.10/site-packages/torch/nn/functional.py:2210\u001B[0m, in \u001B[0;36membedding\u001B[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001B[0m\n\u001B[1;32m   2204\u001B[0m     \u001B[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001B[39;00m\n\u001B[1;32m   2205\u001B[0m     \u001B[38;5;66;03m# XXX: equivalent to\u001B[39;00m\n\u001B[1;32m   2206\u001B[0m     \u001B[38;5;66;03m# with torch.no_grad():\u001B[39;00m\n\u001B[1;32m   2207\u001B[0m     \u001B[38;5;66;03m#   torch.embedding_renorm_\u001B[39;00m\n\u001B[1;32m   2208\u001B[0m     \u001B[38;5;66;03m# remove once script supports set_grad_enabled\u001B[39;00m\n\u001B[1;32m   2209\u001B[0m     _no_grad_embedding_renorm_(weight, \u001B[38;5;28minput\u001B[39m, max_norm, norm_type)\n\u001B[0;32m-> 2210\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadding_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscale_grad_by_freq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msparse\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.ByteTensor instead (while checking arguments for embedding)"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "# metric = evaluate.load(\"accuracy\")\n",
    "# \n",
    "# def compute_metrics(eval_pred):\n",
    "#     logits, labels = eval_pred\n",
    "#     predictions = np.argmax(logits, axis=-1)\n",
    "#     return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=drive_path / \"pretgpt\" / \"murakami_rugpt3small\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        overwrite_output_dir=True,\n",
    "        save_steps=1000,\n",
    "        save_total_limit=2,\n",
    "    ),\n",
    "    train_dataset=train_set,\n",
    "    eval_dataset=test_set,\n",
    "    # compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vlad/git/vladsaveliev/deeplearning/karpathy/venv/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2501130\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 937926\n",
      "  Number of trainable parameters = 125231616\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "vars() argument must have __dict__ attribute",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/git/vladsaveliev/deeplearning/karpathy/venv/lib/python3.10/site-packages/transformers/trainer.py:1543\u001B[0m, in \u001B[0;36mTrainer.train\u001B[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[1;32m   1538\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_wrapped \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\n\u001B[1;32m   1540\u001B[0m inner_training_loop \u001B[38;5;241m=\u001B[39m find_executable_batch_size(\n\u001B[1;32m   1541\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inner_training_loop, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_train_batch_size, args\u001B[38;5;241m.\u001B[39mauto_find_batch_size\n\u001B[1;32m   1542\u001B[0m )\n\u001B[0;32m-> 1543\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1544\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1545\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1546\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1547\u001B[0m \u001B[43m    \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1548\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/git/vladsaveliev/deeplearning/karpathy/venv/lib/python3.10/site-packages/transformers/trainer.py:1765\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[1;32m   1762\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_load_rng_state(resume_from_checkpoint)\n\u001B[1;32m   1764\u001B[0m step \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[0;32m-> 1765\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step, inputs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(epoch_iterator):\n\u001B[1;32m   1766\u001B[0m \n\u001B[1;32m   1767\u001B[0m     \u001B[38;5;66;03m# Skip past any already trained steps if resuming training\u001B[39;00m\n\u001B[1;32m   1768\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m steps_trained_in_current_epoch \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1769\u001B[0m         steps_trained_in_current_epoch \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m~/git/vladsaveliev/deeplearning/karpathy/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    625\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    626\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    627\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 628\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    629\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    630\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    631\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    632\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/git/vladsaveliev/deeplearning/karpathy/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:671\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    669\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    670\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 671\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    672\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    673\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m~/git/vladsaveliev/deeplearning/karpathy/venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:61\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     60\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n\u001B[0;32m---> 61\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollate_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/git/vladsaveliev/deeplearning/karpathy/venv/lib/python3.10/site-packages/transformers/trainer_utils.py:700\u001B[0m, in \u001B[0;36mRemoveColumnsCollator.__call__\u001B[0;34m(self, features)\u001B[0m\n\u001B[1;32m    698\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, features: List[\u001B[38;5;28mdict\u001B[39m]):\n\u001B[1;32m    699\u001B[0m     features \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_remove_columns(feature) \u001B[38;5;28;01mfor\u001B[39;00m feature \u001B[38;5;129;01min\u001B[39;00m features]\n\u001B[0;32m--> 700\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata_collator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/git/vladsaveliev/deeplearning/karpathy/venv/lib/python3.10/site-packages/transformers/data/data_collator.py:70\u001B[0m, in \u001B[0;36mdefault_data_collator\u001B[0;34m(features, return_tensors)\u001B[0m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;66;03m# In this function we'll make the assumption that all `features` in the batch\u001B[39;00m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;66;03m# have the same attributes.\u001B[39;00m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;66;03m# So we will look at the first element as a proxy for what attributes exist\u001B[39;00m\n\u001B[1;32m     67\u001B[0m \u001B[38;5;66;03m# on the whole batch.\u001B[39;00m\n\u001B[1;32m     69\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m return_tensors \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch_default_data_collator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m return_tensors \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtf\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tf_default_data_collator(features)\n",
      "File \u001B[0;32m~/git/vladsaveliev/deeplearning/karpathy/venv/lib/python3.10/site-packages/transformers/data/data_collator.py:109\u001B[0m, in \u001B[0;36mtorch_default_data_collator\u001B[0;34m(features)\u001B[0m\n\u001B[1;32m    106\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m    108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(features[\u001B[38;5;241m0\u001B[39m], Mapping):\n\u001B[0;32m--> 109\u001B[0m     features \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mvars\u001B[39m(f) \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m features]\n\u001B[1;32m    110\u001B[0m first \u001B[38;5;241m=\u001B[39m features[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    111\u001B[0m batch \u001B[38;5;241m=\u001B[39m {}\n",
      "File \u001B[0;32m~/git/vladsaveliev/deeplearning/karpathy/venv/lib/python3.10/site-packages/transformers/data/data_collator.py:109\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    106\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m    108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(features[\u001B[38;5;241m0\u001B[39m], Mapping):\n\u001B[0;32m--> 109\u001B[0m     features \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mvars\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m features]\n\u001B[1;32m    110\u001B[0m first \u001B[38;5;241m=\u001B[39m features[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    111\u001B[0m batch \u001B[38;5;241m=\u001B[39m {}\n",
      "\u001B[0;31mTypeError\u001B[0m: vars() argument must have __dict__ attribute"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "'Охота на овец\\nЧасть первая\\n25.11.1970\\nПИКНИК СРЕДИ НЕДЕЛИ\\nО ее смерти сообщил мне по телефону старый приятель, наткнувшись на случайные строчки в газете. Единственный абзац скупой заметки он членораздельно зачитал прямо в трубку. Заурядная газетная хроника. Молоденький журналист, едва закончив университет, получил задание и опробовал перо.\\nТогда-то и там-то такой-то, находясь за'"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encoded['input_ids'][:100])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Охота на овец - это не так уж и сложно, как кажется. Как вы, наверно, уже догадались, эта птица - хищная. У нее тоже есть имя - Одиссей, так же она является хищной птицей. Однажды одиссей спас свою дочь от преследователей и с тех пор он служит своим богам. Но ему по-прежнему предстоит выполнить свою долю на поле чести и справедливости, так что пусть одиссей не думает, что он собирается играть в этой мясорубке с\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "t = pipe(prompt, **kwargs, do_sample=True)  # multinomial sampling\n",
    "print(t[0]['generated_text'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load from checkpoint\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "drive_path = Path(\"/Users/vlad/MyDrive/AI\")\n",
    "checkpoint_dir = drive_path / \"pretgpt/murakami_rugpt3small/checkpoint-2000\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sberbank-ai/rugpt3small_based_on_gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint_dir)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": "[{'generated_text': 'Часть первая\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n'}]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "generate = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Часть первая\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = generate(\"Часть первая\", max_length=1000, do_sample=False)\n",
    "print(result[0]['generated_text'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}